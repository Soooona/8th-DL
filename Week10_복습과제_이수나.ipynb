{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **TF-IDF란?**🔍\n",
        "\n",
        "- TF-IDF는 문서 집합 내에서 특정 단어가 얼마나 중요한지를 평가하는 통계적 측정 도구입니다.\n",
        "이 값은 두 가지 요소의 곱으로 계산됩니다:\n",
        "\n",
        "> TF (Term Frequency) – 특정 단어가 해당 문서에서 얼마나 자주 등장하는지\n",
        "\n",
        "> IDF (Inverse Document Frequency) – 해당 단어가 전체 문서 집합에서 얼마나 희귀한지\n",
        "\n",
        "- 예를 들어, \"this\", \"what\", \"if\" 같은 단어는 모든 문서에 흔하게 등장하므로 TF가 높아도 IDF가 낮아져 TF-IDF 값이 낮습니다.\n",
        "반면, \"Bug\" 같은 단어가 특정 문서에만 자주 등장하면 높은 TF-IDF 점수를 갖고, 해당 문서의 주요 주제를 나타낼 수 있습니다 (예: 신뢰성 관련 문서).\n",
        "\n",
        "- 수식으로 표현된 TF-IDF 계산법: *TF-IDF(𝑡,𝑑)=TF(𝑡,𝑑)×IDF(𝑡)*\n",
        "\n",
        "\n",
        "\n",
        "**Scikit-learn 라이브러리에 내장된 TF-IDF 알고리즘을 사용하여, 1987년부터 2019년까지 NeurIPS 학회에서 발표된 논문들로부터 상위 10개 키워드를 추출할 해봅시다** 😀"
      ],
      "metadata": {
        "id": "ubuPsL3gfN2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **데이터 불러오기**\n",
        "\n",
        "- 아래 셀을 실행시켜주세요"
      ],
      "metadata": {
        "id": "4ML81JvIi9W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlnqNL5Tgkl_",
        "outputId": "7d8000c8-95fa-4468-8bb8-59fbacab6256"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0KgEJl0fEXy",
        "outputId": "c23dd32c-6418-4fd7-c9d0-fb6682f7bace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/EURONE/Week10/All_English_Stopwords.txt\n",
            "/content/drive/MyDrive/EURONE/Week10/kaggle_authors.csv\n",
            "/content/drive/MyDrive/EURONE/Week10/kaggle_papers.csv\n",
            "/content/drive/MyDrive/EURONE/Week10/Week10_복습과제_이수나.ipynb\n"
          ]
        }
      ],
      "source": [
        "# 데이터 파일 이름 print\n",
        "import pandas as pd\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/EURONE/Week10'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "# 위의 print된 내용에 따라 아래 path를 수정해주세요\n",
        "PUNCTUATION = \"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"\n",
        "TOP_K_KEYWORDS = 10\n",
        "STOPWORD_PATH = \"/content/drive/MyDrive/EURONE/Week10/All_English_Stopwords.txt\"\n",
        "PAPERS_PATH = \"/content/drive/MyDrive/EURONE/Week10/kaggle_papers.csv\""
      ],
      "metadata": {
        "id": "1lthMPFSiYlU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import re, os, string\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "Ze__Jve-hsRT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **키워드 추출을 위한 함수 정의** ⚓"
      ],
      "metadata": {
        "id": "pLuzfjwhlriq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **get stopwords list 함수 정의**\n",
        "- 주어진 파일에서 불용어 목록을 읽어와 공백 제거 및 중복 제거 후 리스트 형태로 반환하는 함수입니다\n",
        "\n",
        "- 아래 빈칸을 완성해주세요"
      ],
      "metadata": {
        "id": "x9qCUZt3jfsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stopwords_list(stop_file_path):\n",
        "    \"\"\"load stop words \"\"\"\n",
        "     # 지정한 경로의 파일을 UTF-8 인코딩으로 읽기 모드 열기\n",
        "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
        "        # 파일의 모든 줄을 리스트로 읽어오기\n",
        "        stopwords = f.readlines()\n",
        "        # 각 줄에서 양쪽 공백을 제거하고 set으로 중복 제거하기\n",
        "        stop_set = set([word.strip() for word in stopwords])\n",
        "        # frozenset으로 다시 중복 제거하고 리스트로 변환 후 반환하기\n",
        "        return list(frozenset(stop_set))"
      ],
      "metadata": {
        "id": "UGdGzedShsD5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **clean text 함수 정의**\n",
        "-  텍스트 데이터를 소문자로 변환, 문장부호 제거, 공백 정리하여 모델 학습이나 분석에 적합한 형태로 정제(cleaning) 함수입니다\n",
        "\n",
        "- 아래 빈칸을 완성해주세요"
      ],
      "metadata": {
        "id": "AGuodw_8kKsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    # 모든 문자를 소문자로 변환하기\n",
        "    text = text.lower()\n",
        "    # 문장부호 제거하기 (PUNCTUATION에 정의된 모든 기호 제거)\n",
        "    text = text.translate(str.maketrans('', '', PUNCTUATION))\n",
        "    # 공백 문자 및 줄바꿈을 하나의 공백으로 치환\n",
        "    text = re.sub(r\"\\s\",\" \", text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "UOzIfyZJiHHw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **sort coo 함수 정의**\n",
        "- 희소행령 (coo_matrix)를 TF-IDF 점수가 높은 단어부터 정렬하는 함수입니다.\n",
        "- 아래 빈칸을 완성해주세요"
      ],
      "metadata": {
        "id": "uuYdnNP7lJBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_coo(coo_matrix):\n",
        "    # (단어 인덱스, 해당 인덱스의 TF-IDF 값) 튜플 생성하기\n",
        "    tuples = list(zip(coo_matrix.col, coo_matrix.data))\n",
        "    # TF-IDF 점수 기준으로 내림차순 정렬 (점수 같을 경우 인덱스 기준으로)\n",
        "    return sorted(tuples, key=lambda x: (-x[1], x[0]))"
      ],
      "metadata": {
        "id": "dEC7TY7QlJaw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **extract topn from vector 함수 정의**\n",
        "- TF-IDF 벡터에서 상위 n개의 단어와 점수를  {단어: 점수} 형태로 추출하는 함수입니다.\n",
        "- 아래 빈칸을 완성해주세요"
      ],
      "metadata": {
        "id": "YXsLePFIkiWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF 벡터에서 상위 topn개의 단어와 점수를 추출하기\n",
        "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
        "    # 상위 topn 개 항목만 사용하기\n",
        "    sorted_items = sorted_items[:topn]\n",
        "\n",
        "    score_vals = [] # TF-IDF 점수 저장용 리스트\n",
        "    feature_vals = [] # 단어 저장용 리스트\n",
        "\n",
        "    # (단어 인덱스, TF-IDF 점수)로부터 단어와 점수를 추출하기\n",
        "    for idx, score in sorted_items:\n",
        "        score_vals.append(round(score,3))  # 점수 반올림하여 저장\n",
        "        feature_vals.append(feature_names[idx]) # 인덱스로 단어 찾아 저장\n",
        "\n",
        "    # 단어: 점수 형태의 딕셔너리 생성하기\n",
        "    results= {}\n",
        "    for idx in range(len(feature_vals)):\n",
        "        results[feature_vals[idx]]= score_vals[idx]\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "i0ADvuKIiQzB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **get keywords 함수 정의**\n",
        "- 문서 하나에서 TF-IDF 기반으로 가장 중요한 단어 K개를 추출하는 함수입니다.\n",
        "- 아래 빈칸을 완성해주세요"
      ],
      "metadata": {
        "id": "2AGwrrYrl5cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_keywords(vectorizer, feature_names, doc):\n",
        "    \"\"\"Return top k keywords from a doc using TF-IDF method\"\"\"\n",
        "\n",
        "    # 주어진 문서에 대해 TF-IDF 벡터 생성하기\n",
        "    tf_idf_vector = vectorizer.transform([doc])\n",
        "\n",
        "    # TF-IDF 점수를 기준으로 내림차순 정렬하기\n",
        "    sorted_items= sort_coo(tf_idf_vector.tocoo())\n",
        "\n",
        "    # 상위 TOP_K_KEYWORDS 개 단어와 점수 추출하기\n",
        "    keywords=extract_topn_from_vector(feature_names, sorted_items)\n",
        "    # 키워드(단어)만 리스트로 반환하기\n",
        "    return list(keywords.keys())"
      ],
      "metadata": {
        "id": "ofUaC1p4iS33"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **데이터에 적용하기** 🌻\n",
        "- 우리의 데이터에 적용해봅시다!\n",
        "- 아래 셀을 실행시켜주세요"
      ],
      "metadata": {
        "id": "CTpm_l6hmQO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(PAPERS_PATH)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JwuXL7NciUpR",
        "outputId": "9d7e1a60-9865-4031-efe7-0bb9f40fe72e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   source_id  year                                              title  \\\n",
              "0         27  1987                         Bit-Serial Neural Networks   \n",
              "1         63  1987                        Connectivity Versus Entropy   \n",
              "2         60  1987        The Hopfield Model with Multi-Level Neurons   \n",
              "3         59  1987                               How Neural Nets Work   \n",
              "4         69  1987  Spatial Organization of Neural Networks: A Pro...   \n",
              "\n",
              "  abstract                                          full_text  \n",
              "0      NaN  573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...  \n",
              "1      NaN  1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...  \n",
              "2      NaN  278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...  \n",
              "3      NaN  442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...  \n",
              "4      NaN  740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-013cbd44-f4bd-4d02-ad2c-6df794ef2d81\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>1987</td>\n",
              "      <td>Bit-Serial Neural Networks</td>\n",
              "      <td>NaN</td>\n",
              "      <td>573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63</td>\n",
              "      <td>1987</td>\n",
              "      <td>Connectivity Versus Entropy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>1987</td>\n",
              "      <td>The Hopfield Model with Multi-Level Neurons</td>\n",
              "      <td>NaN</td>\n",
              "      <td>278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59</td>\n",
              "      <td>1987</td>\n",
              "      <td>How Neural Nets Work</td>\n",
              "      <td>NaN</td>\n",
              "      <td>442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69</td>\n",
              "      <td>1987</td>\n",
              "      <td>Spatial Organization of Neural Networks: A Pro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-013cbd44-f4bd-4d02-ad2c-6df794ef2d81')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-013cbd44-f4bd-4d02-ad2c-6df794ef2d81 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-013cbd44-f4bd-4d02-ad2c-6df794ef2d81');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9ff7f7be-4845-44dd-a545-42d702713b78\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ff7f7be-4845-44dd-a545-42d702713b78')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9ff7f7be-4845-44dd-a545-42d702713b78 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 9680,\n  \"fields\": [\n    {\n      \"column\": \"source_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1825,\n        \"min\": 1,\n        \"max\": 9406,\n        \"num_unique_values\": 4522,\n        \"samples\": [\n          5676,\n          2528,\n          5716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 1987,\n        \"max\": 2019,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          2018,\n          2002,\n          2013\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9680,\n        \"samples\": [\n          \"Label Embedding Trees for Large Multi-Class Tasks\",\n          \"Catastrophic Interference in Human Motor Learning\",\n          \"Provably Correct Automatic Sub-Differentiation for Qualified Programs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6361,\n        \"samples\": [\n          \"We introduce algorithmic assurance, the problem of testing whether\\nmachine learning algorithms are conforming to their intended design\\ngoal. We address this problem by proposing an efficient framework\\nfor algorithmic testing. To provide assurance, we need to efficiently\\ndiscover scenarios where an algorithm decision deviates maximally\\nfrom its intended gold standard. We mathematically formulate this\\ntask as an optimisation problem of an expensive, black-box function.\\nWe use an active learning approach based on Bayesian optimisation\\nto solve this optimisation problem. We extend this framework to algorithms\\nwith vector-valued outputs by making appropriate modification in Bayesian\\noptimisation via the EXP3 algorithm. We theoretically analyse our\\nmethods for convergence. Using two real-world applications, we demonstrate\\nthe efficiency of our methods. The significance of our problem formulation\\nand initial solutions is that it will serve as the foundation in assuring\\nhumans about machines making complex decisions.\",\n          \"Hamiltonian Monte Carlo (HMC) is a widely deployed method to sample from high-dimensional  distributions in  Statistics and Machine learning. HMC is known to run very efficiently in practice and its popular second-order ``leapfrog\\\" implementation has long been conjectured to run in $d^{1/4}$ gradient evaluations. Here we show that this conjecture is true when sampling from strongly log-concave target distributions that satisfy a weak third-order regularity property associated with the input data.  Our regularity condition is weaker than the Lipschitz Hessian property and allows us to show faster convergence bounds for a much larger class of distributions than would be possible with the usual Lipschitz Hessian constant alone.  Important distributions that satisfy our regularity condition include posterior distributions used in Bayesian logistic regression for which the data satisfies an ``incoherence\\\" property. Our result compares favorably with the best available bounds for the class of strongly log-concave distributions, which grow like $d^{{1}/{2}}$ gradient evaluations with the dimension. Moreover, our simulations on synthetic data suggest that, when our regularity condition is satisfied, leapfrog HMC performs better than its competitors -- both in terms of accuracy and in terms of the number of gradient evaluations it requires.\",\n          \"Dependencies among neighbouring labels in a sequence is an important source of information for sequence labeling problems. However, only dependencies between adjacent labels are commonly exploited in practice because of the high computational complexity of typical inference algorithms when longer distance dependencies are taken into account. In this paper, we show that it is possible to design efficient inference algorithms for a conditional random field using features that depend on long consecutive label sequences (high-order features), as long as the number of distinct label sequences in the features used is small. This leads to efficient learning algorithms for these conditional random fields. We show experimentally that exploiting dependencies using high-order features can lead to substantial performance improvements for some problems and discuss conditions under which high-order features can be effective.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9673,\n        \"samples\": [\n          \"Nonparametric Multi-group Membership Model\\n\\nfor Dynamic Networks\\n\\nMyunghwan Kim\\nStanford University\\nStanford, CA 94305\\n\\nJure Leskovec\\n\\nStanford University\\nStanford, CA 94305\\n\\nmykim@stanford.edu\\n\\njure@cs.stanford.edu\\n\\nRelational data\\u2014like graphs, networks, and matrices\\u2014is often dynamic, where the relational struc-\\nture evolves over time. A fundamental problem in the analysis of time-varying network data is to\\nextract a summary of the common structure and the dynamics of the underlying relations between\\nthe entities. Here we build on the intuition that changes in the network structure are driven by dy-\\nnamics at the level of groups of nodes. We propose a nonparametric multi-group membership model\\nfor dynamic networks. Our model contains three main components: We model the birth and death of\\nindividual groups with respect to the dynamics of the network structure via a distance dependent In-\\ndian Buffet Process. We capture the evolution of individual node group memberships via a Factorial\\nHidden Markov model. And, we explain the dynamics of the network structure by explicitly mod-\\neling the connectivity structure of groups. We demonstrate our model\\u2019s capability of identifying the\\ndynamics of latent groups in a number of different types of network data. Experimental results show\\nthat our model provides improved predictive performance over existing dynamic network models on\\nfuture network forecasting and missing link prediction.\\n\\n1 Introduction\\n\\nStatistical analysis of social networks and other relational data is becoming an increasingly impor-\\ntant problem as the scope and availability of network data increases. Network data\\u2014such as the\\nfriendships in a social network\\u2014is often dynamic in a sense that relations between entities rise and\\ndecay over time. A fundamental problem in the analysis of such dynamic network data is to extract\\na summary of the common structure and the dynamics of the underlying relations between entities.\\n\\nAccurate models of structure and dynamics of network data have many applications. They allow us\\nto predict missing relationships [20, 21, 23], recommend potential new relations [2], identify clusters\\nand groups of nodes [1, 29], forecast future links [4, 9, 11, 24], and even predict group growth and\\nlongevity [15].\\n\\nHere we present a new approach to modeling network dynamics by considering time-evolving inter-\\nactions between groups of nodes as well as the arrival and departure dynamics of individual nodes\\nto these groups. We develop a dynamic network model, Dynamic Multi-group Membership Graph\\nModel, that identi\\ufb01es the birth and death of individual groups as well as the dynamics of node join-\\ning and leaving groups in order to explain changes in the underlying network linking structure. Our\\nnonparametric model considers an in\\ufb01nite number of latent groups, where each node can belong to\\nmultiple groups simultaneously. We capture the evolution of individual node group memberships\\nvia a Factorial Hidden Markov model. However, in contrast to recent works on dynamic network\\nmodeling [4, 5, 11, 12, 14], we explicitly model the birth and death dynamics of individual groups\\nby using a distance-dependent Indian Buffet Process [7]. Under our model only active/alive groups\\nin\\ufb02uence relationships in a network at a given time. Further innovation of our approach is that we\\nnot only model relations between the members of the same group but also account for links between\\nmembers and non-members. By explicitly modeling group lifespan and group connectivity structure\\nwe achieve greater modeling \\ufb02exibility, which leads to improved performance on link prediction and\\nnetwork forecasting tasks as well as to increased interpretability of obtained results.\\n\\n1\\n\\n\\fThe rest of the paper is organized as follows: Section 2 provides the background and Section 3\\npresents our generative model and motivates its parametrization. We discuss related work in Sec-\\ntion 4 and present model inference procedure in Section 5. Last, in Section 6 we provide experi-\\nmental results as well as analysis of the social network from the movie, The Lord of the Rings.\\n\\n2 Models of Dynamic Networks\\n\\nFirst, we describe general components of modern dynamic network models [4, 5, 11, 14]. In the\\nnext section we will then describe our own model and point out the differences to the previous work.\\n\\nDynamic networks are generally conceptualized as discrete time series of graphs on a \\ufb01xed set of\\nnodes N . Dynamic network Y is represented as a time series of adjacency matrices Y (t) for each\\ntime t = 1, 2, \\u00b7 \\u00b7 \\u00b7 , T . In this work, we limit our focus to unweighted directed as well as undirected\\nnetworks. So, each Y (t) is a N \\u00d7 N binary matrix where Y (t)\\nij = 1 if a link from node i to j exists\\nat time t and Y (t)\\n\\nij = 0 otherwise.\\n\\nEach node i of the network is associated with a number of latent binary features that govern the\\ninteraction dynamics with other nodes of the network. We denote the binary value of feature k of\\nnode i at time t by z(t)\\nik \\u2208 {0, 1}. Such latent features can be viewed as assigning nodes to multi-\\nple overlapping, latent clusters or groups [1, 21]. In our work, we interpret these latent features as\\nmemberships to latent groups such as social communities of people with the same interests or hob-\\nbies. We allow each node to belong to multiple groups simultaneously. We model each node-group\\nmembership using a separate Bernoulli random variable [17, 22, 29]. This is in contrast to mixed-\\nmembership models where the distribution over individual node\\u2019s group memberships is modeled\\nusing a multinomial distribution [1, 5, 12]. The advantage of our multiple-membership approach\\nis as follows. Mixed-membership models (i.e., multinomial distribution over group memberships)\\nessentially assume that by increasing the amount of node\\u2019s membership to some group k, the same\\nnode\\u2019s membership to some other group k\\u2032 has to decrease (due to the condition that the probabilities\\nnormalize to 1). On the other hand, multiple-membership models do not suffer from this assumption\\nand allow nodes to truely belong to multiple groups. Furthermore, we consider a nonparametric\\nmodel of groups which does not restrict the number of latent groups ahead of time. Hence, our\\nmodel adaptively learns the appropriate number of latent groups for a given network at a given time.\\n\\nIn dynamic network models, one also speci\\ufb01es a process by which nodes dynamically join and leave\\ngroups. We assume that each node i can join or leave a given group k according to a Markov model.\\nHowever, since each node can join multiple groups independently, we naturally consider factorial\\nhidden Markov models (FHMM) [8], where latent group membership of each node independently\\nevolves over time. To be concrete, each membership z(t)\\nik evolves through a 2-by-2 Markov transition\\nprobability matrix Q(t)\\n= r), where\\nr, s \\u2208 {0 = non-member, 1 = member}.\\n\\nk [r, s] corresponds to P (z(t)\\n\\nk where each entry Q(t)\\n\\nik = s|z(t\\u22121)\\n\\nik\\n\\nNow, given node group memberships z(t)\\nik at time t one also needs to specify the process of link\\ngeneration. Links of the network realize according to a link function f (\\u00b7). A link from node i to\\nnode j at time t occurs with probability determined by the link function f (z(t)\\nj\\u00b7 ). In our model,\\nwe develop a link function that not only accounts for links between group members but also models\\nlinks between the members and non-members of a given group.\\n\\ni\\u00b7 , z(t)\\n\\n3 Dynamic Multi-group Membership Graph Model\\n\\nNext we shall describe our Dynamic Multi-group Membership Graph Model (DMMG) and point out\\nthe differences with the previous work. In our model, we pay close attention to the three processes\\ngoverning network dynamics: (1) birth and death dynamics of individual groups, (2) evolution of\\nmemberships of nodes to groups, and (3) the structure of network interactions between group mem-\\nbers as well as non-members. We now proceed by describing each of them in turn.\\n\\nModel of active groups. Links of the network are in\\ufb02uenced not only by nodes changing member-\\nships to groups but also by the birth and death of groups themselves. New groups can be born and\\nold ones can die. However, without explicitly modeling group birth and death there exists ambiguity\\n\\n2\\n\\n\\fbetween group membership change and the birth/death of groups. For example, consider two dis-\\njoint groups k and l such that their lifetimes and members do not overlap. In other words, group l is\\nborn after group k dies out. However, if group birth and death dynamics is not explicitly modeled,\\nthen the model could interpret that the two groups correspond to a single latent group where all the\\nmembers of k leave the group before the members of l join the group. To resolve this ambiguity we\\ndevise an explicit model of birth/death dynamics of groups by introducing a notion of active groups.\\n\\nUnder our model, a group can be in one of two states: it can be either active (alive) or inactive (not\\nyet born or dead). However, once a group becomes inactive, it can never be active again. That is,\\nonce a group dies, it can never be alive again. To ensure coherence of group\\u2019s state over time, we\\nbuild on the idea of distance-dependent Indian Buffet Processes (dd-IBP) [7]. The IBP is named\\nafter a metaphorical process that gives rise to a probability distribution, where customers enter an\\nIndian Buffet restaurant and sample some subset of an in\\ufb01nitely long sequence of dishes. In the\\ncontext of networks, nodes usually correspond to \\u2018customers\\u2019 and latent features/groups correspond\\nto \\u2018dishes\\u2019. However, we apply dd-IBP in a different way. We regard each time step t as a \\u2018customer\\u2019\\nthat samples a set of active groups Kt. So, at the \\ufb01rst time step t = 1, we have P oisson(\\u03bb) number\\nof groups that are initially active, i.e., |K1| \\u223c P oisson(\\u03bb). To account for death of groups we\\nthen consider that each active group at time t \\u2212 1 can become inactive at the next time step t with\\nprobability \\u03b3. On the other hand, P oisson(\\u03b3\\u03bb) new groups are also born at time t. Thus, at each\\ntime currently active groups can die, while new ones can also be born. The hyperparameter \\u03b3\\ncontrols for how often new groups are born and how often old ones die. For instance, there will be\\nalmost no newborn or dead groups if \\u03b3 \\u2248 1, while there would be no temporal group coherence and\\npractically all the groups would die between consecutive time steps if \\u03b3 = 0.\\n\\nFigure 1(a) gives an example of the above process. Black circles indicate active groups and white\\ncircles denote inactive (not yet born or dead) groups. Groups 1 and 3 exist at t = 1 and Group 2\\nis born at t = 2. At t = 3, Group 3 dies but Group 4 is born. Without our group activity model,\\nGroup 3 could have been reused with a completely new set of members and Group 4 would have\\nnever been born. Our model can distinguish these two disjoint groups.\\n\\nFormally, we denote the number of active groups at time t by Kt = |Kt|. We also denote the state\\n(active/inactive) of group k at time t by W (t)\\nk = 1{k \\u2208 Kt}. For convenience, we also de\\ufb01ne a set\\nof newly active groups at time t be K+\\n\\nt = |K+\\nt |.\\nPutting it all together we can now fully describe the process of group birth/death as follows:\\n\\nk = 0 \\u2200t\\u2032 < t} and K +\\n\\nk = 1, W (t\\u2032)\\n\\nt = {k|W (t)\\n\\nfor t = 1\\nfor t > 1\\n\\nK +\\n\\nP oisson (\\u03b3\\u03bb) ,\\n\\nt \\u223c(cid:26)P oisson (\\u03bb) ,\\nk \\u223c\\uf8f1\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f3\\n\\nBernoulli(1 \\u2212 \\u03b3)\\n1,\\n0,\\n\\nW (t)\\n\\nk\\n\\n= 1\\nt\\u2032=1 K +\\n\\nif W (t\\u22121)\\n\\nif Pt\\u22121\\n\\notherwise .\\n\\nt\\u2032 < k \\u2264Pt\\n\\nt\\u2032=1 K +\\n\\nt\\u2032\\n\\n(1)\\n\\nNote that under this model an in\\ufb01nite number of active groups can exist. This means our model au-\\ntomatically determines the right number of active groups and each node can belong to many groups\\nsimultaneously. We now proceed by describing the model of node group membership dynamics.\\n\\nDynamics of node group memberships. We capture the dynamics of nodes joining and leaving\\ngroups by assuming that latent node group memberships form a Markov chain. In this framework,\\nnode memberships to active groups evolve through time according to Markov dynamics:\\n\\nP (z(t)\\n\\nik |z(t\\u22121)\\n\\nik\\n\\n) = Qk =(cid:18) 1 \\u2212 ak\\n\\nbk\\n\\nak\\n\\n1 \\u2212 bk (cid:19) ,\\n\\nwhere matrix Qk[r, s] denotes a Markov transition from state r to state s, which can be a \\ufb01xed\\nparameter, group speci\\ufb01c, or otherwise domain dependent as long as it de\\ufb01nes a Markov transition\\nmatrix. Thus, the transition of node\\u2019s i membership to active group k can be de\\ufb01ned as follows:\\n\\nak, bk \\u223c Beta(\\u03b1, \\u03b2), z(t)\\n\\nik \\u223c W (t)\\n\\nk\\n\\n\\u00b7 Bernoulli(cid:18)a\\n\\n(t\\u22121)\\nik\\n\\n1\\u2212z\\nk\\n\\n(1 \\u2212 bk)z\\n\\n(t\\u22121)\\n\\nik (cid:19) .\\n\\n(2)\\n\\nTypically, \\u03b2 > \\u03b1, which ensures that group\\u2019s memberships are not too volatile over time.\\n\\n3\\n\\n\\f(a) Group activity model\\n\\n(b) Link function model\\n\\nFigure 1: (a) Birth and death of groups: Black circles represent active and white circles represent inactive\\n(unborn or dead) groups. A dead group can never become active again.\\ndenotes\\nbinary node group memberships. Entries of link af\\ufb01nity matrix \\u0398k denotes linking parameters between all 4\\ncombinations of members (z(t)\\nij , individual\\naf\\ufb01nities \\u0398k[z(t)\\n\\ni = 0). To obtain link probability p(t)\\n\\ni = 1) and non-members (z(t)\\n\\n] are combined using a logistic function g(\\u00b7)\\n\\n(b) Link function: z(t)\\n\\n, z(t)\\n\\ni\\n\\nj\\n\\nj\\n\\n.\\n\\nRelationship between node group memberships and links of the network. Last, we describe the\\npart of the model that establishes the connection between node\\u2019s memberships to groups and the\\nlinks of the network. We achieve this by de\\ufb01ning a link function f (i, j), which for given a pair of\\nnodes i, j determines their interaction probability p(t)\\n\\nij based on their group memberships.\\n\\nWe build on the Multiplicative Attribute Graph model [16, 18], where each group k is associated\\nwith a link af\\ufb01nity matrix \\u0398k \\u2208 R2\\u00d72. Each of the four entries of the link af\\ufb01nity matrix captures\\nthe tendency of linking between group\\u2019s members, members and non-members, as well as non-\\nmembers themselves. While traditionally link af\\ufb01nities were considered to be probabilities, we\\nrelax this assumption by allowing af\\ufb01nities to be arbitrary real numbers and then combine them\\nthrough a logistic function to obtain a \\ufb01nal link probability.\\n\\nThe model is illustrated in Figure 1(b). Given group memberships z(t)\\njk of nodes i and j at\\ntime t the binary indicators \\u201cselect\\u201d an entry \\u0398k[z(t)\\njk ] of matrix \\u0398k. This way linking tendency\\nfrom node i to node j is re\\ufb02ected based on their membership to group k. We then determine the\\noverall link probability p(t)\\n\\nij by combining the link af\\ufb01nities via a logistic function g(\\u00b7)1. Thus,\\n\\nik and z(t)\\n\\nik , z(t)\\n\\nij = f (z(t)\\np(t)\\n\\ni\\u00b7 , z(t)\\n\\nj\\u00b7 ) = g \\u01ebt +\\n\\n\\u0398k[z(t)\\n\\nik , z(t)\\n\\njk ]! , Yij \\u223c Bernoulli(p(t)\\n\\nij )\\n\\n(3)\\n\\n\\u221e\\n\\nXk=1\\n\\nwhere \\u01ebt is a density parameter that re\\ufb02ects the varying link density of network over time.\\n\\nNote that due to potentially in\\ufb01nite number of groups the sum of an in\\ufb01nite number of link af\\ufb01nities\\nmay not be tractable. To resolve this, we notice that for a given \\u0398k subtracting \\u0398k[0, 0] from all its\\nentries and then adding this value to \\u01ebt does not change the overall linking probability p(t)\\nij . Thus, we\\ncan set \\u0398k[0, 0] = 0 and then only a \\ufb01nite number of af\\ufb01nities selected by z(t)\\nik have to be considered.\\nFor all other entries of \\u0398k we use N (0, \\u03bd2) as a prior distribution.\\n\\nTo sum up, Figure 2 illustrates the three components of the DMMG in a plate notation. Group\\u2019s\\nstate W (t)\\nik is de\\ufb01ned as\\nthe FHMM over active groups. Then, the link between nodes i and j is determined based on the\\ngroups they belong to and the corresponding group link af\\ufb01nity matrices \\u0398.\\n\\nis determined by the dd-IBP process and each node-group membership z(t)\\n\\nk\\n\\n4 Related Work\\n\\nClassically, non-Bayesian approaches such as exponential random graph models [10, 27] have been\\nused to study dynamic networks. On the other hand, in the Bayesian approaches to dynamic network\\nanalysis latent variable models have been most widely used. These approaches differ by the struc-\\nture of the latent space that they assume. For example, euclidean space models [13, 24] place nodes\\n\\n1g(x) = exp(x)/(1 + exp(x))\\n\\n4\\n\\n\\fFigure 2: Dynamic Multi-group Membership Graph Model. Network Y depends on each node\\u2019s group mem-\\nberships Z and active groups W . Links of Y appear via link af\\ufb01nities \\u0398.\\n\\nin a low dimensional Euclidean space and the network evolution is then modeled as a regression\\nproblem of node\\u2019s future latent location. In contrast, our model uses HMMs, where latent vari-\\nables stochastically depend on the state at the previous time step. Related to our work are dynamic\\nmixed-membership models where a node is probabilistically allocated to a set of latent features. Ex-\\namples of this model include the dynamic mixed-membership block model [5, 12] and the dynamic\\nin\\ufb01nite relational model [14]. However, the critical difference here is that our model uses multi-\\nmemberships where node\\u2019s membership to one group does not limit its membership to other groups.\\nProbably most related to our work here are DRIFT [4] and LFP [11] models. Both of these models\\nconsider Markov switching of latent multi-group memberships over time. DRIFT uses the in\\ufb01nite\\nfactorial HMM [6], while LFP adds \\u201csocial propagation\\u201d to the Markov processes so that network\\nlinks of each node at a given time directly in\\ufb02uence group memberships of the corresponding node\\nat the next time. Compared to these models, we uniquely incorporate the model of group birth and\\ndeath and present a novel and powerful linking function.\\n\\n5 Model Inference via MCMC\\n\\nWe develop a Markov chain Monte Carlo (MCMC) procedure to approximate samples from the\\nposterior distribution of the latent variables in our model. More speci\\ufb01cally, there are \\ufb01ve types\\nof variables that we need to sample: node group memberships Z = {z(t)\\nik }, group states W =\\n{W (t)\\nk }, group membership transitions Q = {Qk}, link af\\ufb01nities \\u0398 = {\\u0398k}, and density parameters\\n\\u01eb = {\\u01ebt}. By sampling each type of variables while \\ufb01xing all the others, we end up with many\\nsamples representing the posterior distribution P (Z, W, Q, \\u0398, \\u01eb|Y, \\u03bb, \\u03b3, \\u03b1, \\u03b2). We shall now explain\\na sampling strategy for each varible type.\\n\\nSampling node group memberships Z. To sample node group membership z(t)\\nik , we use the\\nforward-backward recursion algorithm [26]. The algorithm \\ufb01rst de\\ufb01nes a deterministic forward\\npass which runs down the chain starting at time one, and at each time point t collects information\\nfrom the data and parameters up to time t in a dynamic programming cache. A stochastic backward\\npass starts at time T and samples each z(t)\\nik in backwards order using the information collected dur-\\ning the forward pass. In our case, we only need to sample z(T B\\nk indicate the\\nbirth time and the death time of group k. Due to space constraints, we discuss further details in the\\nextended version of the paper [19].\\n\\nk and T D\\n\\nwhere T B\\n\\nk :T D\\nk )\\n\\nik\\n\\nSampling group states W . To update active groups, we use the Metropolis-Hastings algorithm\\nwith the following proposal distribution P (W \\u2192 W \\u2032): We add a new group, remove an existing\\ngroup, or update the life time of an active group with the same probability 1/3. When adding a new\\ngroup k\\u2032 we select the birth and death time of the group at random such that 1 \\u2264 T B\\nk\\u2032 \\u2264 T D\\nk\\u2032 \\u2264 T .\\nFor removing groups we randomly pick one of existing groups k\\u2032\\u2032 and remove it by setting W (t)\\nk\\u2032\\u2032 = 0\\nfor all t. Finally, to update the birth and death time of an existing group, we select an existing group\\nand propose new birth and death time of the group at random. Once new state vector W \\u2032 is proposed\\nwe accept it with probability\\n\\nmin(cid:18)1,\\n\\nP (Y |W \\u2032)P (W \\u2032|\\u03bb, \\u03b3)P (W \\u2032 \\u2192 W )\\n\\nP (Y |W )P (W |\\u03bb, \\u03b3)P (W \\u2192 W \\u2032) (cid:19) .\\n\\n(4)\\n\\nWe compute P (W |\\u03bb, \\u03b3) and P (W \\u2032 \\u2192 W ) in a closed form, while we approximate the posterior\\nP (Y |W ) by sampling L Gibbs samples while keeping W \\ufb01xed.\\n\\n5\\n\\n\\fSampling group membership transition matrix Q. Beta distribution is a conjugate prior of\\nBernoulli distribution and thus we can sample each ak and bk in Qk directly from the posterior\\ndistribution: ak \\u223c Beta(\\u03b1 + N01,k, \\u03b2 + N00,k) and bk \\u223c Beta(\\u03b1 + N10,k, \\u03b2 + N11,k), where Nrs,k\\nis the number of nodes that transition from state r to s in group k (r, s \\u2208 {0 = non-member, 1 =\\nmember}).\\n\\nSampling link af\\ufb01nities \\u0398. Once node group memberships Z are determined, we update the entries\\nof link af\\ufb01nity matrices \\u0398k. Direct sampling of \\u0398 is intractable because of non-conjugacy of the\\nlogistic link function. An appropriate method in such case would be the Metropolis-Hastings that\\naccepts or rejects the proposal based on the likelihood ratio. However, to avoid low acceptance\\nrates and quickly move toward the mode of the posterior distribution, we develop a method based\\non Hybrid Monte Carlo (HMC) sampling [3]. We guide the sampling using the gradient of log-\\nlikelihood function with respect to each \\u0398k. Because links Y (t)\\nij are generated independently given\\ngroup memberships Z, the gradient with respect to \\u0398k[x, y] can be computed by\\n\\n\\u2212\\n\\n1\\n2\\u03c32 \\u03982\\n\\nk +Xi,j,t(cid:16)Y (t)\\n\\nij \\u2212 p(t)\\n\\nik = x, z(t)\\n\\njk = y} .\\n\\nij (cid:17) 1{z(t)\\n\\n(5)\\n\\nUpdating density parameter \\u01eb. Parameter vector \\u01eb is de\\ufb01ned over a \\ufb01nite dimension T . Therefore,\\nwe can update \\u01eb by maximizing the log-likelihood given all the other variables. We compute the\\ngradient update for each \\u01ebt and directly update \\u01ebt via a gradient step.\\n\\nUpdating hyperparameters. The number of groups over all time periods is given by a Poisson\\ndistribution with parameter \\u03bb (1 + \\u03b3 (T \\u2212 1)). Hence, given \\u03b3 we sample \\u03bb by using a Gamma\\nconjugate prior. Similarly, we can use the Beta conjugate prior for the group death process (i.e.,\\nBernoulli distribution) to sample \\u03b3. However, hyperparameters \\u03b1 and \\u03b2 do not have a conjugate\\nprior, so we update them by using a gradient method based on the sampled values of ak and bk.\\n\\nij\\n\\nTime complexity of model parameter estimation. Last, we brie\\ufb02y comment on the time com-\\nplexity of our model parameter estimation procedure. Each sample z(t)\\nik requires computation of\\nlink probability p(t)\\nfor all j 6= i. Since the expected number of active groups at each time is \\u03bb,\\nthis requires O(\\u03bbN 2T ) computations of p(t)\\nij . By caching the sum of link af\\ufb01nities between every\\npair of nodes sampling Z as well as W requires O(\\u03bbN 2T ) time. Sampling \\u0398 and \\u01eb also requires\\nO(\\u03bbN 2T ) because the gradient of each p(t)\\nij needs to be computed. Overall, our approach takes\\nO(\\u03bbN 2T ) to obtain a single sample, while models that are based on the interaction matrix between\\nall groups [4, 5, 11] require O(K 2N 2T ), where K is the expected number of groups. Furthermore,\\nit has been shown that O(log N ) groups are enough to represent networks [16, 18]. Thus, in practice\\nK (i.e., \\u03bb) is of order log N and the running time for each sample is O(N 2T log N ).\\n\\n6 Experiments\\n\\nWe evaluate our model on three different tasks. For quantitative evaluation, we perform missing link\\nprediction as well as future network forecasting and show our model gives favorable performance\\nwhen compared to current dynamic and static network models. We also analyze the dynamics of\\ngroups in a dynamic social network of characters in a movie \\u201cThe Lord of the Rings: The Two\\nTowers.\\u201d\\n\\nExperimental setup. For the two prediction experiments, we use the following three datasets. First,\\nthe NIPS co-authorships network connects two people if they appear on the same publication in\\nthe NIPS conference in a given year. Network spans T =17 years (1987 to 2003). Following [11]\\nwe focus on a subset of 110 most connected people over all time periods. Second, the DBLP co-\\nauthorship network is obtained from 21 Computer Science conferences from 2000 to 2009 (T =\\n10) [28]. We focus on 209 people by taking 7-core of the aggregated network for the entire time.\\nThird, the INFOCOM dataset represents the physical proximity interactions between 78 students at\\nthe 2006 INFOCOM conference, recorded by wireless detector remotes given to each attendee [25].\\nAs in [11] we use the processed data that removes inactive time slices to have T =50.\\n\\nTo evaluate the predictive performance of our model, we compare it to three baseline models. For\\na naive baseline model, we regard the relationship between each pair of nodes as the instance of\\n\\n6\\n\\n\\fModel\\n\\nNaive\\nLFRM\\nDRIFT\\n\\nDMMG\\n\\nTestLL\\n\\n-2030\\n-880\\n-758\\n\\n\\u2212624\\n\\nNIPS\\nAUC\\n\\n0.808\\n0.777\\n0.866\\n0.916\\n\\nF1\\n\\nTestLL\\n\\n-12051\\n0.177\\n-3783\\n0.195\\n-3108\\n0.296\\n0.434 \\u22122684\\n\\nDBLP\\nAUC\\n\\n0.814\\n0.784\\n0.916\\n0.939\\n\\nINFOCOM\\n\\nF1\\n\\nTestLL\\n\\nAUC\\n\\nF1\\n\\n-17821\\n0.300\\n-8689\\n0.146\\n-6654\\n0.421\\n0.492 \\u22126422\\n\\n0.677\\n0.946\\n0.973\\n0.976\\n\\n0.252\\n0.703\\n0.757\\n0.764\\n\\nTable 1: Missing link prediction. We bold the performance of the best scoring method. Our DMMG performs\\nthe best in all cases. All improvements are statistically signi\\ufb01cant at 0.01 signi\\ufb01cance level.\\n\\nindependent Bernoulli distribution with Beta(1, 1) prior. Thus, for a given pair of nodes, the link\\nprobability at each time equals to the expected probability from the posterior distribution given net-\\nwork data. Second baseline is LFRM [21], a model of static networks. For missing link prediction,\\nwe independently \\ufb01t LFRM to each snapshot of dynamic networks. For network forecasting task,\\nwe \\ufb01t LFRM to the most recent snapshot of a network. Even though LFRM does not capture time\\ndynamics, we consider this to be a strong baseline model. Finally, for the comparison with dynamic\\nnetwork models, we consider two recent state of the art models. The DRIFT model [4] is based\\non an in\\ufb01nite factorial HMM and authors kindly shared their implementation. We also consider the\\nLFP model [11] for which we were not able to obtain the implementation, but since we use the same\\ndatasets, we compare performance numbers directly with those reported in [11].\\n\\nTo evaluate predictive performance, we use various standard evaluation metrics. First, to assess\\ngoodness of inferred probability distributions, we report the log-likelihood of held-out edges. Sec-\\nond, to verify the predictive performance, we compute the area under the ROC curve (AUC). Last,\\nwe also report the maximum F1-score (F1) by scanning over all possible precision/recall thresholds.\\n\\nTask 1: Predicting missing links. To generate the datasets for the task of missing link prediction,\\nwe randomly hold out 20% of node pairs (i.e., either link or non-link) throughout the entire time\\nperiod. We then run each model to obtain 400 samples after 800 burn-in samples for each of 10\\nMCMC chains. Each sample gives a link probability for a given missing entry, so the \\ufb01nal link\\nprobability of a missing entry is computed by averaging the corresponding link probability over all\\nthe samples. This \\ufb01nal link probability provides the evaluation metric for a given missing data entry.\\n\\nTable 1 shows average evaluation metrics for each model and dataset over 10 runs. We also compute\\nthe p-value on the difference between two best results for each dataset and metric. Overall, our\\nDMMG model signi\\ufb01cantly outperforms the other models in every metric and dataset. Particularly\\nin terms of F1-score we gain up to 46.6% improvement over the other models.\\n\\nBy comparing the naive model and LFRM, we observe that LFRM performs especially poorly\\ncompared to the naive model in two networks with few edges (NIPS and DBLP). Intuitively this\\nmakes sense because due to the network sparsity we can obtain more information from the temporal\\ntrajectory of each link than from each snapshot of network. However, both DRIFT and DMMG\\nsuccessfully combine the temporal and the network information which results in better predictive\\nperformance. Furthermore, we note that DMMG outperforms the other models by a larger margin\\nas networks get sparser. DMMG makes better use of temporal information because it can explicitly\\nmodel temporally local links through active groups.\\n\\nLast, we also compare our model to the LFP model. The LFP paper reports AUC ROC score of\\n\\u223c0.85 for NIPS and \\u223c0.95 for INFOCOM on the same task of missing link prediction with 20%\\nheld-out missing data [11]. Performance of our DMMG on these same networks under the same\\nconditions is 0.916 for NIPS and 0.976 for INFOCOM, which is a strong improvement over LFP.\\n\\nTask 2: Future network forecasting. Here we are given a dynamic network up to time Tobs and\\nthe goal is to predict the network at the next time Tobs + 1. We follow the experimental protocol\\ndescribed in [4, 11]: We train the models on \\ufb01rst Tobs networks, \\ufb01x the parameters, and then for\\neach model we run MCMC sampling one time step into the future. For each model and network,\\nwe obtain 400 samples with 10 different MCMC chains, resulting in 400K network samples. These\\nnetwork samples provide a probability distribution over links at time Tobs + 1.\\n\\nTable 2 shows performance averaged over different Tobs values ranging from 3 to T -1. Overall,\\nDMMG generally exhibits the best performance, but performance results seem to depend on the\\ndataset. DMMG performs the best at 0.001 signi\\ufb01cance level in terms of AUC and F1 for the NIPS\\ndataset, and at 0.05 level for the INFOCOM dataset. While DMMG improves performance on AUC\\n\\n7\\n\\n\\fModel\\n\\nNaive\\nLFRM\\nDRIFT\\n\\nTestLL\\n\\n-547\\n-356\\n\\u2212148\\n\\nDMMG\\n\\n-170\\n\\nNIPS\\nAUC\\n\\n0.524\\n0.398\\n0.672\\n0.732\\n\\nF1\\n\\n0.130\\n0.011\\n0.084\\n0.196\\n\\nTestLL\\n\\n-3248\\n-1680\\n\\u22121324\\n\\nDBLP\\nAUC\\n0.668\\n0.492\\n0.650\\n\\n-1347\\n\\n0.652\\n\\nINFOCOM\\n\\nF1\\n\\nTestLL\\n\\nAUC\\n\\nF1\\n\\n0.243\\n0.024\\n0.122\\n0.245\\n\\n-774\\n-760\\n-661\\n\\n\\u2212625\\n\\n0.673\\n0.640\\n0.782\\n0.804\\n\\n0.270\\n0.248\\n0.381\\n0.392\\n\\nTable 2: Future network forecasting. DMMG performs best on NIPS and INFOCOM while results on DBLP\\nare mixed.\\n\\nhaldir\\ngandalf\\nmerry\\nfrodo\\nsam\\ngollum\\npippin\\naragorn\\nlegolas\\ngimli\\nsaruman\\neowyn\\neomer\\ntheoden\\ngrima\\nhama\\nfaramir\\narwen\\nelrond\\ngaladriel\\nmadril\\n\\nhaldir\\ngandalf\\nmerry\\nfrodo\\nsam\\ngollum\\npippin\\naragorn\\nlegolas\\ngimli\\nsaruman\\neowyn\\neomer\\ntheoden\\ngrima\\nhama\\nfaramir\\narwen\\nelrond\\ngaladriel\\nmadril\\n\\nhaldir\\ngandalf\\nmerry\\nfrodo\\nsam\\ngollum\\npippin\\naragorn\\nlegolas\\ngimli\\nsaruman\\neowyn\\neomer\\ntheoden\\ngrima\\nhama\\nfaramir\\narwen\\nelrond\\ngaladriel\\nmadril\\n\\n 1\\n\\n 2\\n\\n 3\\n\\n 4\\n\\n 5\\n\\n 1\\n\\n 2\\n\\n 3\\n\\n 4\\n\\n 5\\n\\n 1\\n\\n 2\\n\\n 3\\n\\n 4\\n\\n 5\\n\\n(a) Group 1\\n\\n(b) Group 2\\n\\n(c) Group 3\\n\\nFigure 3: Group arrival and departure dynamics of different characters in the Lord of the Rings. Dark areas in\\nthe plots correspond to a give node\\u2019s (y-axis) membership to each group over time (x-axis)\\n\\n.\\n\\n(9%) and F1 (133%), DRIFT achieves the best log-likelihood on the NIPS dataset. In light of our\\nprevious observations, we conjecture that this is due to change in network edge density between\\ndifferent snapshots. On the DBLP dataset, DRIFT gives the best log-likelihood, the naive model\\nperforms best in terms of AUC, and DMMG is the best on F1 score. However, in all cases of DBLP\\ndataset, the differences are not statistically signi\\ufb01cant. Overall, DMMG performs the best on NIPS\\nand INFOCOM and provides comparable performance on DBLP.\\n\\nTask 3: Case study of \\u201cThe Lord of the Rings: The Two Towers\\u201d social network. Last, we also\\ninvestigate groups identi\\ufb01ed by our model on a dynamic social network of characters in a movie,\\nThe Lord of the Rings: The Two Towers. Based on the transcript of the movie we created a dynamic\\nsocial network on 21 characters and T =5 time epochs, where we connect a pair of characters if they\\nco-appear inside some time window.\\n\\nWe \\ufb01t our model to this network and examine the results in Figure 3. Our model identi\\ufb01ed three\\ndynamic groups, which all nicely correspond to the Lord of the Rings storyline. For example,\\nthe core of Group 1 corresponds to Aragorn, elf Legolas, dwarf Gimli, and people in Rohan who\\nin the end all \\ufb01ght against the Orcs. Similarly, Group 2 corresponds to hobbits Sam, Frodo and\\nGollum on their mission to destroy the ring in Mordor, and are later joined by Faramir and ranger\\nMadril. Interestingly, Group 3 evolving around Merry and Pippin only forms at t=2 when they start\\ntheir journey with Treebeard and later \\ufb01ght against wizard Saruman. While the \\ufb01ght occurs in two\\nseparate places we \\ufb01nd that some scenes are not distinguishable, so it looks as if Merry and Pippin\\nfought together with Rohan\\u2019s army against Saruman\\u2019s army.\\n\\nAcknowledgments\\n\\nWe thank Creighton Heaukulani and Zoubin Ghahramani for sharing data and code. This research\\nhas been supported in part by NSF IIS-1016909, CNS-1010921, IIS-1149837, IIS-1159679, IARPA\\nAFRL FA8650-10-C-7058, Okawa Foundation, Docomo, Boeing, Allyes, Volkswagen, Intel, Alfred\\nP. Sloan Fellowship and the Microsoft Faculty Fellowship.\\n\\nReferences\\n\\n[1] E. M. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing. Mixed membership stochastic blockmodels.\\n\\nJMLR, 9, 2008.\\n\\n[2] L. Backstrom and J. Leskovec. Supervised random walks: Predicting and recommending links in social\\n\\nnetworks. In WSDM, 2011.\\n\\n8\\n\\n\\f[3] S. Duane, A. Kennedy, B. J. Pendleton, and D. Roweth. Hybrid monte carlo. Physics Letter B,\\n\\n195(2):216\\u2013222, 1987.\\n\\n[4] J. Foulds, A. U. Asuncion, C. DuBois, C. T. Butts, and P. Smyth. A dynamic relational in\\ufb01nite feature\\n\\nmodel for longitudinal social networks. In AISTATS, 2011.\\n\\n[5] W. Fu, L. Song, and E. P. Xing. Dynamic mixed membership blockmodel for evolving networks.\\n\\nIn\\n\\nICML, 2009.\\n\\n[6] J. V. Gael, Y. W. Teh, , and Z. Ghahramani. The in\\ufb01nite factorial hidden markov model. In NIPS, 2009.\\n\\n[7] S. J. Gershman, P. I. Frazier, and D. M. Blei. Distance dependent in\\ufb01nite latent feature models.\\n\\narXiv:1110.5454, 2012.\\n\\n[8] Z. Ghahramani and M. I. Jordan. Factorial hidden markov models. Machine Learning, 29(2-3):245\\u2013273,\\n\\n1997.\\n\\n[9] F. Guo, S. Hanneke, W. Fu, and E. P. Xing. Recovering temporally rewiring networks: a model-based\\n\\napproach. In ICML, 2007.\\n\\n[10] S. Hanneke, W. Fu, and E. P. Xing. Discrete temporal models of social networks. Electron. J. Statist.,\\n\\n4:585\\u2013605, 2010.\\n\\n[11] C. Heaukulani and Z. Ghahramani. Dynamic probabilistic models for latent feature propagation in social\\n\\nnetworks. In ICML, 2013.\\n\\n[12] Q. Ho, L. Song, and E. P. Xing. Evolving cluster mixed-membership blockmodel for time-varying net-\\n\\nworks. In AISTATS, 2011.\\n\\n[13] P. D. Hoff, A. E. Raftery, and M. S. Handcock. Latent space approaches to social network analysis. JASA,\\n\\n97(460):1090 \\u2013 1098, 2002.\\n\\n[14] K. Ishiguro, T. Iwata, N. Ueda, and J. Tenenbaum. Dynamic in\\ufb01nite relational model for time-varying\\n\\nrelational data analysis. In NIPS, 2010.\\n\\n[15] S. Kairam, D. Wang, and J. Leskovec. The life and death of online groups: Predicting group growth and\\n\\nlongevity. In WSDM, 2012.\\n\\n[16] M. Kim and J. Leskovec. Modeling social networks with node attributes using the multiplicative attribute\\n\\ngraph model. In UAI, 2011.\\n\\n[17] M. Kim and J. Leskovec. Latent multi-group membership graph model. In ICML, 2012.\\n\\n[18] M. Kim and J. Leskovec. Multiplicative attribute graph model of real-world networks. Internet Mathe-\\n\\nmatics, 8(1-2):113\\u2013160, 2012.\\n\\n[19] M. Kim and J. Leskovec. Nonparametric multi-group membership model for dynamic networks.\\n\\narXiv:1311.2079, 2013.\\n\\n[20] J. R. Lloyd, P. Orbanz, Z. Ghahramani, and D. M. Roy. Random function priors for exchangeable arrays\\n\\nwith applications to graphs and relational data. In NIPS, 2012.\\n\\n[21] K. T. Miller, T. L. Grifths, and M. I. Jordan. Nonparametric latent feature models for link prediction. In\\n\\nNIPS, 2009.\\n\\n[22] M. M\\u00f8rup, M. N. Schmidt, and L. K. Hansen.\\n\\nIn\\ufb01nite multiple membership relational modeling for\\n\\ncomplex networks. In MLSP, 2011.\\n\\n[23] K. Palla, D. A. Knowles, and Z. Ghahramani. An in\\ufb01nite latent attribute model for network data.\\n\\nIn\\n\\nICML, 2012.\\n\\n[24] P. Sarkar and A. W. Moore. Dynamic social network analysis using latent space models. In NIPS, 2005.\\n\\n[25] J. Scott, R. Gass, J. Crowcroft, P. Hui, C. Diot, and A. Chaintreau. CRAWDAD data set cambridge/haggle\\n\\n(v. 2009-05-29), May 2009.\\n\\n[26] S. L. Scott. Bayesian methods for hidden markov models. JASA, 97(457):337\\u2013351, 2002.\\n\\n[27] T. A. B. Snijders, G. G. van de Bunt, and C. E. G. Steglich. Introduction to stochastic actor-based models\\n\\nfor network dynamics. Social Networks, 32(1):44\\u201360, 2010.\\n\\n[28] J. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su. Arnetminer: Extraction and mining of academic\\n\\nsocial networks. In KDD\\u201908, 2008.\\n\\n[29] J. Yang and J. Leskovec. Community-af\\ufb01liation graph model for overlapping community detection. In\\n\\nICDM, 2012.\\n\\n9\\n\\n\\f\",\n          \"Tangent Prop - A formalism for specifying \\nselected invariances in an adaptive network \\n\\nPatrice Simard \\n\\nAT&T Bell Laboratories \\n101 Crawford Corner Rd \\n\\nHolmdel, NJ 07733 \\n\\nBernard Victorri \\nUniversite de Caen \\nCaen 14032 Cedex \\n\\nFrance \\n\\nYann Le Cun \\n\\nAT&T Bell Laboratories \\n101 Crawford Corner Rd \\n\\nHolmdel, NJ 07733 \\n\\nJohn Denker \\n\\nAT&T Bell Laboratories \\n101 Crawford Corner Rd \\n\\nHolmdel, NJ 07733 \\n\\nAbstract \\n\\nIn many machine learning applications, one has access, not only to training \\ndata, but also to some high-level a priori knowledge about the desired be(cid:173)\\nhavior of the system. For example, it is known in advance that the output \\nof a character recognizer should be invariant with respect to small spa(cid:173)\\ntial distortions of the input images (translations, rotations, scale changes, \\netcetera). \\nWe have implemented a scheme that allows a network to learn the deriva(cid:173)\\ntive of its outputs with respect to distortion operators of our choosing. \\nThis not only reduces the learning time and the amount of training data, \\nbut also provides a powerful language for specifying what generalizations \\nwe wish the network to perform. \\n\\n1 \\n\\nINTRODUCTION \\n\\nIn machine learning, one very often knows more about the function to be learned \\nthan just the training data. An interesting case is when certain directional deriva(cid:173)\\ntives of the desired function are known at certain points. For example, an image \\n895 \\n\\n\\f896 \\n\\nSimard, Victorri, Le Cun, and Denker \\n\\nFigure 1: Top: Small rotations of an original digital image of the digit \\\"3\\\" (center). \\nMiddle: Representation of the effect of the rotation in the input vector space space \\n(assuming there are only 3 pixels). Bottom: Images obtained by moving along the \\ntangent to the transformation curve for the same original digital image (middle). \\n\\nrecognition system might need to be invariant with respect to small distortions of \\nthe input image such as translations, rotations, scalings, etc.; a speech recognition \\nsystem n.ight need to be invariant to time distortions or pitch shifts. \\nIn other \\nwords, the derivative of the system's output should be equal to zero when the input \\nis transformed in certain ways. \\n\\nGiven a large amount of training data and unlimited training time, the system \\ncould learn these invariances from the data alone, but this is often infeasible. The \\nlimitation on data can be overcome by training the system with additional data \\nobtained by distorting (translating, rotating, etc.) \\nthe original patterns (Baird, \\n1990). The top of Fig. 1 shows artificial data generated by rotating a digital image of \\nthe digit \\\"3\\\" (with the original in the center). This procedure, called the \\\"distortion \\nmodel\\\" , has two drawbacks. First, the user must choose the magnitude of distortion \\nand how many instances should be generated. Second, and more importantly, the \\ndistorted data is highly correlated with the original data. This makes traditional \\nlearning algorithms such as back propagation very inefficient. The distorted data \\ncarries only a very small incremental amount of information, since the distorted \\npatterns are not very different from the original ones. It may not be possible to \\nadjust the learning system so that learning the invariances proceeds at a reasonable \\nrate while learning the original points is non-divergent. \\n\\nThe key idea in this paper is that it is possible to directly learn the effect on \\nthe output of distorting the input, independently from learning the undistorted \\n\\n\\fTangent Prop-A formalism for specifying selected invariances in an adaptive network \\n\\n897 \\n\\nF(x) \\n\\nF(x) \\n\\nx1 \\n\\nx2 \\n\\nx3 \\n\\nx4 \\n\\nx \\n\\nx1 \\n\\nx2 \\n\\nx3 \\n\\nx4 \\n\\nx \\n\\nFigure 2: Learning a given function (solid line) from a limited set of example (Xl \\nto X4). The fitted curves are shown in dotted line. Top: The only constraint is that \\nthe fitted curve goes through the examples. Bottom: The fitted curves not only \\ngoes through each examples but also its derivatives evaluated at the examples agree \\nwith the derivatives of the given function. \\n\\npatterns. When a pattern P is transformed (e.g. rotated) with a transformation \\ns that depends on one parameter a (e.g. the angle of the rotation), the set of all \\nthe transformed patterns S(P) = {sea, P) Va} is a one dimensional curve in the \\nvector space of the inputs (see Fig. 1). In certain cases, such as rotations of digital \\nimages, this curve must be made continuous using smoothing techniques, as will be \\nshown below. When the set of transformations is parameterized by n parameters \\nai (rotation, translation, scaling, etc.), S(P) is a manifold of at most n dimensions. \\nThe patterns in S(P) that are obtained through small transformations of P, i.e. \\nthe part of S( P) that is close to P, can be approximated by a plane tangent to \\nthe manifold S(P) at point P. Small transformations of P can be obtained by \\nadding to P a linear combination of vectors that span the tangent plane (tangent \\nvectors). The images at the bottom of Fig. 1 were obtained by that procedure. \\nMore importantly, the tangent vectors can be used to specify high order constraints \\non the function to be learned, as explained below. \\n\\nTo illustrate the method, consider the problem of learning a single-valued function \\nF from a limited set of examples. Fig. 2 (left) represents a simple case where the \\ndesired function F (solid line) is to be approximated by a function G (dotted line) \\nfrom four examples {(Xi, F(Xi))}i=1,2,3,4. As exemplified in the picture, the fitted \\nfunction G largely disagrees with the desired function F between the examples. If \\nthe functions F and G are assumed to be differentiable (which is generally the case), \\nthe approximation G can be greatly improved by requiring that G's derivatives \\nevaluated at the points {xd are equal to the derivatives of F at the same points \\n(Fig. 2 right). This result can be extended to multidimensional inputs. In this case, \\nwe can impose the equality of the derivatives of F and G in certain directions, not \\nnecessarily in all directions of the input space. \\nSuch constraints find immediate use in traditional learning problems. It is often the \\ncase that a priori knowledge is available on how the desired function varies with \\n\\n\\f898 \\n\\nSimard, Victorri, Le Cun, and Denker \\n\\npattern P \\n\\npattern P \\nrotated by ex \\n\\n-\\n\\ntangent \\nvector \\n\\n--\\n\\nFigure 3: How to compute a tangent vector for a given transformation (in this case \\na rotation). \\n\\nrespect to some transformations of the input. It is straightforward to derive the \\ncorresponding constraint on the directional derivatives of the fitted function G in \\nthe directions of the transformations (previously named tangent vectors). Typical \\nexamples can be found in pattern recognition where the desired classification func(cid:173)\\ntion is known to be invariant with respect to some transformation of the input such \\nas translation, rotation, scaling, etc., in other words, the directional derivatives of \\nthe classification function in the directions of these transformations is zero. \\n\\n2 \\n\\nIMPLEMENTATION \\n\\nThe implementation can be divided into two parts. The first part consists in com(cid:173)\\nputing the tangent vectors. This part is independent from the learning algorithm \\nused subsequently. The second part consists in modifying the learning algorithm \\n(for instance backprop) to incorporate the information about the tangent vectors. \\nPart I: Let x be an input pattern and s be a transformation operator acting \\non the input space and depending on a parameter a. If s is a rotation operator \\nfor instance, then s( a, x) denotes the input x rotated by the angle a. We will \\nrequire that the transformation operator s be differentiable with respect to a and \\nx, and that s(O, x) = x. The tangent vector is by definition 8s(a, x)/8a. It can be \\napproximated by a finite difference, as shown in Fig. 3. In the figure, the input space \\nis a 16 by 16 pixel image and the patterns are images of handwritten digits. The \\ntransformations considered are rotations of the digit images. The tangent vector \\nis obtained in two steps. First the image is rotated by an infinitesimal amount a. \\nThis is done by computing the rotated coordinates of each pixel and interpolating \\nthe gray level values at the new coordinates. This operation can be advantageously \\ncombined with some smoothing using a convolution. A convolution with a Gaussian \\nprovides an efficient interpolation scheme in O(nm) multiply-adds, where nand m \\nare the (gaussian) kernel and image sizes respectively. The next step is to subtract \\n(pixel by pixel) the rotated image from the original image and to divide the result \\n\\n\\fTangent Prop-A formalism for specifying selected invariances in an adaptive network \\n\\n899 \\n\\nby the scalar 0 (see Fig. 3). If Ie types of transformations are considered, there \\nwill be Ie different tangent vectors per pattern. For most algorithms, these do not \\nrequire any storage space since they can be generated as needed from the original \\npattern at negligible cost. \\nPart IT: Tangent prop is an extension of the backpropagation algorithm, allowing \\nit to learn directional derivatives. Other algorithms such as radial basis functions \\ncan be extended in a similar fashion. \\n\\nTo implement our idea, we will modify the usual weight-update rule: \\nis replaced with ~w = -7] ow (E + J.tEr) \\n\\noE \\n~w = -7] ow \\n\\n0 \\n\\n(1) \\n\\nwhere 7] is the learning rate, E the usual objective function, Er an additional objec(cid:173)\\ntive function (a regularizer) that measures the discrepancy between the actual and \\ndesired directional derivatives in the directions of some selected transformations, \\nand J.t is a weighting coefficient. \\nLet x be an input pattern, y = G(x) be the input-output function of the network. \\nThe regularizer Er is of the form \\n\\nwhere Er(x) is \\n\\nEr(x) \\n\\n:e e trainingset \\n\\n(2) \\n\\nHere, Ki(x) is the desired directional derivative of G in the direction induced by \\ntransformation Si applied to pattern x. The second term in the norm symbol is the \\nactual directional derivative, which can be rewritten as \\n\\n= G'{x). OSi(O, x) \\n\\n00 \\n\\n0=0 \\n\\n0=0 \\n\\nwhere G'(x) is the Jacobian of G for pattern x, and OSi(O, x)Joo is the tangent \\nvector associated to transformation Si as described in Part I. Multiplying the tangent \\nvector by the Jacobian involves one forward propagation through a \\\"linearized\\\" \\nversion of the network. In the special case where local invariance with respect to \\nthe Si'S is desired, Ki(x) is simply set to o. \\nComposition of transformations: The theory of Lie groups (Gilmore, 1974) \\nensures that compositions of local (small) transformations Si correspond to linear \\ncombinations of the corresponding tangent vectors (the local transformations Si \\nhave a structure of Lie algebra). Consequently, if Er{x) = 0 is verified, the network \\nderivative in the direction of a linear combination of the tangent vectors is equal \\nto the same linear combination of the desired derivatives. In other words if the \\nnetwork is successfully trained to be locally invariant with respect to, say, horizontal \\ntranslation and vertical translations, it will be invariant with respect to compositions \\nthereof. \\nWe have derived and implemented an efficient algorithm, \\\"tangent prop\\\" , for per(cid:173)\\nforming the weight update (Eq. 1). It is analogous to ordinary backpropagation, \\n\\n\\f900 \\n\\nSimard, Victorri, Le Cun, and Denker \\n\\nW'+l \\n\\nIti \\n\\nW l+1 \\n\\nIti \\n\\ne: l \\n\\nb'.-l , \\n\\nx\\u00b7 , \\n'-I \\n\\nNetwork \\n\\nj3J-1 \\n\\ne;-I \\nJacobian nework \\n\\nFigure 4: forward propagated variables (a, x, a, e), and backward propagated vari(cid:173)\\nables (b, y, p, t/J) in the regular network (roman symbols) and the Jacobian (lin(cid:173)\\nearized) network (greek symbols) \\n\\nbut in addition to propagating neuron activations, it also propagates the tangent \\nvectors. The equations can be easily derived from Fig. 4. \\nForward propagation: \\n\\na~ = ~ wL x'.-l \\nI, , \\n\\u2022 \\n\\nL...J \\ni \\n\\nx~ = u(aD \\n\\nTangent forward propagation: \\n\\n, _ ~ , ~'-1 \\nai - L...J wW\\\"i \\n\\ni \\n\\ne! = u'(a~)a~ \\n\\nTangent gradient backpropagation: \\n\\n(31 - ~ w'+1.I.l+1 \\ni - L...J \\nIt \\n\\nIti \\u00a5lit \\n\\nGradient backpropagation: \\n\\nb' - ~ w1+ 1yl+1 \\ni - L...J \\nIt \\n\\nIti \\n\\nIt \\n\\nWeight update: \\n\\n8[E(W, Up) + I'Er (W, Up, Tp)] _ 1-1 , + ~'-l.I.' \\n\\u00a5Ii \\n\\n- Xi Yi \\n\\nI'\\\\oi \\n\\nw\\u00b7\\u00b7 I, \\n8 ' \\n\\n(3) \\n\\n(4) \\n\\n(5) \\n\\n(6) \\n\\n(7) \\n\\n\\fTangent Prop--A formalism for specifying selected invariances in an adaptive network \\n\\n901 \\n\\n60 \\n\\n50 \\n\\n%Erroron \\nthe test set \\n\\n20 \\n\\n10 \\n\\n160 \\n\\n320 \\n\\nTraining set size \\n\\nFigure 5: Generalization performance curve as a function of the training set size for \\nthe tangent prop and the backprop algorithms \\n\\nThe regularization parameter jJ is tremendously important, because it determines \\nthe tradeoff between minimizing the usual objective function and minimizing the \\ndirectional derivative error. \\n\\n3 RESULTS \\n\\nTwo experiments illustrate the advantages of tangent prop. The first experiment \\nis a classification task, using a small (linearly separable) set of 480 binarized hand(cid:173)\\nwritten digit. The training sets consist of 10, 20, 40, 80, 160 or 320 patterns, and \\nthe training set contains the remaining 160 patterns. The patterns are smoothed \\nusing a gaussian kernel with standard deviation of one half pixel. For each of the \\ntraining set patterns, the tangent vectors for horizontal and vertical translation \\nare computed. The network has two hidden layers with locally connected shared \\nweights, and one output layer with 10 units (5194 connections, 1060 free parame(cid:173)\\nters) (Le Cun, 1989). The generalization performance as a function of the training \\nset size for traditional backprop and tangent prop are compared in Fig. 5. We have \\nconducted additional experiments in which we implemented not only translations \\nbut also rotations, expansions and hyperbolic deformations. This set of 6 gener(cid:173)\\nators is a basis for all linear transformations of coordinates for two dimensional \\nimages. It is straightforward to implement other generators including gray-Ievel(cid:173)\\nshifting, \\\"smooth\\\" segmentation, local continuous coordinate transformations and \\nindependent image segment transformations. \\n\\nThe next experiment is designed to show that in applications where data is highly \\n\\n\\f902 \\n\\nSimard, Victorri, Le Cun, and Denker \\n\\nAv\\\"ge NMSE VI 1ge \\n\\nA-. NMSE VI. \\n\\n0.15 \\n\\n0.1 \\n\\n.15 \\n\\n.1 \\n\\no \\no 1000 2000 3000 4000 5000 6000 7000 8000 0000 10000 \\n\\noL-~~==~~=;~==+=~~~ \\n1000 2000 3000 4000 5000 6000 7000 8000 0000 10000 \\n0 \\n\\n-\\n\\n\\\" \\n\\n..... \\n\\n15 \\n\\no \\n\\n-0.5 \\n\\n-1 \\n\\n..... \\n\\n15 -\\n\\n\\\" \\n\\n0 \\n\\n-.5 \\n\\n-1 \\n\\n-1 .5 +--_+_-_--+_-_+_-_-_ \\n\\n-1.5 +--_+_-_--+--_+_-_-__t \\n\\n-1 .5 \\n\\n-1 \\n\\n1.5 \\n\\n-1.5 \\n\\n-1 \\n\\n0 \\n\\n0.5 \\n\\n-0.5 \\nDistortion model \\n\\no \\n\\n.5 \\n\\n- .5 \\nTangent prop \\n\\n1.5 \\n\\nFigure 6: Comparison of the distortion model (left column) and tangent prop (right \\ncolumn). The top row gives the learning curves (error versus number of sweeps \\nthrough the training set). The bottom row gives the final input-output function of \\nthe network; the dashed line is the result for unadorned back prop. \\n\\n\\fTangent Prop-A formalism for specifying selected invariances in an adaptive network \\n\\n903 \\n\\ncorrelated, tangent prop yields a large speed advantage. Since the distortion model \\nimplies adding lots of highly correlated data, the advantage of tangent prop over \\nthe distortion model becomes clear. \\nThe task is to approximate a function that has plateaus at three locations. We want \\nto enforce local invariance near each of the training points (Fig. 6, bottom). The \\nnetwork has one input unit, 20 hidden units and one output unit. Two strategies are \\npossible: either generate a small set of training point covering each of the plateaus \\n(open squares on Fig. 6 bottom), or generate one training point for each plateau \\n(closed squares), and enforce local invariance around them (by setting the desired \\nderivative to 0). The training set of the former method is used as a measure the \\nperformance for both methods. All parameters were adjusted for approximately \\noptimal performance in all cases. The learning curves for both models are shown in \\nFig. 6 (top). Each sweep through the training set for tangent prop is a little faster \\nsince it requires only 6 forward propagations, while it requires 9 in the distortion \\nmodel. As can be seen, stable performance is achieved after 1300 sweeps for the \\ntangent prop, versus 8000 for the distortion model. The overall speedup is therefore \\nabout 10. \\nTangent prop in this example can take advantage of a very large regularization term. \\nThe distortion model is at a disadvantage because the only parameter that effec(cid:173)\\ntively controls the amount of regularization is the magnitude of the distortions, and \\nthis cannot be increased to large values because the right answer is only invariant \\nunder small distortions. \\n\\n4 CONCLUSIONS \\n\\nWhen a priori information about invariances exists, this information must be made \\navailable to the adaptive system. There are several ways of doing this, including the \\ndistortion model and tangent prop. The latter may be much more efficient in some \\napplications, and it permits separate control of the emphasis and learning rate for \\nthe invariances, relative to the original training data points. Training a system to \\nhave zero derivatives in some directions is a powerful tool to express invariances to \\ntransformations of our choosing. Tests of this procedure on large-scale applications \\n(handwritten zipcode recognition) are in progress. \\n\\nReferences \\n\\nBaird, H. S. (1990). Document Image Defect Models. In IAPR 1990 Workshop on \\n\\nSytactic and Structural Pattern Recognition, pages 38-46, Murray Hill, NJ. \\n\\nGilmore, R. (1974). Lie Groups, Lie Algebras and some of their Applications. Wiley, \\n\\nNew York. \\n\\nLe Cun, Y. (1989) . Generalization and Network Design Strategies. In Pfeifer, R., \\nSchreter, Z., Fogelman, F., and Steels, L., editors, Connectionism in Perspec(cid:173)\\ntive, Zurich, Switzerland. Elsevier. an extended version was published as a \\ntechnical report of the University of Toronto. \\n\\n\\f\",\n          \"Minimizing  Statistical Bias with Queries \\n\\nDavid A.  Cohn \\n\\nAdaptive Systems Group \\n\\nHarlequin,  Inc. \\n\\nOne  Cambridge Center \\nCambridge,  MA  02142 \\ncOhnCharlequin.com \\n\\nAbstract \\n\\nI describe  a  querying criterion that attempts to minimize the error \\nof a  learner  by  minimizing its estimated squared  bias.  I  describe \\nexperiments  with  locally-weighted  regression  on  two  simple prob(cid:173)\\nlems,  and observe  that this  \\\"bias-only\\\"  approach  outperforms the \\nmore  common  \\\"variance-only\\\"  exploration  approach,  even  in  the \\npresence  of noise. \\n\\n1 \\n\\nINTRODUCTION \\n\\nIn recent  years, there has been an explosion of interest in \\\"active\\\"  machine learning \\nsystems.  These  are  learning  systems  that  make  queries,  or  perform  experiments \\nto  gather data that  are expected  to maximize performance.  When  compared with \\n\\\"passive\\\"  learning  systems,  which  accept  given,  or  randomly  drawn  data,  active \\nlearners have demonstrated significant decreases  in the amount of data required  to \\nachieve equivalent performance.  In industrial applications,  where  each  experiment \\nmay take  days  to  perform  and  cost  thousands  of dollars,  a  method  for  optimally \\nselecting  these  points would offer enormous savings in time and  money. \\nAn  active  learning system  will  typically attempt to select  data that  will  minimize \\nits  predictive  error.  This  error  can  be  decomposed  into  bias  and  variance  terms. \\nMost  research  in selecting  optimal actions or  queries  has  assumed  that the learner \\nis  approximately unbiased,  and that to minimize learner error,  variance is  the only \\nthing  to  minimize  (e.g.  Fedorov  [1972]'  MacKay  [1992]'  Cohn  [1996],  Cohn  et  al., \\n[1996],  Paass  [1995]).  In  practice,  however,  there  are very  few  problems for  which \\nwe have unbiased learners.  Frequently, bias constitutes a large portion of a learner's \\nerror;  if the learner is deterministic and the data are noise-free, then bias is the  only \\nsource  of error.  Note  that the bias  term here  is  a  statistical bias,  distinct from  the \\ninductive  bias  discussed  in some  machine  learning  research  [Dietterich  and  Kong, \\n1995]. \\n\\n\\f418 \\n\\nD.A. Cohn \\n\\nIn this paper I describe an algorithm which selects actions/ queries designed to mini(cid:173)\\nmize the bias of a locally weighted regression-based  learner.  Empirically, \\\"variance(cid:173)\\nminimizing\\\" strategies which ignore bias seem to perform well, even in cases  where, \\nstrictly speaking,  there is  no  variance  to  minimize.  In  the  tasks  considered  in  this \\npaper,  the  bias-minimizing strategy  consistently  outperforms  variance  minimiza(cid:173)\\ntion, even in  the presence  of noise. \\n\\n1.1  BIAS  AND  VARIANCE \\n\\nLet us  begin  by defining P(x, y)  to be the unknown joint distribution over  x and y, \\nand  P( x)  to  be  the  known  marginal distribution  of x  (commonly called  the  input \\ndistribution).  We  denote  the  learner's  output  on input  x,  given  training set  D  as \\ny(x; D).  We  can  then  write the expected  error of the learner as \\n\\n1 E  [(y(x;D) - y(x))2Ix] P(x)dx, \\n\\n(1) \\n\\nwhere E[\\u00b7] denotes the expectation over P and over training sets D.  The expectation \\ninside the integral may be  decomposed as follows  (Geman et al. , 1992): \\n\\nE  [(y(x;D) - y(x))2Ix] \\n\\nE  [(y(x) - E[ylx]?] \\n\\n(2) \\n\\n+ (Ev [y(x; D)] - E[ylx])2 \\n\\n+Ev [(y(x;D) - Ev[y(x;D)])2] \\n\\nwhere Ev [.] denotes the expectation over training sets.  The first  term in Equation 2 \\nis the variance of y given x - it is the noise in the distribution, and does  not depend \\non our learner or how the training data are chosen.  The second term is the learner's \\nsquared bias, and the third is its variance; these last two terms comprise the expected \\nsquared error of the learner  with  respect  to the regression  function  E[Ylx]. \\nMost  research  in  active  learning  assumes  that  the  second  term  of Equation  2  is \\napproximately zero,  that  is,  that  the  learner  is  unbiased.  If this  is  the  case,  then \\none may concentrate on selecting data so  as to minimize the variance of the learner. \\nAlthough this  \\\"all-variance\\\" approach is optimal when the learner is  unbiased, truly \\nunbiased  learners  are  rare.  Even  when  the  learner's  representation  class  is  able \\nto  match  the  target  function  exactly,  bias is  generally  introduced  by  the  learning \\nalgorithm  and  learning  parameters.  From  the  Bayesian  perspective,  a  learner  is \\nonly unbiased  if its  priors are  exactly  correct. \\nThe optimal choice  of query would,  of course, minimize  both  bias and variance,  but \\nI leave that for future work.  For the purposes of this paper, I will only be concerned \\nwith  selecting  queries  that  are  expected  to  minimize  learner  bias.  This  approach \\nis  justified  in  cases  where  noise  is  believed  to  be  only  a  small  component  of the \\nlearner's  error.  If the  learner  is  deterministic  and  there  is  no  noise,  then  strictly \\nspeaking, there  is  no error  due  to  variance -\\nall  the error  must be  due  to learner \\nbias.  In cases with non-determinism or noise, all-bias minimization, like all-variance \\nminimization, becomes  an approximation of the optimal approach. \\n\\nThe learning model discussed  in this paper is  a  form of locally  weighted  regression \\n(LWR)  [Cleveland et  al.,  1988],  which  has  been  used  in  difficult  machine  learning \\ntasks,  notably  the  \\\"robot  juggler\\\"  of Schaal  and  Atkeson  [1994].  Previous  work \\n[Cohn et al.,  1996]  discussed  all-variance query selection for  LWR; in the remainder \\nof this paper, I describe  a method for  performing all-bias query selection.  Section 2 \\ndescribes the criterion that must be optimized for all-bias query selection.  Section 3 \\ndescribes  the  locally  weighted  regression  learner  used  in  this  paper  and  describes \\n\\n\\fMinimizing Statistical Bias with Queries \\n\\n419 \\n\\nhow  the  all-bias criterion  may be  computed for  it .  Section  4  describes  the  results \\nof experiments using this criterion on several simple domains.  Directions for future \\nwork  are discussed  in  Section 5. \\n\\n2  ALL-BIAS  QUERY  SELECTION \\n\\nLet  us  assume for  the moment that we  have  a source of noise-free examples (Xi, Yi) \\nand  a  deterministic learner  which,  given  input  X,  outputs estimate Y(X).l  Let  us \\nalso  assume  that  we  have  an  accurate estimate of the  bias  of y which  can  be  used \\nto estimate  the  true  function  y(x)  =  y(x)  - bias(x).  We  will  break  these  rather \\nstrong assumptions of noise-free examples and accurate bias estimates in Section 4, \\nbut they  are useful for  deriving  the theoretical  approach described  below. \\n\\nGiven  an  accurate  bias estimate,  we  must force  the  biased  estimator into the  best \\napproximation of y(x)  with  the fewest  number of examples.  This,  in effect,  trans(cid:173)\\nforms  the  query  selection  problem  into  an  example filter  problem  similar  to  that \\nstudied  by  Plutowski  and  White  [1993]  for  neural  networks.  Below,  I  derive  this \\ncriterion for  estimating the change  in error at  X  given  a  new  queried  example at x. \\nSince  we  have  (temporarily)  assumed  a  deterministic  learner  and  noise-free  data, \\nthe expected  error in  Equation 2 simplifies to: \\n\\nE  [(Y( X; 'D)  - y( x))2Ix, 'D] \\n\\n(Y(x; 'D)  - y(x))2 \\n\\n(3) \\n\\nWe  want to select  a new  x such that when we  add (x, f)),  the resulting squared bias \\nis  minimized: \\n\\n(Y'  - y? ==  (y(x; 'D U (x, f)))  - y(x))2 . \\n\\n(4) \\nI will, for the remainder of the paper, use the  \\\"'\\\"  to indicate estimates based on the \\ninitial training set  plus  the  additional example  (x, y).  To  minimize  Expression  4, \\nwe  need  to  compute  how  a  query  at  x will  change  the  learner's  bias  at  x.  If we \\nassume  that  we  know  the  input  distribution,2  then  we  can  integrate  this  change \\nover  the  entire  domain  (using  Monte  Carlo  procedures)  to  estimate  the  resulting \\naverage  change,  and select  a  x such  that  the  expected  squared  bias  is  minimized. \\nDefining bias ==  y - y and f:,.y  ==  y'  - y, we  can  write the new  squared  bias as: \\n\\nbias,2 \\n\\n(y'  - y)2  =  (Y + f:,.y  _ y)2 \\nf:,.y2  + 2f:,.y . bias + bias2 \\n\\n(5) \\nNote  that  since  bias  as  defined  here  is  independent  of x,  minimizing  the  bias  is \\nequivalent to minimizing f:,.y2  + 2f:,.y . bias. \\nThe estimate of bias'  tells  us  how much our bias will change for  a given x. We may \\noptimize this value over x in one of a number of ways.  In low dimensional spaces,  it \\nis often sufficient to consider a set of \\\"candidate\\\" x and select the one promising the \\nsmallest resulting  error.  In  higher  dimensional spaces,  it  is  often  more efficient  to \\nsearch  for  an optimal x with  a  response  surface  technique  [Box  and  Draper, 1987], \\nor hill climb on  abias,2 / ax. \\nEstimates  of bias  and  f:,.y  depend  on  the  specific  learning  model  being  used.  In \\nSection 3, I describe a locally weighted regression model, and show how differentiable \\nestimates of bias  and f:,.y  may be  computed for  it. \\n\\n1 For  clarity,  I  will  drop  the  argument  :z;  except  where  required  for  disambiguation.  I \\n\\nwill  also  denote only  the univariate  case;  the results  apply  in  higher  dimensions  as  well. \\n2This assumption is  contrary to the assumption norma.lly  made in some forms of learn(cid:173)\\n\\ning,  e.g.  PAC-learning,  but it is  appropriate in  many  domains. \\n\\n\\f420 \\n\\nD.  A.  Cohn \\n\\n2.1  AN  ASIDE:  WHY  NOT JUST USE Y - Mas? \\n\\nIf we  have  an accurate  bias estimate, it is  reasonable to ask  why  we  do  not simply \\nuse  the  corrected  y - C;;;S  as  our  predictor.  The  answer  has  two  parts,  the  first \\nof  which  is  that  for  most  learners,  there  are  no  perfect  bias  estimators  -\\nthey \\nintroduce their own  bias and  variance,  which  must  be  addressed  in data selection. \\nSecond,  we  can  define  a  composite learner Ye  ==  Y - C:;;;S.  Given  a random training \\nsample  then,  we  would  expect  Ye  to  outperform  y.  However,  there  is  no  obvious \\nway  to select  data for  this composite learner other than selecting  to maximize the \\nperformance  of its  two  components.  In  our  case,  the  second  component  (the  bias \\nestimate)  is  non-analytic,  which  leaves  us  selecting  data  so  as  to  maximize  the \\nperformance of the  first  component  (the uncorrected  estimator).  We  are  now  back \\nto  our  original  problem:  we  can  select  data so  as  to  minimize either  the  bias  or \\nvariance of the uncorrected  LWR-based learner.  Since the purpose of the correction \\nis to give an unbiased estimator, intuition suggests that variance minimization would \\nbe the more sensible route in this  case.  Empirically, this approach does  not appear \\nto yield  any  benefit  over  uncorrected  variance minimization (see  Figure  1). \\n\\n3  LOCALLY WEIGHTED REGRESSION \\n\\nThe type  of learner  I  consider here  is  a form  of locally weighted  regression  (LWR) \\nthat is  a slight variation on  the  LOESS  model of Cleveland et  al.  [1988]  (see  Cohn \\net al., [1996]  for details).  The LOESS  model performs a linear regression  on points \\nin  the  data set,  weighted  by  a  kernel  centered  at  x.  The kernel  shape  is  a  design \\nparameter:  the original LOESS  model uses  a  \\\"tricubic\\\"  kernel;  in my experiments \\nI  use  the more common Gaussian \\n\\nwhere Ie  is a smoothing parameter.  For brevity, I will drop the argument x for  hi(x), \\nand define  n  = 2:i  hi.  We  can then  write  the weighted  means and  covariances  as: \\n\\n\\\"\\\"  Xi \\n, \\nn \\n. \\n\\nJ.l:r;  = L..J hi - ,  \\nJ.ly  = L h,-, \\n\\nYi \\nn \\n\\n, \\n. \\n\\n\\\"\\\" \\n\\nU:r;y  =  L..J hi \\n\\n, \\n. \\n\\n(Xi  - X)(Yi  - J.ly) \\n\\nn \\n\\n. \\n\\nWe use these means and covariances to produce an estimate Y at the x  around which \\nthe kernel  is  centered,  with  a  confidence  term in  the form of a  variance estimate: \\n\\nIn  all the experiments  discussed  in  this paper,  the smoothing parameter Ie  was  set \\nso  as  to minimize u2. \\nThe  low  cost  of incorporating  new  training  examples  makes  this  form  of locally \\nweighted regression  appealing for  learning systems which must operate in real time, \\nor with time-varying target functions  (e.g.  [Schaal and Atkeson  1994]). \\n\\n\\fMinimizing Statistical Bias with Queries \\n\\n421 \\n\\nI \\n\\nI \\nY \\n\\n) \\n\\nA \\n\\nA \\n\\nA  I \\n\\nA \\n\\n3.1  COMPUTING D..y  FOR LWR \\nIf we  know  what  new  point  (x, y)  we're  going  to  add,  computing D..y  for  LWR  is \\nstraightforward.  Defining h as  the  weight  given to x,  and n as  n + h we  can write \\n~y  =  y  - y  =  J.L  + -\\n\\nx  - J.Lx \\n\\nh (Y  ___ J.Ly)  _  uxy (x _  J.Lx)  + (x _  n~x _  ~x) . nuXY_ + h . ~x -:xKii - J.Ly) \\n\\nU xy ( \\nU/2 \\nx \\n\\nU xy ( \\n-\\nu2 \\nx \\n\\nn \\n\\nnu;+h\\u00b7(x-J.Lx)2 \\nNote  that computing D..y  requires  us  to know both the x and y of the new  point .  In \\npractice,  we only know x.  If we  assume, however,  that we  can estimate the learner's \\nbias  at  any  x,  then  we  can  also estimate  the  unknown  value  y ~ y(x)  - bias(x) . \\nBelow,  I  consider  how  to compute the bias  estimate. \\n\\nn \\n\\nn \\n\\nI  ) \\nx - J.L \\nx \\n\\n- J.L \\ny \\n\\n-\\n\\nu; \\n\\n3.2  ESTIMATING  BIAS  FOR LWR \\n\\nThe most common technique for estimating bias is  cross-validation .  Standard cross(cid:173)\\nvalidation however, only gives estimates of the  bias  at our specific  training points , \\nwhich  are  usually combined  to form  an  average  bias estimate.  This is  sufficient  if \\none  assumes  that the  training distribution is  representative  of the  test  distribution \\n(which  it  isn't  in  query  learning)  and  if one  is  content  to just  estimate  the  bias \\nwhere  one  already has  training data (which  we  can't be). \\nIn the query selection  problem, we  must be  able to estimate the bias  at all possible \\nx.  Box  and  Draper  [1987]  suggest  fitting  a  higher  order  model and measuring the \\ndifference.  For  the  experiments  described  in  this  paper,  this  method yielded  poor \\nresults; two other bias-estimation techniques,  however, performed very  well. \\n\\nOne  method  of estimating  bias  is  by  bootstrapping  the  residuals  of  the  training \\npoints.  One produces a  \\\"bootstrap sample\\\" of the learner's residuals on the training \\ndata, and adds them to the original predictions to create a synthetic training set .  By \\naveraging  predictions  over  a  number of bootstrapped  training sets  and  comparing \\nthe average prediction with that of the original predictor, one arrives at a first-order \\nbootstrap estimate of the predictor's bias [Connor 1993; Efron and Tibshirani, 1993] . \\nIt is  known  that this  estimate is  itself biased  towards  zero;  a  standard heuristic  is \\nto divide the estimate by  0.632  [Efron,  1983]. \\nAnother method of estimating bias of a learner is  by fitting  its own cross-validated \\nresiduals.  We  first  compute the cross-validated residuals  on  the training examples. \\nThese  produce  estimates  of the  learner's  bias  at  each  of the  training  points.  We \\ncan then  use  these  residuals  as  training examples for  another  learner  (again  LWR) \\nto produce estimates of what the cross-validated error would be  in places  where  we \\ndon't have  training data. \\n\\n4  EMPIRICAL  RESULTS \\n\\nIn  the  previous  two  sections,  I  have  explained  how  having  an  estimate of D..y  and \\nbias  for  a  learner  allows  one  to  compute  the  learner's  change  in  bias  given  a  new \\nquery,  and  have  shown  how  these  estimates  may be  computed  for  a  learner  that \\nuses  locally weighted regression.  Here,  I apply these  results to two simple problems \\nand  demonstrate  that  they  may  actually  be  used  to  select  queries  that  minimize \\nthe statistical bias (and the error)  of the learner.  The problems involve learning the \\nkinematics  of a  planar  two-jointed  robot  arm:  given  the  shoulder  and elbow joint \\nangles, the learner must predict  the  tip position. \\n\\n\\f422 \\n\\n4.1  BIAS  ESTIMATES \\n\\nD.A. Cohn \\n\\nI tested the accuracy of the two bias estimators by observing their correlations on 64 \\nreference  inputs, given 100 random training examples from the planar arm problem. \\nThe  bias estimates had  a  correlation  with  actual biases  of 0.852  for  the bootstrap \\nmethod, and 0.871  for  the  cross-validation method. \\n\\n4.2  BIAS  MINIMIZATION \\n\\nI ran two sets of experiments using the bias-minimizing criterion in conjunction with \\nthe  bias  estimation technique  of the  previous  section  on  the  planar arm  problem. \\nThe bias minimization criterion was  used  as follows:  At each time step, the learner \\nwas  given  a  set  of 64  randomly chosen  candidate  queries  and  64  uniformly chosen \\nreference  points.  It evaluated  E' (x)  for  each  reference  point  given  each  candidate \\npoint and selected  for  its next  query  the candidate point with the smallest average \\nE' (x) over the reference  points.  I compared the bias-minimizing strategy (using the \\ncross-validation and bootstrap estimation techniques)  against random sampling and \\nthe  variance-minimizing strategy  discussed  in  Cohn  et  al.  [1996].  On  a  Sparc  10, \\nwith m training examples, the  average evaluation times per candidate per reference \\npoint were  58 + 0.16m J.lseconds  for  the variance criterion, 65 + 0.53m J.lseconds  for \\nthe cross-validation-based bias criterion, and 83 + 3. 7m J.lseconds  for  the bootstrap(cid:173)\\nbased  bias criterion  (with  20x resampling) . \\nTo test  whether the  bias-only assumption was robust  against the presence  of noise, \\n1 % Gaussian  noise  was  added  to  the  input  values  of the  training  data  in  all  ex(cid:173)\\nperiments.  This simulates noisy  position effectors  on  the arm , and  results  in  non(cid:173)\\nGaussian noise  in  the output coordinate  system. \\n\\nIn  the  first  series  of experiments,  the  candidate  shoulder  and  elbow  joint  angles \\nwere  drawn  uniformly over  (U[O, 271\\\"],  U[O,  71\\\")) .  In  unconstrained  domains like  this, \\nrandom sampling is  a fairly good default  strategy.  The bias minimization strategies \\nstill  significantly  outperform  both  random  sampling  and  the  variance  minimizing \\nstrategy in these  experiments (see  Figure  1). \\n\\n-1 \\n\\n10 \\n\\ng \\n'\\\" 'il ,0-2 \\n:a \\n~ \\nc: \\n~10  .  random \\n\\n-3 \\n\\n' '\\\\ \\n\\n\\\".'~ \\n\\nvariance-min \\n-\\no  cross-val-min \\n~ x  bootstrap-min \\n200 \\n\\n100 \\n\\n10  0 \\n\\n300 \\n\\ntrainlno set size \\n\\nI, \\n\\\\\\\\ \\n--\\n\\n1 \\n10 \\n\\ng  0 \\n\\n\\\"'10 \\n\\n}1O-1 \\n~  -2 \\n\\n,- -\\n\\n.:  ~~&e-.!)jni(llIZI~  , \\no \\n\\n10 \\n10-3  ~  ~~~~rmiWngar- iOlmizing \\n400 \\n\\n300 \\n\\n200 \\n\\n1 00 \\n\\ntrainino set size \\n\\nIheta 1 \\n\\n(left)  MSE  as  a  function  of number of noisy  training examples for  the \\nFigure  1: \\nunconstrained  arm  problem.  Errors  are  averaged  over  10  runs  for  the  bootstrap \\nmethod and 15  runs for  all others.  One run with the cross-validation-based method \\nwas  excluded  when  k  failed  to  converge  to  a  reasonable  value.  (center)  MSE  as \\na  function  of number of noisy  training examples for  the  constrained  arm problem . \\nThe bias correction strategy discussed in Section 2.1  does no better than the uncor(cid:173)\\nrected  variance-minimizing strategy,  and  much  worse  than  the  bias-minimization \\nstrategy.  (right)  Sample  exploration  trajectory  in  joint-space  for  the  constrained \\narm problem , explored  according  to the bias minimizing criterion. \\n\\nIn the second series of experiments, candidates were  drawn uniformly from a region \\n\\n\\fMinimizing Statistical Bias with Queries \\n\\n423 \\n\\nlocal to  the previously  selected  query:  (01  \\u00b1 0.217\\\", O2  \\u00b1 0.117\\\").  This corresponds  to \\nrestricting  the  arm  to local  motions.  In  a  constrained  problem such  as  this,  ran(cid:173)\\ndom  sampling  is  a  poor  strategy;  both  the  bias  and  variance-reducing  strategies \\noutperform it at least  an order of magnitude.  Further, the  bias-minimization strat(cid:173)\\negy  outperforms variance minimization by a large  margin (Figure 1).  Figure  1 also \\nshows  an  exploration  trajectory  produced  by  pursuing  the  bias-minimizing crite(cid:173)\\nrion.  It is  noteworthy that, although the implementation in this case  was a  greedy \\n(one-step)  minimization, the trajectory results  in globally good exploration. \\n\\n5  DISCUSSION \\n\\nI  have argued  in  this paper  that, in many situations, selecting  queries  to minimize \\nlearner bias is an appropriate and effective strategy for  active learning.  I have given \\nempirical  evidence  that,  with  a  LWR-based  learner  and  the  examples  considered \\nhere,  the strategy is effective  even  in the presence  of noise. \\n\\nBeyond  minimizing either  bias  or  variance,  an  important next  step  is  to explicitly \\nminimize  them  together .  The  bootstrap-based  estimate should  facilitate  this,  as \\nit produces  a  complementary variance estimate with little additional computation. \\nBy optimizing over both criteria simultaneously, we expect to derive a criterion that \\nthat, in  terms of statistics,  is  truly optimal for  selecting  queries. \\n\\nREFERENCES \\nBox,  G.,  &  Draper, N.  (1987).  Empirical model-building  and  response  surfaces, \\nWiley,  New  York. \\nCleveland,  W.,  Devlin,  S.,  &  Grosse,  E.  (1988) .  Regression  by  local fitting. \\nJournal  of Econometrics,  37, 87-114. \\nCohn,  D.  (1996)  Neural  network  exploration  using  optimal  experiment  design. \\nNeural Networks,  9(6):1071-1083. \\nCohn,  D.,  Ghahramani,  Z.,  &  Jordan,  M.  (1996) .  Active  learning  with sta(cid:173)\\ntistical models.  Journal  of Artificial Inteligence  Research 4:129-145 . \\nConnor, J. (1993).  Bootstrap Methods in Neural Network Time Series  Prediction. \\nIn  J .  Alspector  et  al.,  eds.,  Proc.  of the  Int.  Workshop  on  Applications  of Neural \\nNetworks  to  Telecommunications,  Lawrence  Erlbaum, Hillsdale,  N.J. \\nDietterich,  T.,  &  Kong,  E.  (1995) .  Error-correcting  output  coding  corrects \\nbias  and  variance.  In  S.  Prieditis  and  S.  Russell,  eds.,  Proceedings  of the  12th \\nInternational  Conference  on  Machine  Learning. \\nEfron, B. (1983) Estimating the error rate of a prediction rule:  some improvements \\non cross-validation.  J.  Amer.  Statist.  Assoc.  78:316-331. \\nEfron, B.  &  Tibshirani, R.  (1993).  An introduction  to  the  bootstrap.  Chapman \\n&  Hall,  New  York . \\nFedorov, V.  (1972).  Theory  of Optimal Experiments.  Academic Press,  New  York. \\nGeman, S.,  Bienenstock, E.,  &  Doursat, R.  (1992).  Neural  networks and the \\nbias/variance dilemma.  Neural  Computation,  4,  1-58. \\nMacKay,  D.  (1992).  Information-based objective functions  for  active  data selec(cid:173)\\ntion,  Neural  Computation,  4,  590-604. \\nPaass,  G.,  and Kindermann, J. (1994).  Bayesian  Query Construction for  Neu(cid:173)\\nral  Network  Models.  In  G.  Tesauro  et  al.,  eds.,  Advances  in  Neural  Information \\nProcessing Systems  7,  MIT Press. \\nPlutowski, M.,  &  White,  H.  (1993).  Selecting concise  training sets from  clean \\ndata.  IEEE  Transactions  on  Neural  Networks,  4, 305-318. \\nSchaal,  S.  &  Atkeson,  C.  (1994).  Robot  Juggling:  An  Implementation  of \\nMemory-based Learning.  Control Systems 14, 57-71. \\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(subset=['full_text'], inplace=True)"
      ],
      "metadata": {
        "id": "OWTlgMNXiugy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위에서 정의한 함수로 data를 정제해줍니다\n",
        "data['full_text'] = data['full_text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "aOQmQ1oBivtb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정제된 데이터를 확인해봅시다\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ecNq-Z7Tiw2g",
        "outputId": "0ab6dee6-474a-41c0-e96e-4218f33bf8a0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   source_id  year                                              title  \\\n",
              "0         27  1987                         Bit-Serial Neural Networks   \n",
              "1         63  1987                        Connectivity Versus Entropy   \n",
              "2         60  1987        The Hopfield Model with Multi-Level Neurons   \n",
              "3         59  1987                               How Neural Nets Work   \n",
              "4         69  1987  Spatial Organization of Neural Networks: A Pro...   \n",
              "\n",
              "  abstract                                          full_text  \n",
              "0      NaN  573   bit  serial neural  networks   alan f  m...  \n",
              "1      NaN  1   connectivity versus entropy   yaser  s  ab...  \n",
              "2      NaN  278   the hopfield model with mul tilevel neur...  \n",
              "3      NaN  442   alan  lapedes  robert  farber   theoreti...  \n",
              "4      NaN  740   spatial  organization  of  neural  nenor...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c67adc78-2398-4d8d-b899-660928ef9a02\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>1987</td>\n",
              "      <td>Bit-Serial Neural Networks</td>\n",
              "      <td>NaN</td>\n",
              "      <td>573   bit  serial neural  networks   alan f  m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63</td>\n",
              "      <td>1987</td>\n",
              "      <td>Connectivity Versus Entropy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1   connectivity versus entropy   yaser  s  ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>1987</td>\n",
              "      <td>The Hopfield Model with Multi-Level Neurons</td>\n",
              "      <td>NaN</td>\n",
              "      <td>278   the hopfield model with mul tilevel neur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59</td>\n",
              "      <td>1987</td>\n",
              "      <td>How Neural Nets Work</td>\n",
              "      <td>NaN</td>\n",
              "      <td>442   alan  lapedes  robert  farber   theoreti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69</td>\n",
              "      <td>1987</td>\n",
              "      <td>Spatial Organization of Neural Networks: A Pro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>740   spatial  organization  of  neural  nenor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c67adc78-2398-4d8d-b899-660928ef9a02')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c67adc78-2398-4d8d-b899-660928ef9a02 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c67adc78-2398-4d8d-b899-660928ef9a02');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7560d1e4-1a90-4465-8c6f-6791e609c5a4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7560d1e4-1a90-4465-8c6f-6791e609c5a4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7560d1e4-1a90-4465-8c6f-6791e609c5a4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 9677,\n  \"fields\": [\n    {\n      \"column\": \"source_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1825,\n        \"min\": 1,\n        \"max\": 9406,\n        \"num_unique_values\": 4521,\n        \"samples\": [\n          2504,\n          836,\n          2332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 1987,\n        \"max\": 2019,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          2018,\n          2002,\n          2013\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9677,\n        \"samples\": [\n          \"Unsupervised Object Segmentation by Redrawing\",\n          \"Spectral Hashing\",\n          \"Deep, complex, invertible  networks for inversion of transmission effects in multimode optical fibres\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6360,\n        \"samples\": [\n          \"Zero-shot learning (ZSL) aims to recognize unseen object classes without any training samples, which can be regarded as a form of transfer learning from seen classes to unseen ones. This is made possible by learning a projection between a feature space and a semantic space (e.g. attribute space). Key to ZSL is thus to learn a projection function that is robust against the often large domain gap between the seen and unseen classes. In this paper, we propose a novel ZSL model termed domain-invariant projection learning (DIPL). Our model has two novel components: (1) A domain-invariant feature self-reconstruction task is introduced to the seen/unseen class data, resulting in a simple linear formulation that casts ZSL into a min-min optimization problem. Solving the problem is non-trivial, and a novel iterative algorithm is formulated as the solver, with rigorous theoretic algorithm analysis provided. (2) To further align the two domains via the learned projection, shared semantic structure among seen and unseen classes is explored via forming superclasses in the semantic space. Extensive experiments show that our model outperforms the state-of-the-art alternatives by significant margins.\",\n          \"In this work, we present new theoretical results on convolutional generative neural networks, in particular their invertibility (i.e., the recovery of input latent code given the network output). The study of network inversion problem is motivated by image inpainting and the mode collapse problem in training GAN. Network inversion is highly non-convex, and thus is typically computationally intractable and without optimality guarantees. However, we rigorously prove that, under some mild technical assumptions, the input of a two-layer convolutional generative network can be deduced from the network output efficiently using simple gradient descent. This new theoretical finding implies that the mapping from the low- dimensional latent space to the high-dimensional image space is bijective (i.e., one-to-one). In addition, the same conclusion holds even when the network output is only partially observed (i.e., with missing pixels). Our theorems hold for 2-layer convolutional generative network with ReLU as the activation function, but we demonstrate empirically that the same conclusion extends to multi-layer networks and networks with other activation functions, including the leaky ReLU, sigmoid and tanh.\",\n          \"Dependencies among neighbouring labels in a sequence is an important source of information for sequence labeling problems. However, only dependencies between adjacent labels are commonly exploited in practice because of the high computational complexity of typical inference algorithms when longer distance dependencies are taken into account. In this paper, we show that it is possible to design efficient inference algorithms for a conditional random field using features that depend on long consecutive label sequences (high-order features), as long as the number of distinct label sequences in the features used is small. This leads to efficient learning algorithms for these conditional random fields. We show experimentally that exploiting dependencies using high-order features can lead to substantial performance improvements for some problems and discuss conditions under which high-order features can be effective.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9673,\n        \"samples\": [\n          \"nonparametric multigroup membership model  for dynamic networks  myunghwan kim stanford university stanford ca 94305  jure leskovec  stanford university stanford ca 94305  mykimstanfordedu  jurecsstanfordedu  relational data\\u2014like graphs networks and matrices\\u2014is often dynamic where the relational struc ture evolves over time a fundamental problem in the analysis of timevarying network data is to extract a summary of the common structure and the dynamics of the underlying relations between the entities here we build on the intuition that changes in the network structure are driven by dy namics at the level of groups of nodes we propose a nonparametric multigroup membership model for dynamic networks our model contains three main components we model the birth and death of individual groups with respect to the dynamics of the network structure via a distance dependent in dian buffet process we capture the evolution of individual node group memberships via a factorial hidden markov model and we explain the dynamics of the network structure by explicitly mod eling the connectivity structure of groups we demonstrate our model\\u2019s capability of identifying the dynamics of latent groups in a number of different types of network data experimental results show that our model provides improved predictive performance over existing dynamic network models on future network forecasting and missing link prediction  1 introduction  statistical analysis of social networks and other relational data is becoming an increasingly impor tant problem as the scope and availability of network data increases network data\\u2014such as the friendships in a social network\\u2014is often dynamic in a sense that relations between entities rise and decay over time a fundamental problem in the analysis of such dynamic network data is to extract a summary of the common structure and the dynamics of the underlying relations between entities  accurate models of structure and dynamics of network data have many applications they allow us to predict missing relationships 20 21 23 recommend potential new relations 2 identify clusters and groups of nodes 1 29 forecast future links 4 9 11 24 and even predict group growth and longevity 15  here we present a new approach to modeling network dynamics by considering timeevolving inter actions between groups of nodes as well as the arrival and departure dynamics of individual nodes to these groups we develop a dynamic network model dynamic multigroup membership graph model that identi\\ufb01es the birth and death of individual groups as well as the dynamics of node join ing and leaving groups in order to explain changes in the underlying network linking structure our nonparametric model considers an in\\ufb01nite number of latent groups where each node can belong to multiple groups simultaneously we capture the evolution of individual node group memberships via a factorial hidden markov model however in contrast to recent works on dynamic network modeling 4 5 11 12 14 we explicitly model the birth and death dynamics of individual groups by using a distancedependent indian buffet process 7 under our model only activealive groups in\\ufb02uence relationships in a network at a given time further innovation of our approach is that we not only model relations between the members of the same group but also account for links between members and nonmembers by explicitly modeling group lifespan and group connectivity structure we achieve greater modeling \\ufb02exibility which leads to improved performance on link prediction and network forecasting tasks as well as to increased interpretability of obtained results  1   the rest of the paper is organized as follows section 2 provides the background and section 3 presents our generative model and motivates its parametrization we discuss related work in sec tion 4 and present model inference procedure in section 5 last in section 6 we provide experi mental results as well as analysis of the social network from the movie the lord of the rings  2 models of dynamic networks  first we describe general components of modern dynamic network models 4 5 11 14 in the next section we will then describe our own model and point out the differences to the previous work  dynamic networks are generally conceptualized as discrete time series of graphs on a \\ufb01xed set of nodes n  dynamic network y is represented as a time series of adjacency matrices y t for each time t  1 2 \\u00b7 \\u00b7 \\u00b7  t  in this work we limit our focus to unweighted directed as well as undirected networks so each y t is a n \\u00d7 n binary matrix where y t ij  1 if a link from node i to j exists at time t and y t  ij  0 otherwise  each node i of the network is associated with a number of latent binary features that govern the interaction dynamics with other nodes of the network we denote the binary value of feature k of node i at time t by zt ik \\u2208 0 1 such latent features can be viewed as assigning nodes to multi ple overlapping latent clusters or groups 1 21 in our work we interpret these latent features as memberships to latent groups such as social communities of people with the same interests or hob bies we allow each node to belong to multiple groups simultaneously we model each nodegroup membership using a separate bernoulli random variable 17 22 29 this is in contrast to mixed membership models where the distribution over individual node\\u2019s group memberships is modeled using a multinomial distribution 1 5 12 the advantage of our multiplemembership approach is as follows mixedmembership models ie multinomial distribution over group memberships essentially assume that by increasing the amount of node\\u2019s membership to some group k the same node\\u2019s membership to some other group k\\u2032 has to decrease due to the condition that the probabilities normalize to 1 on the other hand multiplemembership models do not suffer from this assumption and allow nodes to truely belong to multiple groups furthermore we consider a nonparametric model of groups which does not restrict the number of latent groups ahead of time hence our model adaptively learns the appropriate number of latent groups for a given network at a given time  in dynamic network models one also speci\\ufb01es a process by which nodes dynamically join and leave groups we assume that each node i can join or leave a given group k according to a markov model however since each node can join multiple groups independently we naturally consider factorial hidden markov models fhmm 8 where latent group membership of each node independently evolves over time to be concrete each membership zt ik evolves through a 2by2 markov transition probability matrix qt  r where r s \\u2208 0  nonmember 1  member  k r s corresponds to p zt  k where each entry qt  ik  szt\\u22121  ik  now given node group memberships zt ik at time t one also needs to specify the process of link generation links of the network realize according to a link function f \\u00b7 a link from node i to node j at time t occurs with probability determined by the link function f zt j\\u00b7  in our model we develop a link function that not only accounts for links between group members but also models links between the members and nonmembers of a given group  i\\u00b7  zt  3 dynamic multigroup membership graph model  next we shall describe our dynamic multigroup membership graph model dmmg and point out the differences with the previous work in our model we pay close attention to the three processes governing network dynamics 1 birth and death dynamics of individual groups 2 evolution of memberships of nodes to groups and 3 the structure of network interactions between group mem bers as well as nonmembers we now proceed by describing each of them in turn  model of active groups links of the network are in\\ufb02uenced not only by nodes changing member ships to groups but also by the birth and death of groups themselves new groups can be born and old ones can die however without explicitly modeling group birth and death there exists ambiguity  2   between group membership change and the birthdeath of groups for example consider two dis joint groups k and l such that their lifetimes and members do not overlap in other words group l is born after group k dies out however if group birth and death dynamics is not explicitly modeled then the model could interpret that the two groups correspond to a single latent group where all the members of k leave the group before the members of l join the group to resolve this ambiguity we devise an explicit model of birthdeath dynamics of groups by introducing a notion of active groups  under our model a group can be in one of two states it can be either active alive or inactive not yet born or dead however once a group becomes inactive it can never be active again that is once a group dies it can never be alive again to ensure coherence of group\\u2019s state over time we build on the idea of distancedependent indian buffet processes ddibp 7 the ibp is named after a metaphorical process that gives rise to a probability distribution where customers enter an indian buffet restaurant and sample some subset of an in\\ufb01nitely long sequence of dishes in the context of networks nodes usually correspond to \\u2018customers\\u2019 and latent featuresgroups correspond to \\u2018dishes\\u2019 however we apply ddibp in a different way we regard each time step t as a \\u2018customer\\u2019 that samples a set of active groups kt so at the \\ufb01rst time step t  1 we have p oisson\\u03bb number of groups that are initially active ie k1 \\u223c p oisson\\u03bb to account for death of groups we then consider that each active group at time t \\u2212 1 can become inactive at the next time step t with probability \\u03b3 on the other hand p oisson\\u03b3\\u03bb new groups are also born at time t thus at each time currently active groups can die while new ones can also be born the hyperparameter \\u03b3 controls for how often new groups are born and how often old ones die for instance there will be almost no newborn or dead groups if \\u03b3 \\u2248 1 while there would be no temporal group coherence and practically all the groups would die between consecutive time steps if \\u03b3  0  figure 1a gives an example of the above process black circles indicate active groups and white circles denote inactive not yet born or dead groups groups 1 and 3 exist at t  1 and group 2 is born at t  2 at t  3 group 3 dies but group 4 is born without our group activity model group 3 could have been reused with a completely new set of members and group 4 would have never been born our model can distinguish these two disjoint groups  formally we denote the number of active groups at time t by kt  kt we also denote the state activeinactive of group k at time t by w t k  1k \\u2208 kt for convenience we also de\\ufb01ne a set of newly active groups at time t be k  t  k t  putting it all together we can now fully describe the process of group birthdeath as follows  k  0 \\u2200t\\u2032  t and k   k  1 w t\\u2032  t  kw t  for t  1 for t  1  k   p oisson \\u03b3\\u03bb   t \\u223ccid26p oisson \\u03bb  k \\u223c\\uf8f1\\uf8f4\\uf8f2 \\uf8f4\\uf8f3  bernoulli1 \\u2212 \\u03b3 1 0  w t  k   1 t\\u20321 k   if w t\\u22121  if pt\\u22121  otherwise   t\\u2032  k \\u2264pt  t\\u20321 k   t\\u2032  1  note that under this model an in\\ufb01nite number of active groups can exist this means our model au tomatically determines the right number of active groups and each node can belong to many groups simultaneously we now proceed by describing the model of node group membership dynamics  dynamics of node group memberships we capture the dynamics of nodes joining and leaving groups by assuming that latent node group memberships form a markov chain in this framework node memberships to active groups evolve through time according to markov dynamics  p zt  ik zt\\u22121  ik    qk cid18 1 \\u2212 ak  bk  ak  1 \\u2212 bk cid19   where matrix qkr s denotes a markov transition from state r to state s which can be a \\ufb01xed parameter group speci\\ufb01c or otherwise domain dependent as long as it de\\ufb01nes a markov transition matrix thus the transition of node\\u2019s i membership to active group k can be de\\ufb01ned as follows  ak bk \\u223c beta\\u03b1 \\u03b2 zt  ik \\u223c w t  k  \\u00b7 bernoullicid18a  t\\u22121 ik  1\\u2212z k  1 \\u2212 bkz  t\\u22121  ik cid19   2  typically \\u03b2  \\u03b1 which ensures that group\\u2019s memberships are not too volatile over time  3   a group activity model  b link function model  figure 1 a birth and death of groups black circles represent active and white circles represent inactive unborn or dead groups a dead group can never become active again denotes binary node group memberships entries of link af\\ufb01nity matrix \\u03b8k denotes linking parameters between all 4 combinations of members zt ij  individual af\\ufb01nities \\u03b8kzt  i  0 to obtain link probability pt  i  1 and nonmembers zt   are combined using a logistic function g\\u00b7  b link function zt   zt  i  j  j    relationship between node group memberships and links of the network last we describe the part of the model that establishes the connection between node\\u2019s memberships to groups and the links of the network we achieve this by de\\ufb01ning a link function f i j which for given a pair of nodes i j determines their interaction probability pt  ij based on their group memberships  we build on the multiplicative attribute graph model 16 18 where each group k is associated with a link af\\ufb01nity matrix \\u03b8k \\u2208 r2\\u00d72 each of the four entries of the link af\\ufb01nity matrix captures the tendency of linking between group\\u2019s members members and nonmembers as well as non members themselves while traditionally link af\\ufb01nities were considered to be probabilities we relax this assumption by allowing af\\ufb01nities to be arbitrary real numbers and then combine them through a logistic function to obtain a \\ufb01nal link probability  the model is illustrated in figure 1b given group memberships zt jk of nodes i and j at time t the binary indicators \\u201cselect\\u201d an entry \\u03b8kzt jk  of matrix \\u03b8k this way linking tendency from node i to node j is re\\ufb02ected based on their membership to group k we then determine the overall link probability pt  ij by combining the link af\\ufb01nities via a logistic function g\\u00b71 thus  ik and zt  ik  zt  ij  f zt pt  i\\u00b7  zt  j\\u00b7   g \\u01ebt   \\u03b8kzt  ik  zt  jk   yij \\u223c bernoullipt  ij   3  \\u221e  xk1  where \\u01ebt is a density parameter that re\\ufb02ects the varying link density of network over time  note that due to potentially in\\ufb01nite number of groups the sum of an in\\ufb01nite number of link af\\ufb01nities may not be tractable to resolve this we notice that for a given \\u03b8k subtracting \\u03b8k0 0 from all its entries and then adding this value to \\u01ebt does not change the overall linking probability pt ij  thus we can set \\u03b8k0 0  0 and then only a \\ufb01nite number of af\\ufb01nities selected by zt ik have to be considered for all other entries of \\u03b8k we use n 0 \\u03bd2 as a prior distribution  to sum up figure 2 illustrates the three components of the dmmg in a plate notation group\\u2019s state w t ik is de\\ufb01ned as the fhmm over active groups then the link between nodes i and j is determined based on the groups they belong to and the corresponding group link af\\ufb01nity matrices \\u03b8  is determined by the ddibp process and each nodegroup membership zt  k  4 related work  classically nonbayesian approaches such as exponential random graph models 10 27 have been used to study dynamic networks on the other hand in the bayesian approaches to dynamic network analysis latent variable models have been most widely used these approaches differ by the struc ture of the latent space that they assume for example euclidean space models 13 24 place nodes  1gx  expx1  expx  4   figure 2 dynamic multigroup membership graph model network y depends on each node\\u2019s group mem berships z and active groups w  links of y appear via link af\\ufb01nities \\u03b8  in a low dimensional euclidean space and the network evolution is then modeled as a regression problem of node\\u2019s future latent location in contrast our model uses hmms where latent vari ables stochastically depend on the state at the previous time step related to our work are dynamic mixedmembership models where a node is probabilistically allocated to a set of latent features ex amples of this model include the dynamic mixedmembership block model 5 12 and the dynamic in\\ufb01nite relational model 14 however the critical difference here is that our model uses multi memberships where node\\u2019s membership to one group does not limit its membership to other groups probably most related to our work here are drift 4 and lfp 11 models both of these models consider markov switching of latent multigroup memberships over time drift uses the in\\ufb01nite factorial hmm 6 while lfp adds \\u201csocial propagation\\u201d to the markov processes so that network links of each node at a given time directly in\\ufb02uence group memberships of the corresponding node at the next time compared to these models we uniquely incorporate the model of group birth and death and present a novel and powerful linking function  5 model inference via mcmc  we develop a markov chain monte carlo mcmc procedure to approximate samples from the posterior distribution of the latent variables in our model more speci\\ufb01cally there are \\ufb01ve types of variables that we need to sample node group memberships z  zt ik  group states w  w t k  group membership transitions q  qk link af\\ufb01nities \\u03b8  \\u03b8k and density parameters \\u01eb  \\u01ebt by sampling each type of variables while \\ufb01xing all the others we end up with many samples representing the posterior distribution p z w q \\u03b8 \\u01eby \\u03bb \\u03b3 \\u03b1 \\u03b2 we shall now explain a sampling strategy for each varible type  sampling node group memberships z to sample node group membership zt ik  we use the forwardbackward recursion algorithm 26 the algorithm \\ufb01rst de\\ufb01nes a deterministic forward pass which runs down the chain starting at time one and at each time point t collects information from the data and parameters up to time t in a dynamic programming cache a stochastic backward pass starts at time t and samples each zt ik in backwards order using the information collected dur ing the forward pass in our case we only need to sample zt b k indicate the birth time and the death time of group k due to space constraints we discuss further details in the extended version of the paper 19  k and t d  where t b  k t d k   ik  sampling group states w  to update active groups we use the metropolishastings algorithm with the following proposal distribution p w \\u2192 w \\u2032 we add a new group remove an existing group or update the life time of an active group with the same probability 13 when adding a new group k\\u2032 we select the birth and death time of the group at random such that 1 \\u2264 t b k\\u2032 \\u2264 t d k\\u2032 \\u2264 t  for removing groups we randomly pick one of existing groups k\\u2032\\u2032 and remove it by setting w t k\\u2032\\u2032  0 for all t finally to update the birth and death time of an existing group we select an existing group and propose new birth and death time of the group at random once new state vector w \\u2032 is proposed we accept it with probability  mincid181  p y w \\u2032p w \\u2032\\u03bb \\u03b3p w \\u2032 \\u2192 w   p y w p w \\u03bb \\u03b3p w \\u2192 w \\u2032 cid19   4  we compute p w \\u03bb \\u03b3 and p w \\u2032 \\u2192 w  in a closed form while we approximate the posterior p y w  by sampling l gibbs samples while keeping w \\ufb01xed  5   sampling group membership transition matrix q beta distribution is a conjugate prior of bernoulli distribution and thus we can sample each ak and bk in qk directly from the posterior distribution ak \\u223c beta\\u03b1  n01k \\u03b2  n00k and bk \\u223c beta\\u03b1  n10k \\u03b2  n11k where nrsk is the number of nodes that transition from state r to s in group k r s \\u2208 0  nonmember 1  member  sampling link af\\ufb01nities \\u03b8 once node group memberships z are determined we update the entries of link af\\ufb01nity matrices \\u03b8k direct sampling of \\u03b8 is intractable because of nonconjugacy of the logistic link function an appropriate method in such case would be the metropolishastings that accepts or rejects the proposal based on the likelihood ratio however to avoid low acceptance rates and quickly move toward the mode of the posterior distribution we develop a method based on hybrid monte carlo hmc sampling 3 we guide the sampling using the gradient of log likelihood function with respect to each \\u03b8k because links y t ij are generated independently given group memberships z the gradient with respect to \\u03b8kx y can be computed by  \\u2212  1 2\\u03c32 \\u03b82  k xijtcid16y t  ij \\u2212 pt  ik  x zt  jk  y   ij cid17 1zt  5  updating density parameter \\u01eb parameter vector \\u01eb is de\\ufb01ned over a \\ufb01nite dimension t  therefore we can update \\u01eb by maximizing the loglikelihood given all the other variables we compute the gradient update for each \\u01ebt and directly update \\u01ebt via a gradient step  updating hyperparameters the number of groups over all time periods is given by a poisson distribution with parameter \\u03bb 1  \\u03b3 t \\u2212 1 hence given \\u03b3 we sample \\u03bb by using a gamma conjugate prior similarly we can use the beta conjugate prior for the group death process ie bernoulli distribution to sample \\u03b3 however hyperparameters \\u03b1 and \\u03b2 do not have a conjugate prior so we update them by using a gradient method based on the sampled values of ak and bk  ij  time complexity of model parameter estimation last we brie\\ufb02y comment on the time com plexity of our model parameter estimation procedure each sample zt ik requires computation of link probability pt for all j 6 i since the expected number of active groups at each time is \\u03bb this requires o\\u03bbn 2t  computations of pt ij  by caching the sum of link af\\ufb01nities between every pair of nodes sampling z as well as w requires o\\u03bbn 2t  time sampling \\u03b8 and \\u01eb also requires o\\u03bbn 2t  because the gradient of each pt ij needs to be computed overall our approach takes o\\u03bbn 2t  to obtain a single sample while models that are based on the interaction matrix between all groups 4 5 11 require ok 2n 2t  where k is the expected number of groups furthermore it has been shown that olog n  groups are enough to represent networks 16 18 thus in practice k ie \\u03bb is of order log n and the running time for each sample is on 2t log n   6 experiments  we evaluate our model on three different tasks for quantitative evaluation we perform missing link prediction as well as future network forecasting and show our model gives favorable performance when compared to current dynamic and static network models we also analyze the dynamics of groups in a dynamic social network of characters in a movie \\u201cthe lord of the rings the two towers\\u201d  experimental setup for the two prediction experiments we use the following three datasets first the nips coauthorships network connects two people if they appear on the same publication in the nips conference in a given year network spans t 17 years 1987 to 2003 following 11 we focus on a subset of 110 most connected people over all time periods second the dblp co authorship network is obtained from 21 computer science conferences from 2000 to 2009 t  10 28 we focus on 209 people by taking 7core of the aggregated network for the entire time third the infocom dataset represents the physical proximity interactions between 78 students at the 2006 infocom conference recorded by wireless detector remotes given to each attendee 25 as in 11 we use the processed data that removes inactive time slices to have t 50  to evaluate the predictive performance of our model we compare it to three baseline models for a naive baseline model we regard the relationship between each pair of nodes as the instance of  6   model  naive lfrm drift  dmmg  testll  2030 880 758  \\u2212624  nips auc  0808 0777 0866 0916  f1  testll  12051 0177 3783 0195 3108 0296 0434 \\u22122684  dblp auc  0814 0784 0916 0939  infocom  f1  testll  auc  f1  17821 0300 8689 0146 6654 0421 0492 \\u22126422  0677 0946 0973 0976  0252 0703 0757 0764  table 1 missing link prediction we bold the performance of the best scoring method our dmmg performs the best in all cases all improvements are statistically signi\\ufb01cant at 001 signi\\ufb01cance level  independent bernoulli distribution with beta1 1 prior thus for a given pair of nodes the link probability at each time equals to the expected probability from the posterior distribution given net work data second baseline is lfrm 21 a model of static networks for missing link prediction we independently \\ufb01t lfrm to each snapshot of dynamic networks for network forecasting task we \\ufb01t lfrm to the most recent snapshot of a network even though lfrm does not capture time dynamics we consider this to be a strong baseline model finally for the comparison with dynamic network models we consider two recent state of the art models the drift model 4 is based on an in\\ufb01nite factorial hmm and authors kindly shared their implementation we also consider the lfp model 11 for which we were not able to obtain the implementation but since we use the same datasets we compare performance numbers directly with those reported in 11  to evaluate predictive performance we use various standard evaluation metrics first to assess goodness of inferred probability distributions we report the loglikelihood of heldout edges sec ond to verify the predictive performance we compute the area under the roc curve auc last we also report the maximum f1score f1 by scanning over all possible precisionrecall thresholds  task 1 predicting missing links to generate the datasets for the task of missing link prediction we randomly hold out 20 of node pairs ie either link or nonlink throughout the entire time period we then run each model to obtain 400 samples after 800 burnin samples for each of 10 mcmc chains each sample gives a link probability for a given missing entry so the \\ufb01nal link probability of a missing entry is computed by averaging the corresponding link probability over all the samples this \\ufb01nal link probability provides the evaluation metric for a given missing data entry  table 1 shows average evaluation metrics for each model and dataset over 10 runs we also compute the pvalue on the difference between two best results for each dataset and metric overall our dmmg model signi\\ufb01cantly outperforms the other models in every metric and dataset particularly in terms of f1score we gain up to 466 improvement over the other models  by comparing the naive model and lfrm we observe that lfrm performs especially poorly compared to the naive model in two networks with few edges nips and dblp intuitively this makes sense because due to the network sparsity we can obtain more information from the temporal trajectory of each link than from each snapshot of network however both drift and dmmg successfully combine the temporal and the network information which results in better predictive performance furthermore we note that dmmg outperforms the other models by a larger margin as networks get sparser dmmg makes better use of temporal information because it can explicitly model temporally local links through active groups  last we also compare our model to the lfp model the lfp paper reports auc roc score of \\u223c085 for nips and \\u223c095 for infocom on the same task of missing link prediction with 20 heldout missing data 11 performance of our dmmg on these same networks under the same conditions is 0916 for nips and 0976 for infocom which is a strong improvement over lfp  task 2 future network forecasting here we are given a dynamic network up to time tobs and the goal is to predict the network at the next time tobs  1 we follow the experimental protocol described in 4 11 we train the models on \\ufb01rst tobs networks \\ufb01x the parameters and then for each model we run mcmc sampling one time step into the future for each model and network we obtain 400 samples with 10 different mcmc chains resulting in 400k network samples these network samples provide a probability distribution over links at time tobs  1  table 2 shows performance averaged over different tobs values ranging from 3 to t 1 overall dmmg generally exhibits the best performance but performance results seem to depend on the dataset dmmg performs the best at 0001 signi\\ufb01cance level in terms of auc and f1 for the nips dataset and at 005 level for the infocom dataset while dmmg improves performance on auc  7   model  naive lfrm drift  testll  547 356 \\u2212148  dmmg  170  nips auc  0524 0398 0672 0732  f1  0130 0011 0084 0196  testll  3248 1680 \\u22121324  dblp auc 0668 0492 0650  1347  0652  infocom  f1  testll  auc  f1  0243 0024 0122 0245  774 760 661  \\u2212625  0673 0640 0782 0804  0270 0248 0381 0392  table 2 future network forecasting dmmg performs best on nips and infocom while results on dblp are mixed  haldir gandalf merry frodo sam gollum pippin aragorn legolas gimli saruman eowyn eomer theoden grima hama faramir arwen elrond galadriel madril  haldir gandalf merry frodo sam gollum pippin aragorn legolas gimli saruman eowyn eomer theoden grima hama faramir arwen elrond galadriel madril  haldir gandalf merry frodo sam gollum pippin aragorn legolas gimli saruman eowyn eomer theoden grima hama faramir arwen elrond galadriel madril   1   2   3   4   5   1   2   3   4   5   1   2   3   4   5  a group 1  b group 2  c group 3  figure 3 group arrival and departure dynamics of different characters in the lord of the rings dark areas in the plots correspond to a give node\\u2019s yaxis membership to each group over time xaxis    9 and f1 133 drift achieves the best loglikelihood on the nips dataset in light of our previous observations we conjecture that this is due to change in network edge density between different snapshots on the dblp dataset drift gives the best loglikelihood the naive model performs best in terms of auc and dmmg is the best on f1 score however in all cases of dblp dataset the differences are not statistically signi\\ufb01cant overall dmmg performs the best on nips and infocom and provides comparable performance on dblp  task 3 case study of \\u201cthe lord of the rings the two towers\\u201d social network last we also investigate groups identi\\ufb01ed by our model on a dynamic social network of characters in a movie the lord of the rings the two towers based on the transcript of the movie we created a dynamic social network on 21 characters and t 5 time epochs where we connect a pair of characters if they coappear inside some time window  we \\ufb01t our model to this network and examine the results in figure 3 our model identi\\ufb01ed three dynamic groups which all nicely correspond to the lord of the rings storyline for example the core of group 1 corresponds to aragorn elf legolas dwarf gimli and people in rohan who in the end all \\ufb01ght against the orcs similarly group 2 corresponds to hobbits sam frodo and gollum on their mission to destroy the ring in mordor and are later joined by faramir and ranger madril interestingly group 3 evolving around merry and pippin only forms at t2 when they start their journey with treebeard and later \\ufb01ght against wizard saruman while the \\ufb01ght occurs in two separate places we \\ufb01nd that some scenes are not distinguishable so it looks as if merry and pippin fought together with rohan\\u2019s army against saruman\\u2019s army  acknowledgments  we thank creighton heaukulani and zoubin ghahramani for sharing data and code this research has been supported in part by nsf iis1016909 cns1010921 iis1149837 iis1159679 iarpa afrl fa865010c7058 okawa foundation docomo boeing allyes volkswagen intel alfred p sloan fellowship and the microsoft faculty fellowship  references  1 e m airoldi d m blei s e fienberg and e p xing mixed membership stochastic blockmodels  jmlr 9 2008  2 l backstrom and j leskovec supervised random walks predicting and recommending links in social  networks in wsdm 2011  8   3 s duane a kennedy b j pendleton and d roweth hybrid monte carlo physics letter b  1952216\\u2013222 1987  4 j foulds a u asuncion c dubois c t butts and p smyth a dynamic relational in\\ufb01nite feature  model for longitudinal social networks in aistats 2011  5 w fu l song and e p xing dynamic mixed membership blockmodel for evolving networks  in  icml 2009  6 j v gael y w teh  and z ghahramani the in\\ufb01nite factorial hidden markov model in nips 2009  7 s j gershman p i frazier and d m blei distance dependent in\\ufb01nite latent feature models  arxiv11105454 2012  8 z ghahramani and m i jordan factorial hidden markov models machine learning 2923245\\u2013273  1997  9 f guo s hanneke w fu and e p xing recovering temporally rewiring networks a modelbased  approach in icml 2007  10 s hanneke w fu and e p xing discrete temporal models of social networks electron j statist  4585\\u2013605 2010  11 c heaukulani and z ghahramani dynamic probabilistic models for latent feature propagation in social  networks in icml 2013  12 q ho l song and e p xing evolving cluster mixedmembership blockmodel for timevarying net  works in aistats 2011  13 p d hoff a e raftery and m s handcock latent space approaches to social network analysis jasa  974601090 \\u2013 1098 2002  14 k ishiguro t iwata n ueda and j tenenbaum dynamic in\\ufb01nite relational model for timevarying  relational data analysis in nips 2010  15 s kairam d wang and j leskovec the life and death of online groups predicting group growth and  longevity in wsdm 2012  16 m kim and j leskovec modeling social networks with node attributes using the multiplicative attribute  graph model in uai 2011  17 m kim and j leskovec latent multigroup membership graph model in icml 2012  18 m kim and j leskovec multiplicative attribute graph model of realworld networks internet mathe  matics 812113\\u2013160 2012  19 m kim and j leskovec nonparametric multigroup membership model for dynamic networks  arxiv13112079 2013  20 j r lloyd p orbanz z ghahramani and d m roy random function priors for exchangeable arrays  with applications to graphs and relational data in nips 2012  21 k t miller t l grifths and m i jordan nonparametric latent feature models for link prediction in  nips 2009  22 m m\\u00f8rup m n schmidt and l k hansen  in\\ufb01nite multiple membership relational modeling for  complex networks in mlsp 2011  23 k palla d a knowles and z ghahramani an in\\ufb01nite latent attribute model for network data  in  icml 2012  24 p sarkar and a w moore dynamic social network analysis using latent space models in nips 2005  25 j scott r gass j crowcroft p hui c diot and a chaintreau crawdad data set cambridgehaggle  v 20090529 may 2009  26 s l scott bayesian methods for hidden markov models jasa 97457337\\u2013351 2002  27 t a b snijders g g van de bunt and c e g steglich introduction to stochastic actorbased models  for network dynamics social networks 32144\\u201360 2010  28 j tang j zhang l yao j li l zhang and z su arnetminer extraction and mining of academic  social networks in kdd\\u201908 2008  29 j yang and j leskovec communityaf\\ufb01liation graph model for overlapping community detection in  icdm 2012  9   \",\n          \"tangent prop  a formalism for specifying  selected invariances in an adaptive network   patrice simard   att bell laboratories  101 crawford corner rd   holmdel nj 07733   bernard victorri  universite de caen  caen 14032 cedex   france   yann le cun   att bell laboratories  101 crawford corner rd   holmdel nj 07733   john denker   att bell laboratories  101 crawford corner rd   holmdel nj 07733   abstract   in many machine learning applications one has access not only to training  data but also to some highlevel a priori knowledge about the desired becid173 havior of the system for example it is known in advance that the output  of a character recognizer should be invariant with respect to small spacid173 tial distortions of the input images translations rotations scale changes  etcetera  we have implemented a scheme that allows a network to learn the derivacid173 tive of its outputs with respect to distortion operators of our choosing  this not only reduces the learning time and the amount of training data  but also provides a powerful language for specifying what generalizations  we wish the network to perform   1   introduction   in machine learning one very often knows more about the function to be learned  than just the training data an interesting case is when certain directional derivacid173 tives of the desired function are known at certain points for example an image  895    896   simard victorri le cun and denker   figure 1 top small rotations of an original digital image of the digit 3 center  middle representation of the effect of the rotation in the input vector space space  assuming there are only 3 pixels bottom images obtained by moving along the  tangent to the transformation curve for the same original digital image middle   recognition system might need to be invariant with respect to small distortions of  the input image such as translations rotations scalings etc a speech recognition  system night need to be invariant to time distortions or pitch shifts  in other  words the derivative of the systems output should be equal to zero when the input  is transformed in certain ways   given a large amount of training data and unlimited training time the system  could learn these invariances from the data alone but this is often infeasible the  limitation on data can be overcome by training the system with additional data  obtained by distorting translating rotating etc  the original patterns baird  1990 the top of fig 1 shows artificial data generated by rotating a digital image of  the digit 3 with the original in the center this procedure called the distortion  model  has two drawbacks first the user must choose the magnitude of distortion  and how many instances should be generated second and more importantly the  distorted data is highly correlated with the original data this makes traditional  learning algorithms such as back propagation very inefficient the distorted data  carries only a very small incremental amount of information since the distorted  patterns are not very different from the original ones it may not be possible to  adjust the learning system so that learning the invariances proceeds at a reasonable  rate while learning the original points is nondivergent   the key idea in this paper is that it is possible to directly learn the effect on  the output of distorting the input independently from learning the undistorted    tangent propa formalism for specifying selected invariances in an adaptive network   897   fx   fx   x1   x2   x3   x4   x   x1   x2   x3   x4   x   figure 2 learning a given function solid line from a limited set of example xl  to x4 the fitted curves are shown in dotted line top the only constraint is that  the fitted curve goes through the examples bottom the fitted curves not only  goes through each examples but also its derivatives evaluated at the examples agree  with the derivatives of the given function   patterns when a pattern p is transformed eg rotated with a transformation  s that depends on one parameter a eg the angle of the rotation the set of all  the transformed patterns sp  sea p va is a one dimensional curve in the  vector space of the inputs see fig 1 in certain cases such as rotations of digital  images this curve must be made continuous using smoothing techniques as will be  shown below when the set of transformations is parameterized by n parameters  ai rotation translation scaling etc sp is a manifold of at most n dimensions  the patterns in sp that are obtained through small transformations of p ie  the part of s p that is close to p can be approximated by a plane tangent to  the manifold sp at point p small transformations of p can be obtained by  adding to p a linear combination of vectors that span the tangent plane tangent  vectors the images at the bottom of fig 1 were obtained by that procedure  more importantly the tangent vectors can be used to specify high order constraints  on the function to be learned as explained below   to illustrate the method consider the problem of learning a singlevalued function  f from a limited set of examples fig 2 left represents a simple case where the  desired function f solid line is to be approximated by a function g dotted line  from four examples xi fxii1234 as exemplified in the picture the fitted  function g largely disagrees with the desired function f between the examples if  the functions f and g are assumed to be differentiable which is generally the case  the approximation g can be greatly improved by requiring that gs derivatives  evaluated at the points xd are equal to the derivatives of f at the same points  fig 2 right this result can be extended to multidimensional inputs in this case  we can impose the equality of the derivatives of f and g in certain directions not  necessarily in all directions of the input space  such constraints find immediate use in traditional learning problems it is often the  case that a priori knowledge is available on how the desired function varies with    898   simard victorri le cun and denker   pattern p   pattern p  rotated by ex     tangent  vector     figure 3 how to compute a tangent vector for a given transformation in this case  a rotation   respect to some transformations of the input it is straightforward to derive the  corresponding constraint on the directional derivatives of the fitted function g in  the directions of the transformations previously named tangent vectors typical  examples can be found in pattern recognition where the desired classification funccid173 tion is known to be invariant with respect to some transformation of the input such  as translation rotation scaling etc in other words the directional derivatives of  the classification function in the directions of these transformations is zero   2   implementation   the implementation can be divided into two parts the first part consists in comcid173 puting the tangent vectors this part is independent from the learning algorithm  used subsequently the second part consists in modifying the learning algorithm  for instance backprop to incorporate the information about the tangent vectors  part i let x be an input pattern and s be a transformation operator acting  on the input space and depending on a parameter a if s is a rotation operator  for instance then s a x denotes the input x rotated by the angle a we will  require that the transformation operator s be differentiable with respect to a and  x and that so x  x the tangent vector is by definition 8sa x8a it can be  approximated by a finite difference as shown in fig 3 in the figure the input space  is a 16 by 16 pixel image and the patterns are images of handwritten digits the  transformations considered are rotations of the digit images the tangent vector  is obtained in two steps first the image is rotated by an infinitesimal amount a  this is done by computing the rotated coordinates of each pixel and interpolating  the gray level values at the new coordinates this operation can be advantageously  combined with some smoothing using a convolution a convolution with a gaussian  provides an efficient interpolation scheme in onm multiplyadds where nand m  are the gaussian kernel and image sizes respectively the next step is to subtract  pixel by pixel the rotated image from the original image and to divide the result    tangent propa formalism for specifying selected invariances in an adaptive network   899   by the scalar 0 see fig 3 if ie types of transformations are considered there  will be ie different tangent vectors per pattern for most algorithms these do not  require any storage space since they can be generated as needed from the original  pattern at negligible cost  part it tangent prop is an extension of the backpropagation algorithm allowing  it to learn directional derivatives other algorithms such as radial basis functions  can be extended in a similar fashion   to implement our idea we will modify the usual weightupdate rule  is replaced with w  7 ow e  jter   oe  w  7 ow   0   1   where 7 is the learning rate e the usual objective function er an additional objeccid173 tive function a regularizer that measures the discrepancy between the actual and  desired directional derivatives in the directions of some selected transformations  and jt is a weighting coefficient  let x be an input pattern y  gx be the inputoutput function of the network  the regularizer er is of the form   where erx is   erx   e e trainingset   2   here kix is the desired directional derivative of g in the direction induced by  transformation si applied to pattern x the second term in the norm symbol is the  actual directional derivative which can be rewritten as    gx osio x   00   00   00   where gx is the jacobian of g for pattern x and osio xjoo is the tangent  vector associated to transformation si as described in part i multiplying the tangent  vector by the jacobian involves one forward propagation through a linearized  version of the network in the special case where local invariance with respect to  the sis is desired kix is simply set to o  composition of transformations the theory of lie groups gilmore 1974  ensures that compositions of local small transformations si correspond to linear  combinations of the corresponding tangent vectors the local transformations si  have a structure of lie algebra consequently if erx  0 is verified the network  derivative in the direction of a linear combination of the tangent vectors is equal  to the same linear combination of the desired derivatives in other words if the  network is successfully trained to be locally invariant with respect to say horizontal  translation and vertical translations it will be invariant with respect to compositions  thereof  we have derived and implemented an efficient algorithm tangent prop  for percid173 forming the weight update eq 1 it is analogous to ordinary backpropagation    900   simard victorri le cun and denker   wl   iti   w l1   iti   e l   bl    x\\u00b7   i   network   j3j1   ei  jacobian nework   figure 4 forward propagated variables a x a e and backward propagated varicid173 ables b y p tj in the regular network roman symbols and the jacobian lincid173 earized network greek symbols   but in addition to propagating neuron activations it also propagates the tangent  vectors the equations can be easily derived from fig 4  forward propagation   a   wl xl  i   \\u2022   lj  i   x  uad   tangent forward propagation       1  ai  lj wwi   i   e  uaa   tangent gradient backpropagation   31   w1il1  i  lj  it   iti \\u00a5lit   gradient backpropagation   b   w1 1yl1  i  lj  it   iti   it   weight update   8ew up  ier w up tp  11   li  \\u00a5ii    xi yi   ioi   w\\u00b7\\u00b7 i  8    3   4   5   6   7    tangent propa formalism for specifying selected invariances in an adaptive network   901   60   50   erroron  the test set   20   10   160   320   training set size   figure 5 generalization performance curve as a function of the training set size for  the tangent prop and the backprop algorithms   the regularization parameter jj is tremendously important because it determines  the tradeoff between minimizing the usual objective function and minimizing the  directional derivative error   3 results   two experiments illustrate the advantages of tangent prop the first experiment  is a classification task using a small linearly separable set of 480 binarized handcid173 written digit the training sets consist of 10 20 40 80 160 or 320 patterns and  the training set contains the remaining 160 patterns the patterns are smoothed  using a gaussian kernel with standard deviation of one half pixel for each of the  training set patterns the tangent vectors for horizontal and vertical translation  are computed the network has two hidden layers with locally connected shared  weights and one output layer with 10 units 5194 connections 1060 free paramecid173 ters le cun 1989 the generalization performance as a function of the training  set size for traditional backprop and tangent prop are compared in fig 5 we have  conducted additional experiments in which we implemented not only translations  but also rotations expansions and hyperbolic deformations this set of 6 genercid173 ators is a basis for all linear transformations of coordinates for two dimensional  images it is straightforward to implement other generators including grayievelcid173 shifting smooth segmentation local continuous coordinate transformations and  independent image segment transformations   the next experiment is designed to show that in applications where data is highly    902   simard victorri le cun and denker   avge nmse vi 1ge   a nmse vi   015   01   15   1   o  o 1000 2000 3000 4000 5000 6000 7000 8000 0000 10000   ol  1000 2000 3000 4000 5000 6000 7000 8000 0000 10000  0           15   o   05   1      15      0   5   1   1 5    15 t   1 5   1   15   15   1   0   05   05  distortion model   o   5    5  tangent prop   15   figure 6 comparison of the distortion model left column and tangent prop right  column the top row gives the learning curves error versus number of sweeps  through the training set the bottom row gives the final inputoutput function of  the network the dashed line is the result for unadorned back prop    tangent propa formalism for specifying selected invariances in an adaptive network   903   correlated tangent prop yields a large speed advantage since the distortion model  implies adding lots of highly correlated data the advantage of tangent prop over  the distortion model becomes clear  the task is to approximate a function that has plateaus at three locations we want  to enforce local invariance near each of the training points fig 6 bottom the  network has one input unit 20 hidden units and one output unit two strategies are  possible either generate a small set of training point covering each of the plateaus  open squares on fig 6 bottom or generate one training point for each plateau  closed squares and enforce local invariance around them by setting the desired  derivative to 0 the training set of the former method is used as a measure the  performance for both methods all parameters were adjusted for approximately  optimal performance in all cases the learning curves for both models are shown in  fig 6 top each sweep through the training set for tangent prop is a little faster  since it requires only 6 forward propagations while it requires 9 in the distortion  model as can be seen stable performance is achieved after 1300 sweeps for the  tangent prop versus 8000 for the distortion model the overall speedup is therefore  about 10  tangent prop in this example can take advantage of a very large regularization term  the distortion model is at a disadvantage because the only parameter that effeccid173 tively controls the amount of regularization is the magnitude of the distortions and  this cannot be increased to large values because the right answer is only invariant  under small distortions   4 conclusions   when a priori information about invariances exists this information must be made  available to the adaptive system there are several ways of doing this including the  distortion model and tangent prop the latter may be much more efficient in some  applications and it permits separate control of the emphasis and learning rate for  the invariances relative to the original training data points training a system to  have zero derivatives in some directions is a powerful tool to express invariances to  transformations of our choosing tests of this procedure on largescale applications  handwritten zipcode recognition are in progress   references   baird h s 1990 document image defect models in iapr 1990 workshop on   sytactic and structural pattern recognition pages 3846 murray hill nj   gilmore r 1974 lie groups lie algebras and some of their applications wiley   new york   le cun y 1989  generalization and network design strategies in pfeifer r  schreter z fogelman f and steels l editors connectionism in perspeccid173 tive zurich switzerland elsevier an extended version was published as a  technical report of the university of toronto    \",\n          \"minimizing  statistical bias with queries   david a  cohn   adaptive systems group   harlequin  inc   one  cambridge center  cambridge  ma  02142  cohncharlequincom   abstract   i describe  a  querying criterion that attempts to minimize the error  of a  learner  by  minimizing its estimated squared  bias  i  describe  experiments  with  locallyweighted  regression  on  two  simple probcid173 lems  and observe  that this  biasonly  approach  outperforms the  more  common  varianceonly  exploration  approach  even  in  the  presence  of noise   1   introduction   in recent  years there has been an explosion of interest in active  machine learning  systems  these  are  learning  systems  that  make  queries  or  perform  experiments  to  gather data that  are expected  to maximize performance  when  compared with  passive  learning  systems  which  accept  given  or  randomly  drawn  data  active  learners have demonstrated significant decreases  in the amount of data required  to  achieve equivalent performance  in industrial applications  where  each  experiment  may take  days  to  perform  and  cost  thousands  of dollars  a  method  for  optimally  selecting  these  points would offer enormous savings in time and  money  an  active  learning system  will  typically attempt to select  data that  will  minimize  its  predictive  error  this  error  can  be  decomposed  into  bias  and  variance  terms  most  research  in selecting  optimal actions or  queries  has  assumed  that the learner  is  approximately unbiased  and that to minimize learner error  variance is  the only  thing  to  minimize  eg  fedorov  1972  mackay  1992  cohn  1996  cohn  et  al  1996  paass  1995  in  practice  however  there  are very  few  problems for  which  we have unbiased learners  frequently bias constitutes a large portion of a learners  error  if the learner is deterministic and the data are noisefree then bias is the  only  source  of error  note  that the bias  term here  is  a  statistical bias  distinct from  the  inductive  bias  discussed  in some  machine  learning  research  dietterich  and  kong  1995    418   da cohn   in this paper i describe an algorithm which selects actions queries designed to minicid173 mize the bias of a locally weighted regressionbased  learner  empirically variancecid173 minimizing strategies which ignore bias seem to perform well even in cases  where  strictly speaking  there is  no  variance  to  minimize  in  the  tasks  considered  in  this  paper  the  biasminimizing strategy  consistently  outperforms  variance  minimizacid173 tion even in  the presence  of noise   11  bias  and  variance   let us  begin  by defining px y  to be the unknown joint distribution over  x and y  and  p x  to  be  the  known  marginal distribution  of x  commonly called  the  input  distribution  we  denote  the  learners  output  on input  x  given  training set  d  as  yx d  we  can  then  write the expected  error of the learner as   1 e  yxd  yx2ix pxdx   1   where e\\u00b7 denotes the expectation over p and over training sets d  the expectation  inside the integral may be  decomposed as follows  geman et al  1992   e  yxd  yx2ix   e  yx  eylx   2    ev yx d  eylx2   ev yxd  evyxd2   where ev  denotes the expectation over training sets  the first  term in equation 2  is the variance of y given x  it is the noise in the distribution and does  not depend  on our learner or how the training data are chosen  the second term is the learners  squared bias and the third is its variance these last two terms comprise the expected  squared error of the learner  with  respect  to the regression  function  eylx  most  research  in  active  learning  assumes  that  the  second  term  of equation  2  is  approximately zero  that  is  that  the  learner  is  unbiased  if this  is  the  case  then  one may concentrate on selecting data so  as to minimize the variance of the learner  although this  allvariance approach is optimal when the learner is  unbiased truly  unbiased  learners  are  rare  even  when  the  learners  representation  class  is  able  to  match  the  target  function  exactly  bias is  generally  introduced  by  the  learning  algorithm  and  learning  parameters  from  the  bayesian  perspective  a  learner  is  only unbiased  if its  priors are  exactly  correct  the optimal choice  of query would  of course minimize  both  bias and variance  but  i leave that for future work  for the purposes of this paper i will only be concerned  with  selecting  queries  that  are  expected  to  minimize  learner  bias  this  approach  is  justified  in  cases  where  noise  is  believed  to  be  only  a  small  component  of the  learners  error  if the  learner  is  deterministic  and  there  is  no  noise  then  strictly  speaking there  is  no error  due  to  variance  all  the error  must be  due  to learner  bias  in cases with nondeterminism or noise allbias minimization like allvariance  minimization becomes  an approximation of the optimal approach   the learning model discussed  in this paper is  a  form of locally  weighted  regression  lwr  cleveland et  al  1988  which  has  been  used  in  difficult  machine  learning  tasks  notably  the  robot  juggler  of schaal  and  atkeson  1994  previous  work  cohn et al  1996  discussed  allvariance query selection for  lwr in the remainder  of this paper i describe  a method for  performing allbias query selection  section 2  describes the criterion that must be optimized for allbias query selection  section 3  describes  the  locally  weighted  regression  learner  used  in  this  paper  and  describes    minimizing statistical bias with queries   419   how  the  allbias criterion  may be  computed for  it   section  4  describes  the  results  of experiments using this criterion on several simple domains  directions for future  work  are discussed  in  section 5   2  allbias  query  selection   let  us  assume for  the moment that we  have  a source of noisefree examples xi yi  and  a  deterministic learner  which  given  input  x  outputs estimate yxl  let  us  also  assume  that  we  have  an  accurate estimate of the  bias  of y which  can  be  used  to estimate  the  true  function  yx    yx   biasx  we  will  break  these  rather  strong assumptions of noisefree examples and accurate bias estimates in section 4  but they  are useful for  deriving  the theoretical  approach described  below   given  an  accurate  bias estimate  we  must force  the  biased  estimator into the  best  approximation of yx  with  the fewest  number of examples  this  in effect  transcid173 forms  the  query  selection  problem  into  an  example filter  problem  similar  to  that  studied  by  plutowski  and  white  1993  for  neural  networks  below  i  derive  this  criterion for  estimating the change  in error at  x  given  a  new  queried  example at x  since  we  have  temporarily  assumed  a  deterministic  learner  and  noisefree  data  the expected  error in  equation 2 simplifies to   e  y x d   y x2ix d   yx d   yx2   3   we  want to select  a new  x such that when we  add x f  the resulting squared bias  is  minimized   y   y   yx d u x f   yx2    4  i will for the remainder of the paper use the    to indicate estimates based on the  initial training set  plus  the  additional example  x y  to  minimize  expression  4  we  need  to  compute  how  a  query  at  x will  change  the  learners  bias  at  x  if we  assume  that  we  know  the  input  distribution2  then  we  can  integrate  this  change  over  the  entire  domain  using  monte  carlo  procedures  to  estimate  the  resulting  average  change  and select  a  x such  that  the  expected  squared  bias  is  minimized  defining bias   y  y and fy    y   y we  can  write the new  squared  bias as   bias2   y   y2    y  fy   y2  fy2   2fy  bias  bias2   5  note  that  since  bias  as  defined  here  is  independent  of x  minimizing  the  bias  is  equivalent to minimizing fy2   2fy  bias  the estimate of bias  tells  us  how much our bias will change for  a given x we may  optimize this value over x in one of a number of ways  in low dimensional spaces  it  is often sufficient to consider a set of candidate x and select the one promising the  smallest resulting  error  in  higher  dimensional spaces  it  is  often  more efficient  to  search  for  an optimal x with  a  response  surface  technique  box  and  draper 1987  or hill climb on  abias2  ax  estimates  of bias  and  fy  depend  on  the  specific  learning  model  being  used  in  section 3 i describe a locally weighted regression model and show how differentiable  estimates of bias  and fy  may be  computed for  it   1 for  clarity  i  will  drop  the  argument  z  except  where  required  for  disambiguation  i   will  also  denote only  the univariate  case  the results  apply  in  higher  dimensions  as  well  2this assumption is  contrary to the assumption normally  made in some forms of learncid173  ing  eg  paclearning  but it is  appropriate in  many  domains    420   d  a  cohn   21  an  aside  why  not just use y  mas   if we  have  an accurate  bias estimate it is  reasonable to ask  why  we  do  not simply  use  the  corrected  y  cs  as  our  predictor  the  answer  has  two  parts  the  first  of  which  is  that  for  most  learners  there  are  no  perfect  bias  estimators   they  introduce their own  bias and  variance  which  must  be  addressed  in data selection  second  we  can  define  a  composite learner ye    y  cs  given  a random training  sample  then  we  would  expect  ye  to  outperform  y  however  there  is  no  obvious  way  to select  data for  this composite learner other than selecting  to maximize the  performance  of its  two  components  in  our  case  the  second  component  the  bias  estimate  is  nonanalytic  which  leaves  us  selecting  data  so  as  to  maximize  the  performance of the  first  component  the uncorrected  estimator  we  are  now  back  to  our  original  problem  we  can  select  data so  as  to  minimize either  the  bias  or  variance of the uncorrected  lwrbased learner  since the purpose of the correction  is to give an unbiased estimator intuition suggests that variance minimization would  be the more sensible route in this  case  empirically this approach does  not appear  to yield  any  benefit  over  uncorrected  variance minimization see  figure  1   3  locally weighted regression   the type  of learner  i  consider here  is  a form  of locally weighted  regression  lwr  that is  a slight variation on  the  loess  model of cleveland et  al  1988  see  cohn  et al 1996  for details  the loess  model performs a linear regression  on points  in  the  data set  weighted  by  a  kernel  centered  at  x  the kernel  shape  is  a  design  parameter  the original loess  model uses  a  tricubic  kernel  in my experiments  i  use  the more common gaussian   where ie  is a smoothing parameter  for brevity i will drop the argument x for  hix  and define  n   2i  hi  we  can then  write  the weighted  means and  covariances  as     xi    n     jlr   lj hi     jly   l h   yi  n           ury    lj hi        xi   xyi   jly   n      we use these means and covariances to produce an estimate y at the x  around which  the kernel  is  centered  with  a  confidence  term in  the form of a  variance estimate   in  all the experiments  discussed  in  this paper  the smoothing parameter ie  was  set  so  as  to minimize u2  the  low  cost  of incorporating  new  training  examples  makes  this  form  of locally  weighted regression  appealing for  learning systems which must operate in real time  or with timevarying target functions  eg  schaal and atkeson  1994    minimizing statistical bias with queries   421   i   i  y      a   a   a  i   a   31  computing dy  for lwr  if we  know  what  new  point  x y  were  going  to  add  computing dy  for  lwr  is  straightforward  defining h as  the  weight  given to x  and n as  n  h we  can write  y    y   y    jl     x   jlx   h y   jly    uxy x   jlx   x   nx   x  nuxy  h  x xkii  jly   u xy   u2  x   u xy    u2  x   n   nuh\\u00b7xjlx2  note  that computing dy  requires  us  to know both the x and y of the new  point   in  practice  we only know x  if we  assume however  that we  can estimate the learners  bias  at  any  x  then  we  can  also estimate  the  unknown  value  y  yx   biasx   below  i  consider  how  to compute the bias  estimate   n   n   i    x  jl  x    jl  y     u   32  estimating  bias  for lwr   the most common technique for estimating bias is  crossvalidation   standard crosscid173 validation however only gives estimates of the  bias  at our specific  training points   which  are  usually combined  to form  an  average  bias estimate  this is  sufficient  if  one  assumes  that the  training distribution is  representative  of the  test  distribution  which  it  isnt  in  query  learning  and  if one  is  content  to just  estimate  the  bias  where  one  already has  training data which  we  cant be  in the query selection  problem we  must be  able to estimate the bias  at all possible  x  box  and  draper  1987  suggest  fitting  a  higher  order  model and measuring the  difference  for  the  experiments  described  in  this  paper  this  method yielded  poor  results two other biasestimation techniques  however performed very  well   one  method  of estimating  bias  is  by  bootstrapping  the  residuals  of  the  training  points  one produces a  bootstrap sample of the learners residuals on the training  data and adds them to the original predictions to create a synthetic training set   by  averaging  predictions  over  a  number of bootstrapped  training sets  and  comparing  the average prediction with that of the original predictor one arrives at a firstorder  bootstrap estimate of the predictors bias connor 1993 efron and tibshirani 1993   it is  known  that this  estimate is  itself biased  towards  zero  a  standard heuristic  is  to divide the estimate by  0632  efron  1983  another method of estimating bias of a learner is  by fitting  its own crossvalidated  residuals  we  first  compute the crossvalidated residuals  on  the training examples  these  produce  estimates  of the  learners  bias  at  each  of the  training  points  we  can then  use  these  residuals  as  training examples for  another  learner  again  lwr  to produce estimates of what the crossvalidated error would be  in places  where  we  dont have  training data   4  empirical  results   in  the  previous  two  sections  i  have  explained  how  having  an  estimate of dy  and  bias  for  a  learner  allows  one  to  compute  the  learners  change  in  bias  given  a  new  query  and  have  shown  how  these  estimates  may be  computed  for  a  learner  that  uses  locally weighted regression  here  i apply these  results to two simple problems  and  demonstrate  that  they  may  actually  be  used  to  select  queries  that  minimize  the statistical bias and the error  of the learner  the problems involve learning the  kinematics  of a  planar  twojointed  robot  arm  given  the  shoulder  and elbow joint  angles the learner must predict  the  tip position    422   41  bias  estimates   da cohn   i tested the accuracy of the two bias estimators by observing their correlations on 64  reference  inputs given 100 random training examples from the planar arm problem  the  bias estimates had  a  correlation  with  actual biases  of 0852  for  the bootstrap  method and 0871  for  the  crossvalidation method   42  bias  minimization   i ran two sets of experiments using the biasminimizing criterion in conjunction with  the  bias  estimation technique  of the  previous  section  on  the  planar arm  problem  the bias minimization criterion was  used  as follows  at each time step the learner  was  given  a  set  of 64  randomly chosen  candidate  queries  and  64  uniformly chosen  reference  points  it evaluated  e x  for  each  reference  point  given  each  candidate  point and selected  for  its next  query  the candidate point with the smallest average  e x over the reference  points  i compared the biasminimizing strategy using the  crossvalidation and bootstrap estimation techniques  against random sampling and  the  varianceminimizing strategy  discussed  in  cohn  et  al  1996  on  a  sparc  10  with m training examples the  average evaluation times per candidate per reference  point were  58  016m jlseconds  for  the variance criterion 65  053m jlseconds  for  the crossvalidationbased bias criterion and 83  3 7m jlseconds  for  the bootstrapcid173 based  bias criterion  with  20x resampling   to test  whether the  biasonly assumption was robust  against the presence  of noise  1  gaussian  noise  was  added  to  the  input  values  of the  training  data  in  all  excid173 periments  this simulates noisy  position effectors  on  the arm  and  results  in  noncid173 gaussian noise  in  the output coordinate  system   in  the  first  series  of experiments  the  candidate  shoulder  and  elbow  joint  angles  were  drawn  uniformly over  uo 271  uo  71   in  unconstrained  domains like  this  random sampling is  a fairly good default  strategy  the bias minimization strategies  still  significantly  outperform  both  random  sampling  and  the  variance  minimizing  strategy in these  experiments see  figure  1   1   10   g   il 02  a    c  10    random   3          variancemin   o  crossvalmin   x  bootstrapmin  200   100   10  0   300   trainlno set size   i      1  10   g  0   10   1o1    2        ejnillizi    o   10  103    rmiwngar iolmizing  400   300   200   1 00   trainino set size   iheta 1   left  mse  as  a  function  of number of noisy  training examples for  the  figure  1  unconstrained  arm  problem  errors  are  averaged  over  10  runs  for  the  bootstrap  method and 15  runs for  all others  one run with the crossvalidationbased method  was  excluded  when  k  failed  to  converge  to  a  reasonable  value  center  mse  as  a  function  of number of noisy  training examples for  the  constrained  arm problem   the bias correction strategy discussed in section 21  does no better than the uncorcid173 rected  varianceminimizing strategy  and  much  worse  than  the  biasminimization  strategy  right  sample  exploration  trajectory  in  jointspace  for  the  constrained  arm problem  explored  according  to the bias minimizing criterion   in the second series of experiments candidates were  drawn uniformly from a region    minimizing statistical bias with queries   423   local to  the previously  selected  query  01  \\u00b1 0217 o2  \\u00b1 0117  this corresponds  to  restricting  the  arm  to local  motions  in  a  constrained  problem such  as  this  rancid173 dom  sampling  is  a  poor  strategy  both  the  bias  and  variancereducing  strategies  outperform it at least  an order of magnitude  further the  biasminimization stratcid173 egy  outperforms variance minimization by a large  margin figure 1  figure  1 also  shows  an  exploration  trajectory  produced  by  pursuing  the  biasminimizing critecid173 rion  it is  noteworthy that although the implementation in this case  was a  greedy  onestep  minimization the trajectory results  in globally good exploration   5  discussion   i  have argued  in  this paper  that in many situations selecting  queries  to minimize  learner bias is an appropriate and effective strategy for  active learning  i have given  empirical  evidence  that  with  a  lwrbased  learner  and  the  examples  considered  here  the strategy is effective  even  in the presence  of noise   beyond  minimizing either  bias  or  variance  an  important next  step  is  to explicitly  minimize  them  together   the  bootstrapbased  estimate should  facilitate  this  as  it produces  a  complementary variance estimate with little additional computation  by optimizing over both criteria simultaneously we expect to derive a criterion that  that in  terms of statistics  is  truly optimal for  selecting  queries   references  box  g    draper n  1987  empirical modelbuilding  and  response  surfaces  wiley  new  york  cleveland  w  devlin  s    grosse  e  1988   regression  by  local fitting  journal  of econometrics  37 87114  cohn  d  1996  neural  network  exploration  using  optimal  experiment  design  neural networks  9610711083  cohn  d  ghahramani  z    jordan  m  1996   active  learning  with stacid173 tistical models  journal  of artificial inteligence  research 4129145   connor j 1993  bootstrap methods in neural network time series  prediction  in  j   alspector  et  al  eds  proc  of the  int  workshop  on  applications  of neural  networks  to  telecommunications  lawrence  erlbaum hillsdale  nj  dietterich  t    kong  e  1995   errorcorrecting  output  coding  corrects  bias  and  variance  in  s  prieditis  and  s  russell  eds  proceedings  of the  12th  international  conference  on  machine  learning  efron b 1983 estimating the error rate of a prediction rule  some improvements  on crossvalidation  j  amer  statist  assoc  78316331  efron b    tibshirani r  1993  an introduction  to  the  bootstrap  chapman    hall  new  york   fedorov v  1972  theory  of optimal experiments  academic press  new  york  geman s  bienenstock e    doursat r  1992  neural  networks and the  biasvariance dilemma  neural  computation  4  158  mackay  d  1992  informationbased objective functions  for  active  data seleccid173 tion  neural  computation  4  590604  paass  g  and kindermann j 1994  bayesian  query construction for  neucid173 ral  network  models  in  g  tesauro  et  al  eds  advances  in  neural  information  processing systems  7  mit press  plutowski m    white  h  1993  selecting concise  training sets from  clean  data  ieee  transactions  on  neural  networks  4 305318  schaal  s    atkeson  c  1994  robot  juggling  an  implementation  of  memorybased learning  control systems 14 5771    \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 키워드를 추출하기 위해 full text를 list 형태로 corpora(말뭉치)에 적용해줍시다\n",
        "corpora = data['full_text'].to_list()"
      ],
      "metadata": {
        "id": "sqB_HZb_iyYX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF을 이용한 키워드 추출 ✅\n",
        "# 불용어(stop words) 리스트 불러오기\n",
        "stopwords=get_stopwords_list(STOPWORD_PATH)"
      ],
      "metadata": {
        "id": "5n5hZ3LjoAzc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어를 포함하여 TF-IDF Vectorizer 초기화하기\n",
        "# smooth_idf=True는 log(IDF) 계산 시 1을 더해 0으로 나누는 것 방지해주세요!\n",
        "vectorizer = TfidfVectorizer(stop_words=stopwords, smooth_idf=True)\n",
        "\n",
        "# 말뭉치(corpora)로부터 단어 사전(vocabulary) 생성하기\n",
        "# 앞의 10개 문서는 테스트용으로 제외하고 학습에 사용하기\n",
        "vectorizer.fit(corpora[10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "G-psgpG3i2p1",
        "outputId": "87b26e1e-7f81-48b6-bb2e-9699ab1650c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['come', 'vis', 'viser', 'visest'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(stop_words=['related', 'his', 'co', 'overalls', 'sayyid',\n",
              "                            'indicates', 'downwardest', 'whenever', 'upped',\n",
              "                            'furthers', 'might', 'yourselves', 'hereafter',\n",
              "                            'gone', 'upons', 'respecting', 'doner', 'r',\n",
              "                            'aslant', 'wherein', 'alls', 'ever', 'lots',\n",
              "                            'therer', 'onest', 'make', 'differenter',\n",
              "                            'necessarier', 'gotten', 'lest', ...])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(stop_words=[&#x27;related&#x27;, &#x27;his&#x27;, &#x27;co&#x27;, &#x27;overalls&#x27;, &#x27;sayyid&#x27;,\n",
              "                            &#x27;indicates&#x27;, &#x27;downwardest&#x27;, &#x27;whenever&#x27;, &#x27;upped&#x27;,\n",
              "                            &#x27;furthers&#x27;, &#x27;might&#x27;, &#x27;yourselves&#x27;, &#x27;hereafter&#x27;,\n",
              "                            &#x27;gone&#x27;, &#x27;upons&#x27;, &#x27;respecting&#x27;, &#x27;doner&#x27;, &#x27;r&#x27;,\n",
              "                            &#x27;aslant&#x27;, &#x27;wherein&#x27;, &#x27;alls&#x27;, &#x27;ever&#x27;, &#x27;lots&#x27;,\n",
              "                            &#x27;therer&#x27;, &#x27;onest&#x27;, &#x27;make&#x27;, &#x27;differenter&#x27;,\n",
              "                            &#x27;necessarier&#x27;, &#x27;gotten&#x27;, &#x27;lest&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(stop_words=[&#x27;related&#x27;, &#x27;his&#x27;, &#x27;co&#x27;, &#x27;overalls&#x27;, &#x27;sayyid&#x27;,\n",
              "                            &#x27;indicates&#x27;, &#x27;downwardest&#x27;, &#x27;whenever&#x27;, &#x27;upped&#x27;,\n",
              "                            &#x27;furthers&#x27;, &#x27;might&#x27;, &#x27;yourselves&#x27;, &#x27;hereafter&#x27;,\n",
              "                            &#x27;gone&#x27;, &#x27;upons&#x27;, &#x27;respecting&#x27;, &#x27;doner&#x27;, &#x27;r&#x27;,\n",
              "                            &#x27;aslant&#x27;, &#x27;wherein&#x27;, &#x27;alls&#x27;, &#x27;ever&#x27;, &#x27;lots&#x27;,\n",
              "                            &#x27;therer&#x27;, &#x27;onest&#x27;, &#x27;make&#x27;, &#x27;differenter&#x27;,\n",
              "                            &#x27;necessarier&#x27;, &#x27;gotten&#x27;, &#x27;lest&#x27;, ...])</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성된 단어 사전을 feature_names에 저장하기\n",
        "feature_names = vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "VDQge5-PoHyS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "# 앞의 10개 문서를 대상으로 반복하기\n",
        "for doc in corpora[0:10]:\n",
        "    df = {} # 하나의 문서 결과를 담을 딕셔너리 생성하기\n",
        "    df['full_text'] = doc # 원본 문서 저장하기\n",
        "    df['top_keywords'] = get_keywords(vectorizer,feature_names, doc) ## 상위 키워드 추출 후 저장하기\n",
        "    result.append(df)"
      ],
      "metadata": {
        "id": "BThX5Elei5Eb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = pd.DataFrame(result)\n",
        "final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "FcwRVmgcoT0_",
        "outputId": "626d4087-76bf-46a6-9e16-1300c3a6c26d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           full_text  \\\n",
              "0  573   bit  serial neural  networks   alan f  m...   \n",
              "1  1   connectivity versus entropy   yaser  s  ab...   \n",
              "2  278   the hopfield model with mul tilevel neur...   \n",
              "3  442   alan  lapedes  robert  farber   theoreti...   \n",
              "4  740   spatial  organization  of  neural  nenor...   \n",
              "5  775   a  neuralnetwork  solution to  the  conc...   \n",
              "6  642   learning by st ate recurrence detecfion ...   \n",
              "7  554   stability results  for neural  networks ...   \n",
              "8  804   introduction to a  system for implementi...   \n",
              "9  474   optimiza non with artificial neural netw...   \n",
              "\n",
              "                                        top_keywords  \n",
              "0  [synaptic, bit, vlsi, activation, state, array...  \n",
              "1  [v2, h2k, 2n, en2, environment, neuron, h2, ed...  \n",
              "2  [qnn, neurons, hopfields, neuron, hopfield, ca...  \n",
              "3  [bumps, net, bump, eqn, layer, hidden, output,...  \n",
              "4  [queueing, network, stimulations, cells, nodes...  \n",
              "5  [sites, neurons, assignment, subarray, site, a...  \n",
              "6  [recurrence, aseace, failure, state, pole, ase...  \n",
              "7  [equilibrium, stability, attraction, subsystem...  \n",
              "8  [processors, processor, simd, connections, tim...  \n",
              "9  [dipole, settling, eq, comer, dt, method, extr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dd25697-c81f-4d1b-b49a-9b350978766d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>top_keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>573   bit  serial neural  networks   alan f  m...</td>\n",
              "      <td>[synaptic, bit, vlsi, activation, state, array...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1   connectivity versus entropy   yaser  s  ab...</td>\n",
              "      <td>[v2, h2k, 2n, en2, environment, neuron, h2, ed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>278   the hopfield model with mul tilevel neur...</td>\n",
              "      <td>[qnn, neurons, hopfields, neuron, hopfield, ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>442   alan  lapedes  robert  farber   theoreti...</td>\n",
              "      <td>[bumps, net, bump, eqn, layer, hidden, output,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>740   spatial  organization  of  neural  nenor...</td>\n",
              "      <td>[queueing, network, stimulations, cells, nodes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>775   a  neuralnetwork  solution to  the  conc...</td>\n",
              "      <td>[sites, neurons, assignment, subarray, site, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>642   learning by st ate recurrence detecfion ...</td>\n",
              "      <td>[recurrence, aseace, failure, state, pole, ase...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>554   stability results  for neural  networks ...</td>\n",
              "      <td>[equilibrium, stability, attraction, subsystem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>804   introduction to a  system for implementi...</td>\n",
              "      <td>[processors, processor, simd, connections, tim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>474   optimiza non with artificial neural netw...</td>\n",
              "      <td>[dipole, settling, eq, comer, dt, method, extr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dd25697-c81f-4d1b-b49a-9b350978766d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9dd25697-c81f-4d1b-b49a-9b350978766d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9dd25697-c81f-4d1b-b49a-9b350978766d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c2a67222-c9aa-44ef-921f-6df0850ff2e7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2a67222-c9aa-44ef-921f-6df0850ff2e7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c2a67222-c9aa-44ef-921f-6df0850ff2e7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a9a08ffd-453d-4cb0-86d8-3348835d16a6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a9a08ffd-453d-4cb0-86d8-3348835d16a6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('final');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final",
              "summary": "{\n  \"name\": \"final\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"804   introduction to a  system for implementing neural  net   connections on simd  architectures   sherryl tomboulian   institute for  computer applications  in science and engineering   nasa  langley research center hampton va  23665   abstract   neural  networks  have  attracted  much  interest  recently  and  using  parallel   architectures  to simulate  neural  networks  is  a  natural  and  necessary  applicacid173 tion  the  simd  model  of parallel  computation is  chosen  because systems  of  this  type  can  be  built  with  large  numbers  of processing  elements  however  such systems are not naturally suited to generalized communication  a method  is  proposed  that  allows  an implementation of neural  network  connections  on  massively parallel simd  architectures  the key to this system is an algorithm  that allows  the formation  of arbitrary  connections  between  the neurons  a  feature  is  the ability  to add  new  connections  quickly  it also  has error  recovcid173 ery  ability and  is  robust  over a  variety  of network  topologies  simulations  of  the general  connection system and its implementation on the connection macid173 chine  indicate  that  the  time and  space  requirements  are  proportional  to  the  product of the  average number of connections per neuron and the diameter of  the interconnection network   introduction   neural networks hold  great promise for biological research artificial intellicid173  gence  and even as  general computational devices  however  to study systems  in  a  realistic  manner  it  is  highly  desirable  to  be  able  to  simulate  a  network  with tens of thousands or hundreds of thousands of neurons  this suggests the  use  of parallel  hardware  the most  natural  method  of exploiting  parallelism  would have each processor simulating a  single neuron   consider the requirements of such a  system  there should  be a  very  large  number of processing  elements which  can work  in  parallel  the computation  that occurs at these elements is simple and based on local data  the processing  elements must be able to have connections to other elements  all  connections  in  the  system must  be  able  to  be  traversed  in parallel  connections  must  be  added and deleted dynamically   given current technology  the only type of parallel model that can be concid173  structed  with  tens  of thousands  or hundreds of thousands  of processors  is  an  simd  architecture  in exchange for being able to build a system with so many  processors there are some inherent limitations  simd stands for single instruccid173 tion  multiple datal  which means  that  all  processors  can  work  in  parallel  but  they  must  do  exactly  the same  thing at the  same  time  this machine  model  is  sufficient  for  the  computation required  within  a  neuron  however  in  such  a  system it is difficult  to implement arbitrary connections between neurons  the  connection machine2  provides such a model but uses a device called the router   this work  was  supported  by  the  national  aeronautics  and  space  administration  under   nasa  constract no  nasl180107 while  the author was in residence  at icase   \\u00a9 american institute of physics 1988    805   to deliver messages  the router is a complex piece of hardware that uses signifcid173 icant chip area and without the additional hardware for the router a  machine  could be built with significantly more processors  since one of the objectives is  to maximize the number of neurons  it is  desirable to eliminate the extra cost  of a  hardware router and instead use  a software method   existing  software  algorithms  for  forming  connections  on  simd  machines  are not sufficient for  the requirements of a  neural networks  they restrict  the  form  of graph  neural  network  that  can  be  embedded  to  permutations\\u00b7\\u00b7  or  sorts56combinedwith7  the methods are network specific and adding a  new conneccid173 tion  is highly  time consuming   the software routing method presented here is a unique algorithm which alcid173  lows arbitrary neural networks to be embedded in machines with a wide variety  of network  topologies  the advantages of such an approach are  numerous  a  new connection can be added  dynamically  in the same amount of time that it  takes to perform a  parallel  traversal  of all  connections  the method has error  recovery ability in case of network failures  this method has relationships with  natural neural models  when a new connection is to be formed  the two neurons  being connected are activated and then the system forms  the connection withcid173 out any knowledge of the address  of the neuronprocessors  and without  any  instruction as to the method of forming  the connecting path  the connections  are entirely distributed  a  processor only knows  that connections pass  through  it  it doesnt  know a  connections origin or final  destination   some neural network applications have been implemented on massively parcid173  allel  architectures  but  they have run  into restrictions  due  to  communication  an  implementation on  the  connection  machines  discovered  that it  was  more  desirable  to  cluster processors  in  groups  and  have  each  processor  in  a  group  represent one connection rather than having one processor per neuron because  the router is designed to deliver one message at a time from each processor  this  approach is  contrary with  the more natural  paradigm of having one  processor  represent a  neuron  the mpp  9  a  massively parallel architecture with procescid173 sors arranged in a mesh has been used to implement neural nets10  but because  of a  lack of generalized  communication software  the method for  edge  conneccid173 tions  is  a  regular  communication  pattern  with  all  neurons  within  a  specified  distance  this is not an unreasonable approach since within the brain neurons  are  usually  locally  connected  but  there  is  also  a  need  for  longer  connections  between  groups  of  neurons  the  algorithms  presented  here  can  be  used  on  both  machines  to facilitate  arbitrary connections  with  an irregular  number of  connections at each processor   machine model   as  mentioned  previously  since  we  desire  to  build  a  system  with  an  large   number of processing elements the only technology currently available for buildcid173 ing  such  large  systems  is  the  simd  architecture  model  in  the  simd  model  there is  a  single control unit and  a  very large  number of slave processors  that  can execute the same instruction stream simultaneously  it is possible to disable  some processors so that only some execute an instruction but it is not possible  to have two processor performing different instructions at the same time  the  processors  have exclusively local  memory which is  small  only  a  few  thousand  bits  and  they  have  no  facilities  for  local  indirect  addressing  in this  scheme  an instruction involves both a  particular operation code and the local memory    806   address  all processors must do this same thing to the same areas of their local  memory at the same time   the basic model of computation is  bitserial  each instruction operates on  a  bit at a  time  to perform multiple bit operations  such as  integer addition  requires  several  instructions  this  model  is  chosen  because  it  requires  less  hardware logic  and so would allow a machine to be built with a  larger number  of processors than could  otherwise  be achieved  with a  standard wordoriented  approach  of course the algorithms presented here will also work for machines  with more complex instruction abilities  the machine model described satisfies  the minimal requirements   an important requirement for  connection formation  is  that the processors   are  connected  in  some  topology  for  instance  the  processors  might  be  concid173 nected  in  a  grid  so  that  each  processor  has  a  north  south  east  and  west  neighbor  the  methods  presented  here  work  for  a  wide  variety  of  network  topologies  the  requirements  are  1  there  must  be some  path  between any  two  proeessors  2  every  neighbor ink  must  be  bidirectional  ie  if a  is  a  neighbor  of  b  then  b  must  be  a  neighbor  of  a  3  the  neighbor  relations  between  processors  must  have  a  consistent  invertible  labeling  a  more  precid173 cise  definition  of the  labeling requirements can be found  in 11  it suffices  that  most  networks  12  including  grid  hypercube  cube  connected  cycles1s  shuffle  exchange14   and  mesh  of trees15  are  admissible  under the scheme  additional  requirements  are  that  the  processors  be  able  to  read  from  or  write  to  their  neighbors  memories  and  that  at  least  one  of  the  processors  acts  as  a  serial  port  between the processors and the controller   computational requirements   the  machine  model  described  here  is  sufficient  for  the  computational  recid173  quirements of a neuron  adopt the paradigm that each processor represents one  neuron  while  several  different  models  of neural  networks  exist  with  slightly  different features  they are all fairly  well  characterized by computing a  sum or  product  of the  neighbors  values  and  if a  certain  threshold  is  exceeded  then  the processor neuron will  fire  le  activate other neurons  the machine model  described  here  is  more efficient  at  boolean computation  such as  described  by  mcculloch and  pitts16  since it is  bit serial  neural  net  models  using  integers  and  floating  point arithmetic  1718  will  also work  but will  be somewhat  slower  since  the  time  for  computation  is  proportional  to  the  number  of bits  of the  operands   the only computational difficulty  lies  in the fact  that the system is  simd  which means that the processes are synchronous  for some neural  net  models  this  is  sufficient18  however others  require  asynchronous behavior  17  this  can  easily be achieved simply by turning the processors on and off based on a speccid173 ified  probability distribution  for a  survey of some different  neural  networks  see 19   connection assumptions   many  models  of  neural  networks  assume  fully  connected  systems  this  model is considered unrealistic and the method presented here will work better  for  models  that  contain more  sparsely  connected  systems  while  the  method  will work for dense connections the time and space required is  proportional to    807   the number of edges  and becomes prohibitively expensive   other  than the  sparse  assumptions  there  are  no  restrictions  to  the topocid173  logical  form  of  the  network  being  simulated  for  example  multiple  layered  systems  slightly irregular structures  and  completely  random connections are  all  handled  easily  the system does  function  better if there  is  locality  in  the  neural network  these assumptions seem to fit  the biological model of neurons   the connection formation method   a fundamental part of a neural network implementation is the realization of   the connections between neurons  this is done using a software scheme first precid173 sented in  1120  the original  method was intended for  realizing directed  graphs  in  simd  architectures  since  a  neural  network  is  a  graph  with  the  neurons  being  vertices  and  the  connections  being  arcs  the  method  maps  perfectly  to  this  system  henceforth  the  terms  neuron  and  vertex  and  the  terms  arc  and  connection will  be used  interchangeably   the software  system presented here for  implementing  the connections  has  several parts  each processor will  be assigned  exactly  one  neuron  of course  some  processors  may  be  free  or unallocated  but even  free  processor  parcid173 ticipate  in  the  routing  process  each  connection  will  be  realized  as  a  path  in  the  topology  of processors  a  labeling  of these  paths in  time  and  space  is  introduced  which  allows  efficient  routing  algorithms  and  a  setup  strategy  is  introduced  that allows new connections to be added quickly   the standard computer science approach to forming  the connection would  be to store the addresses of the processors to which a given neuron is connected  then  using  a  routing  algorithm  messages  could  be  passed  to  the  processors  with  the specified  destination  however  the simd  architecture does  not  lend  itself to standard  message  passing schemes because  processors  cannot do indicid173 rect addressing so buffering of values  is  difficult and costly   instead a scheme is introduced which is closer to the natural neuronsynapse  structures  instead  of having an address  for  each  connection  the  connection  is  actually represented as  a  fixed  path between the processors using time as a  virtual  dimension  the path a  connection  takes  through  the  network  of  procid173 cessors is statically encoded in the local  memories of the neurons that it passes  through  to achieve  this  the following  data structures will  be resident at each  processor   allocated   boolean  flag  indicating  whether  this  processor  is  assigned  a  vertex  neuron  in  the  graph   vertex  label   label  of  graph  vertex  hasneighborl  neighborlimit  flag   indicating  the  existence  of  neighbors  arc  path  information   slotsl  t  of   neuron   startnew  arc  starts  here  directiondirection  to  send   l  neighborlimitfree   endarc  ends  here  arc  labellabel  of  arc    808   the allocated and vertex label field  indicates that the processor  has been assigned a  vertex in the graph  neuron  the has  neighbor field  is used  to indicate whether a  physical wire exists in the particular direction  it  allows  irregular network topologies  and  boundary conditions  to  be supported  the  slots  data structure is  the  key  to  realizing  the  connections  it is  used  to instruct the processor where to send a  message and to insure that paths are  constructed in such a  way that no collisions will  occur   slots is an array with t elements  the value t  is called the time quantum  traversing all  the edges  of the embedded  graph  in  parallel  will  take  a  certain  amount  of time  since  messages  must  be  passed  along  through  a  sequence  of  neighboring  processors  forming  these parallel  connections will  be considered  an uninterruptable operation which will take t  steps  the slots array is used  to tell the processors what they should do on each relative time  position within  the time quantum   one of the characteristics of this algorithm is  that a  fixed  path is  chosen to  represent  the connection  between  two  processors  and  once  chosen  it  is  never  changed  for example consider the grid below   abcde  fghij  i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   fig  1  grid  example   if there is  an arc  between a and h  there are several  possible paths  eastcid173  eastsouth  eastsoutheast  and  southeasteast  only  one  of these  paths  will  be  chosen  between  a  and  h  and  that  same  path  will  always  be  used  besides  being  invariant  in space  paths  are  also  invariant  in  time  as  stated  above  traversal is  done  within  a  time  quantum t  paths do  no  have  to start  on  time  1  but  can  be  scheduled  to  start  at  some  relative  offset  within  the  time quantum  once the starting time for  the path has  been fixed  it is  never  changed  another requirement is  that a  message can not be buffered  it  must  proceed  along  the  specified  directions  without  interruption  for  example  if  the  path  is  of  length  3  and  it  starts  at  time  1  then  it  will  arrive  at  time  4  alternatively  if it  starts  at  time  2  it will  arrive  at  time  5  further  it  is  necessary  to place  the paths so  that no collisions occur  that is  no two paths  can  be  at  the  same  processor  at  the  same  instant  in  time  essentially  time  adds an extra dimension to the topology of the network and within this spacecid173 time network all data paths must be nonconflicting  the rules for constructing  paths that fulfill  these requirements are listed  below    \\u2022  at  most  one  connection  can  enter a  processor  at  a  given  time  and  at  most one connection can leave  a  processor at a  given time  it is  possible  to have both one coming and one going at the same time  note that this  does  not mean  that a  processor can have  only  one  connection  it  means  that it can have only one connection during anyone of the t  time steps  it can have as many as t  connections going  through it    \\u2022  any  path  between  two  processors  uv  reprsenting  a  connection  must   consist of steps at contiguous times  for example  if the path from  procid173 cessor u  to processor v  is  ufghv  then if the arc  from uf is  assigned  time 1  fg  must  have time 2  gh time 3  and hv  time 4  likewise if uf  occurs  at time 5  then arc hv will  occur time 8    809   when these  rules  are used when forming  paths  the slots structure  can  be used  to mark the paths  each path goes  through neighboring processors  at  successive  time  steps  for each of these  time  steps  the  dffiection  field  of  the slots structure is  marked telling the processor which direction  it should  pass a message if it receives it on that time  slots serves both to instruct the  processors  how to send  messages and to indicate that a  processor is  busy at a  certain time slot so  that when new paths are constructed it can be guaranteed  that they wont conflict with current paths  consider  the following  example  suppose we  are  given  the  directed  graph  with  vertices  abcd  and  edges  a     c  b     cb     d  and  d     a  this  is  to  be  done  where  abc  and  d  have  been  assigned  to  successive  elements  of  a  linear  array  a  linear  array  in  not  a  good  network  for  this  scheme but is  a  convenient source of examples   loical connections   faa  2  giapb example   abcd  are  successive  members  in  a  linear  array   1234  abcd   first  a c  can  be  completed  with  the  map  easteast  so  slotsa1direction    e  slotsb2directione  slotsc2end    1     bc  can  be  done  with  the  map  east  it  can  start  at  time  1  since  slotsb 1  direction  and  slotsc 1end  are  free   bd  goes  through  c then  to  d  its  map  is  easteast  b is  occupied  at  time  1  and  2  it  is  free  at  time  3  so  slotsb 3direction    e  slotsc 4direction    e  slotsd 4end    1   da  must  go  through  cba  using  map  westwestwest  d is  free  on  time  1  c  is  free  on  time  2  but  b is  occupied  on  time  3  d is  free  on  time  2  but  c  is  occupied  on  time  3  it  can  start  from  d at  time  3  slotsd 3direction    w  slotsc 4  direction    w  slotsb 5direction    w  slots a  5end1    810   every processor acts as a  conduit for its neighbors messages  no  processor  knows where any message is going to or coming from  but each processor knows  what it must do  to establish the local connections   the  use  of  contiguous  time  slots  is  vital  to  the  correct  operation  of  the  system  if all edgepaths  are established according to the above rules  there is  a  simple  method for  making  the connections  the paths  have been  restricted  so  that there  will  be  no  collisions  and  paths  directions  use  consecutive  time  slots  hence  if all  arcs  at time  i send a  message  to their neighbors  then each  processor  is  guaranteed  no  more  than  1  message  coming  to it  the end  of a  path  is  specified  by  setting  a  separate  bit  that  is  tested  after  each  message  is  received  a  separate  start  bit  indicates when  a  path starts  the  start  bit  is  needed  because  the  slots  array just tells  the  processors  where  to send  a  message  regardless  of  how  that  message  arrived  the  start  array  indicates  when a  message originates as opposed to arriving from a  neighbor   the following  algorithm is  basic to the routing system   for  i    time  1  to  t   forall  processors    if  an  arc  starts  or  is  passing  through  at  this  time   if  sloti  start    1  or  active    1   for  j1  to  neighborlimit   if  slotidirection  j   write  message  bit  to  inbox   of  neighbor  j   set  active    0  forall  processor  that  just  received  a  message  if  endi   move  inbox  to  messagedestination   else   move  inbox  to  outbox  set  active  bit    1   this  code  follows  the  method  mentioned  above  the  time  slots  are  looped  through and the messages are passed in the appropriate directions as specified  in the slots array  two bits inbox and outbox are used for message passing  so  that  an outgoing  message  wont be  overwritten  by  an  incoming  message  before  it  gets  transferred  the  inner  loop  lor j   1  to  neighbor  limit  checks  each of the  possible  neighbor  directions  and sends  the message  to  the correct  neighbor  for instance in a grid the neighbor limit is  4 for north south east  and  west  neighbors  the  time  complexity  of data  movement  is  ot  times  neighborlimi t    setting  up  connections   one of the goals in developing this system was to have a  method for adding  new connections quickly  paths are added so  that they dont conflict with any  previously  constructed  path  once  a  path  is  placed  it  will  not  be  rerouted    811   by the  basic  placement algorithm  it will  always start at the same spot at the  same  time  the basic  idea of the  method  for  placing  a  connection  is  to start  from  the source  processor  and  in  parallel  examine  all  possible  paths outward  from it that do not conflict with preestablished paths and which adhere to the  sequential  time  constraint  as  the  trial  paths  are  flooding  the  system  they  are recorded  in temporary storage  at the end of this deluge of trial  paths all  possible  paths will  have been examined  if the destination processor has been  reached  then  a  path  exists  under  the  current  timespace  restrictions  using  the stored  information a  path can be  backtraced and  recorded  in the  slots  structure  this is  similar to the leemoore routing algorithm21 \\u202222  for  finding  a  path in a  system but with the sequential time restriction   for example  suppose  that the  connection  uv  is  to  be  added  first  it is  assumed  that processors for  u  and v  have already  been  determined otherwise  as  a  simplification  assume  a  random  allocation  from  a  pool  of free  procescid173 sors  a  parallel breadthfirst search will  be performed starting from  the source  processor  during the propagation phase a  processor which receives a  message  checks its slots array to see if they are busy on that time step if not  it will  propagate to its neighbors on the next  time step  for instance suppose a  trial  path starts at time 1 and moves to a neighboring processor but that neighbor is  already busy at time 1  as can be seen by examining the directionslot  since a  path that would go  through this  neighbor at this time is  not legal  the  trial path would commit suicide  that is  it stops propagating itself  if the procid173 cessor slot for time 2 was free  the trial path would attempt to propagate to all  of its neighbors  at time 3   using  this  technique  paths can  be  constructed  with  essentially  no  knowlcid173 edge of the relative locations of the  neurons  being connected or the underlycid173 ing topology  variations on the outlined method such as choosing the shortest  path can improve the choice of paths with very little overhead  if the entire netcid173 work were known ahead of time an offline method could  be used  to construct  the paths more efficiently  work on offline methods is underway  however the  simple elegance of this basic method holds great appeal for systems that change  slowly over time in unpredictable ways   performance   adding an edge  assuming one can be added deleting any set of edges  or   traversing all  the edges in parallel all  have time complexity ot x  neighborcid173 limit  if it  is  assumed  that neighbor  limit  is  a  small  constant then  the  comcid173 plexity  is  ot  since  t  is  related  both  to  the  time  and  space  needed  it  is  a  crucial  factor  in  determining  the  value  of the  algorithms  presented  some  analytic bounds on t  were presented inll but it is difficult to get a  tight bound  on t  for general interconnection networks and dynamically changing graphs  a  simulator was constructed to examine the behavior of the algorithms  besides  the  simulated  data  the  algorithms  mentioned  were  actually  implemented  for  the  connection  machine  the  data  produced  by  the  simulator  is  consistent  with that produced by the real machine  the major result is  that the size of t  appears  proportional to the average degree of the graph times  the diameter of  the interconnection network20 \\u2022    812   further research   this  paper has  been  largely  concerned  with  a  system that  can realize  the  connections in a  neural network when the two  neurons  to be joined have  been  activated  the  tests  conducted  have  been  concerned  with  the validity  of the  method  for  implementing connections  rather than with  a  full  simulation of a  neural  network  clearly this is  the next step   a  natural  extension  of  this  method  is  a  system  which  can  form  its own  connections  based  solely  on  the  activity  of  certain  neurons  without  having  to explicitly  activate the  source  and  destination neurons  this  is  an exciting  avenue and further results should  be forthcoming   another  area of  research  involves  the  formation  of branching  paths  the  current method  takes an arc in  the neural  network and realizes  it  as a  unique  path  in  spacetime  a  variation  that  has  similarities  to  dendritic  structure  would  allow  a  path coming  from  a  neuron  to  branch and  go  to several  target  neurons  this extension would  allow  for  a  much more  economical  embedding  system  simulations are currently underway   conclusions   a method has been outlined which allows the implementation of neural nets  connections on a  class  of parallel  architectures which can be constructed with  very large numbers of processing elements  to economize on hardware so as  to  maximize the number of processing element buildable it was assumed that the  processors  only  have local connections  no hardware is  provided for  communicid173 cation  some simple  algorithms  have  been  presented which  allow  neural  nets  with arbitrary connections to be embedded in simd architectures having a  vacid173 riety of topologies  the time for  performing a  parallel traversal and for adding  a  new  connection  appears  to  be  proportional  to the diameter of the  topology  times  the average  number of arcs  in  the  graph  being embedded  in a  system  where  the topology  has diameter ologn  and where  the degree of the  graph  being  embedded  is  bounded  by  a  constant  the  time  is  apparently  ologn  this  makes  it  competitive with  existing  methods  for  simd  routing  with  the  advantages that there are no apriori requirements for the form of the data and  the  topological  requirements are  extremely  general  also  with  our  approach  new arcs can be added without reconfiguring the entire system  the simplicity  of the implementation and the flexibility of the method suggest that it could be  an important tool for  using simd  architectures for  neural network simulation   bibliography   1  mj  flynn  some  computer organizations  and  their effectiveness  ieee  trans comput vol  c21  no9  pp  948960  2  w  hillis the connection machine mit press  cambridge mass  1985  3  d  nassimi s  sahni  parallel algorithms to setup the benes permutation  network proc  workshop on interconnection networks for  parallel and discid173 tributed processing  april 1980  4  d nassimi s sahni  benes network and parallel permutation algorithms  ieee transactions on computers vol  c30  no 5  may 1981  5  d  nassimi  s  sahni  parallel permutation and sorting algorithms and  a    813   new  generalized  connection network  jacm  vol  29  no3 july 1982  pp  642667  6  ke  batcher  sorting networks and  their applications the proceedings  of afips 1968  sjcc 1968  pp  307314  7  c thompson  generalized connection networks for parallel processor intercid173 communication ieee tran  computers vol  c no 27 dec 78 pp  11191125  8  nathan h  brown jr  neural network implementation approaches for the  connection machine presented at the 1987 conference on neural information  processing systems  natural and synthetic  9  ke  batcher  design of a  massively  parallel  processor  ieee  trans  on  computers  sept 1980 pp  836840  10  hm hastings s waner neural nets on the mpp  frontiers of massively  parallel  scientific  computation  nasa  conference  publication  2478  nasa  goddard  space flight center greenbelt maryland  1986  11  s  tomboulian  a  system for  routing arbitrary communication graphs  on  simd  architectures  doctoral  dissertation  dept  of  computer  science  duke university durham nc  12  t  feng  a  survey  of  interconnection  networks  computer  dec  1981  pp1227  13  f  preparata and j  vuillemin  the cube  connected  cycles  a  versatile  network for  parallel computation  comm  acm vol  24 no 5 may 1981 pp  300309  14  h  stone  parallel processing with the perfect shuffle ieee trans  comcid173 puters  vol  c  no  20  feb 1971  pp  153161  15  t leighton  parallel  computation using  meshes  of trees  proc  intercid173 national  workshop  on  graph  theory  concepts  in  computer  science  1983  16  ws  mcculloch and w  pitts  a logical  calculus of the ideas imminent  in nervous activity  bulletin of mathematical biophysics vol 5  1943 pp115 133  17  jj  hopfield  neural  networks and  physical  systems  with  emergent  colcid173 lective computational abilities  prot  natl  aca  sci  vol  79  april  1982 pp  25542558  18  t kohonen  selforganization and associative memory springerverlag  berlin 1984  19  rp lippmann  an introduction to computing with neural nets  ieee  aasp apri11987  pp  422  20  s tomboulian  a system for routing directed graphs on simd architeccid173 tures  icase  report  no  8714  nasa  langley research center  hampton  va  21  cy  lee  an  algorithm for  path  connections and  its  applications  ire  trans  elec  comput  vol  eci0 sept  1961  pp  346365  22  e  f  moore  shortest  path  through  a  maze  a nnals  of  computation  laboratory vol  30  cambridge ma  harvard univ  press 1959  pp285292    \",\n          \"1   connectivity versus entropy   yaser  s  abumostafa   california  institute  of technology   pasadena ca 91125   abstract   how  does  the  connectivity  of a  neural  network  number  of synapses  per  neuron  relate  to  the complexity  of the  problems  it  can  handle  measured  by  the entropy  switching theory would suggest no relation at all since all boolean  functions  can be  implemented  using  a  circuit  with very  low  connectivity  eg  using  twoinput  nand  gates  however  for  a  network  that  learns  a  problem  from  examples  using  a  local  learning  rule  we  prove  that  the  entropy  of  the  problem becomes  a  lower  bound for  the connectivity of the network   introduction   the most  distinguishing feature of neural networks  is  their  ability to sponcid173  taneously  learn  the  desired  function  from  training samples  ie  their  ability  to  program themselves  clearly  a  given  neural  network  cannot just learn  any  function  there  must  be  some  restrictions  on which  networks  can  learn which  functions  one obvious restriction which is  independent of the learning aspect  is  that  the network  must  be big enough  to  accommodate the  circuit  complexcid173 ity of the function  it  will  eventually simulate  are there restrictions  that  arise  merely from the fact  that the network  is  expected to learn the function  rather  than being purposely designed for the function  this paper reports a restriction  of this kind   the result imposes a  lower bound on the connectivity of the network  numcid173  ber  of synapses  per neuron  this  lower  bound  can  only  be  a  consequence of  the learning aspect since switching theory provides purposely designed circuits  of low  connectivity  eg  using only  twoinput  nand  gates  capable of implecid173 menting any boolean function  12   it also follows  that the learning mechanism  must  be restricted for  this  lower  bound to hold  a  powerful  mechanism can be   \\u00a9 american institute of physics 1988    2   designed  that will  find  one of the lowconnectivity circuits  perhaps byexhauscid173 tive search and hence the lower bound on connectivity cannot hold in general  indeed we  restrict the learning mechanism to be local  when  a  training sample  is  loaded into the network each neuron has access only to those bits carried by  itself and  the neurons  it  is  directly  connected  to  this  is  a  strong  assumption  that excludes sophisticated learning mechanisms used in neuralnetwork models  but may be more plausible from a  biological point of view   the  lower  bound  on  the  connectivity  of the  network  is  given  in  terms  of  the entropy of the environment that provides the training samples  entropy is  a  quantitative measure of the disorder or randomness in an environment or equivcid173 alently  the  amount  of information  needed  to specify  the environment  there  are many different ways to define entropy and many technical variations of this  concept  3  in the next section  we shall  introduce  the formal  definitions  and  results but we start here with an informal exposition of the ideas  involved   the  environment  in  our  model  produces  patterns  represented  by  n  bits  x    xl \\u2022\\u2022\\u2022 x n  pixels in the picture of a visual scene if you will  only h different  patterns can be generated by  a  given environment where  h   2n  the entropy  is  essentially  log2 h  no  knowledge  is  assumed  about  which  patterns  the  encid173 vironment  is  likely  to generate only  that there  are  h  of them  in the  learning  process  a  huge  number of sample  patterns  are  generated  at random from  the  environment  and input to the network  one  bit per neuron  the network  uses  this  information to set its  internal parameters  and gradually tune itself to this  particular environment  because of the network architecture each neuron knows  only  its own bit and at best  the bits of the neurons it is  directly connected to  by  a  synapse  hence  the learning  rules  are local  a  neuron  does  not have  the  benefit of the entire global pattern that is  being learned   after the learning process has taken place each neuron is  ready to perform  a  function  defined  by  what  it  has  learned  the  collective  interaction  of  the  functions of the neurons is what defines the overall function of the network  the  main  result  of this  paper  is  that  roughly  speaking  if the  connectivity  of the  network  is  less  than the entropy of the environment the network  cannot learn  about the environment  the idea of the proof is  to show that if the connectivity  is  small  the  final  function  of each  neuron  is  independent  of the environment  and hence to conclude that the overall network has accumulated no information  about the environment it is  supposed to learn about   formal result   a neural network is an undirected graph the vertices are the neurons and the  edges are the synapses  label the neurons 1 n  and define kn  c  i n  to  be  the  set  of neurons  connected  by  a  synapse  to  neuron  n  together  with  neuron n  itself  an environment is  a subset e  c  oin  each x  e  e  is  a sample    3   from  the  environment  during  learning  xl xn  the bits  of x  are loaded  into  the  neurons  1 n  respectively  consider  an  arbitrary  neuron  nand  relabel  everything  to make  kn  become  i k  thus  the  neuron  sees  the  first  k  coordinates of each x   since our result  is  asymptotic  in  n we  will specify  k  as  a  function  of n  k   an  where  a   an  satifies  limnoo an   00  0   00   1  since  the  result  is  also statistical we will  consider the ensemble of environments e   eenecoin  i  lelh   where  h    2n and  3   3n  satifies  limnoo 3n   30  0   30    1  the  probability  distribution on e is  uniform  any  environment  e e  e is  as  likely  to  occur as  any other   the  neuron  sees  only  the  first  k  coordinates  of each  x  generated  by  the  environment  e  for  each  e  we  define  the function  n    oik    o 12\\u00b7\\u00b7  where   nal ak  ix eel  xle   ale  for  k  1 ki   and the normalized version   the function  v  describes the relative frequency of occurrence for  each of the 2k  binary vectors xl  xk  as x    xl \\u2022\\u2022\\u2022 xn runs through all h vectors in e  in other  words  v  specifies  the projection of e  as  seen by  the neuron  clearly veal   0  for  all a e  olk  and laeolk veal    1   corresponding to two environments el and e2 we will have two functions  vi  and v2  it vi  is  not distinguishable from v2  the neuron cannot tell the difference  between  el  and  e2  the  distinguishability  between  vi  and v2  can be measured  by   iv1a   v2a i   1   dvlv2    2  2 aeolk   the  range  of dvb v2  is  0    dvl v2    1 where  0  corresponds  to complete  indistinguishability  while  1  corresponds  to  maximum  distinguishability  we  are now  in  a  position to state the main result  let el and e2 be independently selected environments from e according to the  uniform probability distribution  dvl v2  is now  a random variable and we  are  interested in the expected value  edvl v2  the case where  edvb v2    0  corresponds to the neuron getting no information about the environment while  the  case  where  edvb v2    1  corresponds  to  the  neuron  getting  maximum  information  the theorem predicts in the limit one of these extremes depending  on how the connectivity  00 compares to the entropy  30    4   theorem  1  h  q o   po   then limn  co e dvi v2    1  2  h  q o   po   then limn  co e  dv v2    o   the proof is  given  in the appendix  but the idea is  easy  to illustrate  inforcid173 mally  suppose  h    2k 10  corresponding to part  2  of the theorem  for  most  environments  e  e  e  the  first  k  bits  of x  e  e go  through  all  2k  possible  valcid173 ues  approximately  210  times each as  x  goes  through  all  h  possible values  once  therefore the patterns seen by the neuron are drawn from the fixed ensemble of  all binary vectors of length k  with essentially uniform probability distribution  ie  v  is  the same for  most  environments  this  means  that  statistically  the  neuron will  end  up  doing  the same  function  regardless  of the environment  at  hand   what about the opposite case where h    2k  10  corresponding to part lof  the theorem  now  with only 2k  10  patterns available from  the environment  the  first  k  bits  of x  can assume  at  most  2k 10  values  out  of the  possible  2k  values a binary vector of length k  can assume in principle  furthermore which  values  can  be  assumed  depends  on  the  particular  environment  at  hand  ie  v  does  depend  on the environment  therefore  although  the  neuron still  does  not  have  the global  picture  the  information  it  has  says  something  about  the  environment   acknowledgement   this work was supported by the air force office of scientific research under   grant  afosr860296   appendix   in this  appendix we  prove the main theorem  we  start by  discussing some  basic  properties  about  the ensemble  of environments  e  since  the  probability  distribution on e is  uniform and since ie i   e we  have   pre      2n1   h   which  is  equivalent  to  generating  e  by  choosing  h  elements  x  e  oln  with  uniform probability without replacement  it follows  that   h  prx e  e   2n    5   h  hl  prxl e  e   x2  e  e   2n  x  2n   1   and so on   the functions  n  and  v  are defined on kbit vectors  the statistics of na   a random variable for  fixed a  is  independent of a   prnat  m   prna2  m   which follows  from the symmetry with respect to each bit of a  the same holds  for  the statistics of va  the expected value ena    h2k  h  objects going  into  2k  cells hence eva    2 k   we  now restate and prove the theorem   theorem  1  if ao  po   then limnoo e  dvt v2   1  2  if ao  po   then limnoo e  dvt v2   0   proof   we expand e  dvt v2  as follows   where nl and n2  denote nlo \\u00b7\\u00b70 and n20\\u00b7\\u00b7 \\u00b70 respectively and the last step  follows  from the fact  that the statistics of nla  and  n2a  is  independent  of a  therefore to prove the theorem we  evaluate elnl  n21  for  large  n   1  assume  ao  po  let  n  denote  no\\u00b7\\u00b7\\u00b7 0  and consider  prn  0  for n  to  be zero  all  2n  k  strings  x  of n  bits  starting with  k  os  must  not  be  in  the  environment  e  hence   prn  0   1      1    h  2n   h   2n   1     1    h     2n   2n k   1   where  the first  term is  the probability  that 0\\u00b7  \\u00b700 f  e  the second term is  the    6   probability that o\\u00b7  01   f  given that o\\u00b7  00   f  and so on    1 2n h2n  k nk    1 h2 n1 2k1 2n  k    1   2h2n2n  k   1 2h2n 2n  k    1 2h2k   hence  prnl  0   prn2   0   prn  0   1  2h2k \\u2022  however  enl    e n2   h2k  therefore   elnl  n2   llprnl   in2   jli  jl        ioo         l l prnl   iprn2    j ii  jl   ioo      l prnl  0prn2   jj  0    l prnl  iprn2  oi   io   which follows  by throwing away  all the terms where neither i  nor j  is  zero  the  term where both i  an j  are zero appears twice for convenience but this term is  zero  anyway    prnl  0en2  prn2    oenl   21  2h2k h2k   substituting this estimate in the expression for  edvb v2  we get   edvl v2    2h elnl  n21   2k   x  21  2h2 k h2k   2k     2h    1 2h2 k   1  2  x  28an   since a o   130  by  assumption this lower bound goes  to 1  as  n  goes to infinity  since  1 is  also  an upper bound for  d vi v2  and hence an upper bound for  the  expected value edvl v2  limnoo edvl v2  must be 1    7   2  assume  a o  po  consider   elnl  n21   e  inl  h2k   n2   h2 k i    enl  h2 k   in2   h2ki   enl  h2 k i   eln2  h2k i   2eln  h2ki   to  evaluate  eln   h2 k i  we  estimate  the  variance  of  n  and  use  the  fact  that  eln  h2 k i    jvarn  recall  that  h2k    en\\u00bb  since  varn    en2  en2  we  need an estimate for  en2  we write n    eeolnk 6  where   6   \\u2022    if 0  \\u00b7oa e  e\\u00b7      1    0  otherwise   in this notation en2   can be written as   en2  e  i   i   66t   eolnk beolnk  i   l   e66t   eolnk beolnk   for the diagonal terms  a   b   e66   pr6  1    h2n   there  are  2n  k  such  diagonal  terms  hence  a  total  contribution  of  2n  k  x  h2 n    h2 k  to the sum  for the offdiagonal terms  a  b   e66b    pr 6  16b  1    pr6  1pr6b  116  1   h  hl  x 2n  2n1   there are 2n  k 2n  k  1 such offdiagonal terms hence a  total contribution of  2n  k2 n  k  1 x  2n1  h2k2 21 to the sum  putting the contributions    8   from the diagonal and offdiagonal terms together we  get   en2  h2k  h2k2 2n    1  varn  en2   en2   2n     h2 k   h2 k  2 1  h2 k    h2k  h2  k2  2n  1   1      h2 k     h2k  1   2n 1   2h2k   the last step follows since h2k is  much smaller than 2n 1 therefore eln h2 k i   vvarn   2h2 ki  substituting this estimate in the expression for  e d vb v2  we  get   1   edvb v2    2h elnl  n21   2k   2k     2h  x  2eln  h2 ki   2k   1     2h  x  2 x  2h2ki      2k    2 h    v2 x  2qn   since a o  po  by assumption this upper bound goes  to 0 as  n  goes to infinity  since  0  is  also  a  lower  bound for  dvb v2  and  hence  a  lower  bound for  the  expected value  edvb v2  limnoo edvb v2  must be o \\u2022   references   1  y  abumostafa  neural  networks  for  computing  alp  conference  procid173 ceedings   151  neural networks for  computing j denker ed pp  16 1986   2  z  kohavi  switching and finite  automata  theory mcgrawhill 1978   3  y  abumostafa  the complexity  of information extraction  ieee  trans  on information  theory vol  it32  pp  513525 july  1986   4  y abumostafa  complexity in neural systems  in analog  vlsi and neural  systems by c  mead  addisonwesley  1988    \",\n          \"775   a  neuralnetwork  solution to  the  concentrator   assignnlent  problem   gene  a  tagliarini  edward  w  page   department of computer  science  clemson university  clemson  sc   296341906  abstract   networks  of simple analog  processors  having  neuronlike properties have  been  employed  to  compute  good  solutions  to  a  variety  of optimization  probcid173 lems  this  paper presents  a  neuralnet solution to  a  resource allocation probcid173 lem that arises  in  providing  local  access  to  the  backbone of a  widearea  comcid173 munication  network  the  problem is  described in  terms of an energy function  that can be  mapped onto an analog computational network  simulation results  characterizing  the  performance  of the  neural  computation  are  also  presented   introduction   this  paper  presents  a  neuralnetwork  solution  to  a  resource  allocation  problem  that  arises  in  providing  access  to  the  backbone  of  a  communication  network 1 in the  field  of operations  research  this  problem was  first  known  as  the  warehouse  location problem and  heuristics  for finding  feasible  suboptimal  solutions  have  been developed  previously2 3  more  recently it  has  been known  as the multifacility location problem4  and as  the concentrator assignment probcid173 lem1   the hopfield  neural  network  model   the  general  structure of the  hopfield  neural  network model5 \\u2022 67 is  illuscid173  trated  in  fig  1  neurons  are  modeled  as amplifiers  that have  a  sigmoid  input  output curve  as  shown  in  fig  2  synapses  are  modeled  by  permitting  the  outcid173 put  of  any  neuron  to  be  connected  to  the  input  of  any  other  neuron  the  strength of the synapse is modeled by a  resistive connection between the output  of a  neuron and the input to another  the amplifiers  provide integrative analog  summation of the currents that result from the  connections to  other neurons  as  well  as  connection  to  external  inputs  to  model  both  excitatory and  inhibitory  synaptic  links  each amplifier provides  both a  normal output v and an inverted  output  v  the  normal  outputs  range  between  0  and  1  while  the  inverting  amcid173 plifier  produces  corresponding  values  between 0 and  1  the  synaptic  link becid173 tween  the  output  of  one  amplifier  and  the  input  of  another  is  defined  by  a  conductance tij  which connects one of the outputs of amplifier j to  the input of  amplifier i  in the  hopfield  model  the  connection  between  neurons  i and  j  is  made with a  resistor having  a  value rij   1rrij   to  provide an excitatory synapcid173 tic  connection  positive  tij   the  resistor  is  connected  to  the  normal  output of   this  research  was  supported  by  the  us  army  strategic defense  command   \\u00a9 american institute of physics 1988    776   13   14   inputs   vi   v4   v3   v2   outputs  fig  1  schematic  for  a  simplified  hopfield  network  with  four  neurons   1   v   o   u   o   u   fig  2  amplifier  inputoutput   relationship   amplifier  j  to  provide  an  inhibitory  connection  negative  tij  the  resistor  is  connected  to  the  inverted  output  of  amplifier  j  the  connections  among  the  neurons  are  defined  by  a  matrix  t  consisting  of  the  conductances  tij   hop field  has  shown  that a  symmetric  t  matrix  tij   tji   whose  diagonal  entries  are  all  zeros  causes  convergence  to  a  stable  state  in  which  the  output of each  amplifier is  either 0 or 1  additionally  when the amplifiers are operated in the  highgain mode  the  stable  states of a  network of n  neurons correspond  to the  local  minima  of the  quantity   n   n  e   112  l  l  jl   il   t\\u00b7vv\\u00b7  ij  1  j   n  l  vi\\u00b7   i  1   1   where  vi  is  the  output of the  ith  neuron  and  ii  is  the  externally  supplied  input  to  the  ph  neuron  hopfield  refers  to  e  as  the  computational  energy  of the  syscid173 tem   the concentrator assignment  problem   consider a  collection of n  sites  that are to  be connected  to  m  concentracid173  tors  as  illustrated  in  fig  3a  the  sites  are  indicated  by  the  shaded  circles  and  the  concentrators  are  indicated  by  squares  the  problem  is  to  find  an  assignment of sites to concentrators that minimizes the total cost of the  assigncid173 ment  and  does  not  exceed  the  capacity  of  any  concentrator  the  constraints  that must be  met can  be  summarized  as  follows   a  each  site  i    i  1  2    n    is  connected to  exactly one concentrator   and    777   b  each concentrator j  j  1  2   m    is  connected to  no  more than  kj   sites  where  kj  is  the  capacity  of concentrator d   figure  3b  illustrates  a  possible  solution  to  the  problem  represented  in  fig  3a   0   \\u2022  \\u2022 \\u2022 \\u2022   \\u2022  \\u2022 \\u2022  \\u2022   0   \\u2022 \\u2022   0   \\u2022   \\u2022   0   o concentrators  \\u2022  sites   a  siteconcentrator  map   b  possible  assignment   fig  3  example  concentrator assignment problem   if the cost of assigning  site i to  concentrator j  is  cij   then the total cost of   a  particular  assignment  is   total  cost     n  m  l  l  jl  il   x \\u00b7\\u00b7  c\\u00b7\\u00b7  ij   ij   2   where  xij  1 only if we  actually decide to assign site i to concentrator j and is  0  otherwise  there  are  mn  possible  assignments  of  sites  to  concentrators  that  satisfy  constraint  a  exhaustive  search  techniques  are  therefore  impractical  except for  relatively  small  values  of  m  and  n   the neural network  solution   this  problem  is  amenable  to  solution  using  the  hopfield  neural  network   model  the  hopfield  model  is  used  to  represent  a  matrix  of  possible  assigncid173 ments of sites to concentrators as illustrated in fig  4  each square corresponds    778   s   ites         \\u2022   concentrators  1  m  r               r  1  ii  11 iii iii  2    i  \\u2022 \\u2022 \\u2022 \\u2022   \\u2022  i the  darkly  shaded  neu i  iii  11 ii ii i ron  corresponds  to  the  hypothesis  that site  i  n ii  \\u2022 ii ii  should  be  asigned to      nl  ii  1111111  slack   n2  iii  ii  \\u2022  \\u2022  \\u2022  nk j ii  11 iii iii   j  concentrator j                          2   j   \\u2022   fig  4  concentrator  assignment array   to  a  neuron  and  a  neuron  in  row  i  and  column  j  of the  upper  n  rows  of the  array  represents  the  hypothesis  that site  i should  be  connected  to  concentrator  j  if the  neuron in  row  i and  column j  is  on  then  site  i should  be  assigned  to  concentrator j  if it is  off  site  i should  not be  assigned  to  concentrator j   the  neurons  in  the  lower  subarray  indicated  as  slack  are  used  to  implement  individual  concentrator capacity constraints  the  number  of  slack  neurons  in a  column should  equal  the  capacity  expressed  as  the  number sites  which  can  be  accommodated  of  the  corresponding  concentrator  while  it  is  not  necessary  to  assume  that  the  concentrators  have  equal  capacities  it  was  assumed here that they did and that their cumulative capacity is  greater than or  equal  to  the  number  of sites   to  enale the  neurons  in  the  network  illustrated  above  to  compute  solucid173  tions  to  the  concentrator problem  the  network must realize  an energy function  in which the  lowest energy states correspond to the  least cost assignments  the  energy  function  must therefore  favor  states which  satisfy  constraints  a  and b  above  as  well  as  states  that  correspond  to  a  minimum  cost  assignment  the  energy function  is  implemented  in terms of connection strengths  between neucid173 rons  the  following  section  details  the  construction  of an  appropriate  energy  function    the energy  function   consider the  following  energy  equation   2  e    a  l   l  y    1     m   n     1  1     1  j   1j   m   nk\\u00b7   b  l   l  j y     k    2      j1   i1   ij   j   779   3   m  nkj     c  l  l  y    1   yij    j1   i1   1j   where  yij  is  the  output  of the  amplifier  in  row  i  and  column  j  of the  neuron  matrix  m  and  n  are  the  number  of  concentrators  and  the  number  of  sites  respectively  and  kj  is  the  capacity of concentrator  j   the first term will  be minimum when the sum of the outputs in each row  of  neurons  associated  with  a  site  equals  one  notice  that  this  term influences  only those rows of neurons which correspond to sites  no term is  used to coerce  the  rows  of  slack  neurons  into  a  particular  state   the  second  term of the  equation  will  be  minimum  when  the  sum of the   outputs in each column equals the  capacity  kj  of the  corresponding concentracid173 tor  the  presence of the  kj  slack neurons  in  each column allows  this  term  to  enforce  the  concentrator capacity restrictions  the effect of this  term upon the  upper  subarray  of  neurons  those  which  correspond  to  site  assignments  is  that  no  more  than  kj  sites  will  be  assigned  to  concentrator  j  the  number of  neurons  to  be  turned  on  in  column j  is  kj   consequently  the  number  of  neucid173 rons  turned  on  in  column  j  of  the  assignment  subarray  will  be  less  than  or  equal  to  kj      the third term causes the  energy function to  favor the  zero  and one  states of the  individual neurons by being  minimum when all neurons are in one  or the  other of these  states  this  term  influences  all  neurons  in  the  network  in summary  the  first  term  enforces  constraint  a  and  the  second  term   enforces  constraint b  above  the  third  term guarantees  that a  choice  is  actucid173 ally  made  it assures  that  each  neuron  in  the  matrix  will  assume  a  final  state  near  zero or one  corresponding  to  the  xij  term of the  cost  equation  eq  2  after some algebraic rearrangement eq  3 can be written in the form of   eq  1  where   t  ij  kl          c    8ui    18ik\\u00bb  if  in  or kn   a   8ik    18ui    b    8u1    18ik\\u00bb  if  in and  kn   4   here  quadruple  subscripts are  used  for  the  entries in the  matrix t  each entry  indicates  the  strength of the  connection  between  the  neuron in  row  i  and  colcid173 umn j  and  the  neuron  in  row  k and  column  i of the  neuron  matrix  the  funccid173 tion  delta  is  given  by    780   8 i    j        1  if i  j   0  otherwise   5   the  a  and b  terms  specify  inhibitions  within  a  row  or a  column of the  upper  subarray  and  the  c  term  provides  the  column  inhibitions  required  for  the  neurons  in  the  subarray of slack neurons   equation 3 specifies the form of a  solution but it does not include a  term  that  will  cause  the  network  to  favor  minimum  cost  assignments  to  complete  the  formulation  the  following  term  is  added  to  each tijkl   d  \\u2022  8 j    i   \\u2022    1   8  i    k       cost   i    j      cost   k    i     where  cost  i   j    is  the  cost of assigning  site  i to  concentrator j  the  effect of  this term is  to  reduce the inhibitions  among the  neurons that correspond to low  cost assignments  the sum of the costs of assigning both site i to concentrator j  and  site  k  to  concentrator i  was  used  in order to  maintain the  symmetry of t  the external input currents were derived from the energy equation eq3   and  are  given  by   i   2 k j   if  i    n   ij    2  \\u2022  k j   1  otherwise   6   this exemplifies a  technique  for combining  external input currents which arise  from  combinations  of certain  basic  types  of constraints   an example   the  neural  network  solution for  a  concentrator assignment problem concid173 sisting  of twelve  sites  and five  concentrators  was  simulated  all  sites  and concid173 centrators  were  located  within  the  unit square on a  randomly  generated  map  for this  problem  it was  assumed  that no  more  than  three  sites  could  be   assigned  to  a  concentrator  the  assignment  cost  matrix  and  a  typical  assigncid173 ment  resulting  from  the  simulation  are  shown  in  fig  5  it  is  interesting  to  notice  that the  network proposed an assignment which made no  use of concencid173 trator 2   because  the  capacity  of  each  concentrator  kj  was  assumed  to  be  three  sites  the  external  input current for  each  neuron  in the  upper  subarray  was   i ij   6   while  in  the  subarray  of slack  neurons  it was   i ij   5   the  other  parameter values  used  in  the  simulation  were   and   a   b   c  2   d   01      781   concentrators   1   2   3   4   5   sites   a   b   c   d   e   f   g   31   62   25   51   17   39   h    81   67   84   33   i   j   k   l   60      42      47   28   72   75   55    46     40   63   95   88   71    39  78    38   92   82   81   77   76   54   56    46  g  41  g  44  g  51  55  b  38   76   66   48   52   56   60  105   71   18   fig  5  the  concentrator assignment cost  matrix  with  choices  circled   since  this  choice  of  parameters  results  in  a  t  matrix  that  is  symmetric  and  whose  diagonal  entries  are  all  zeros  the  network  will  converge  to  the  minima of eq  3  furthermore  inclusion of the  term which  is  weighted  by  the  parameter d  causes  the  network  to  favor  minimum  cost assignments   to  evaluate  the  performance  of  the  simulated  network  an  exhaustive   search of all  solutions to the problem was conducted using  a backtracking algocid173 rithm  a  frequency distribution of the  solution costs associated with the assigncid173 ments generated by the  exhaustive search is  shown in fig  6  for comparison  a  histogram  of the  results  of  one  hundred  consecutive  runs  of  the  neuralnet  simulation is  shown in fig  7  although the  neuralnet simulation did  not find  a  global  minimum  ninetytwo  of the  one  hundred  assignments  which  it  did  find  were  among  the  best 001   of all  solutions  and  the  remaining  eight were  among  the  best 03   neural  networks  can  be  used  to  find  good  though  not  necessarily  opticid173  mal  solutions  to  combinatorial  optimization  problems  like  the  concentrator   conclusion    782   frequency   4000000  3500000  3000000  250000   1500000  100000  500000   ol 32  42   52   62   72   cost  82   fig  6  distribution  of assignment  costs  resulting  from  an exhaustive  search of all  possible  solutions   frequency  25   20   15   10   5   o   fig  7  distribution  of assignment  costs  resulting  from  100  consecucid173 tive  executions  of the  neural  net  simulation   assignment problem  in order to  use  a  neural  network to  solve  such problems  it is  necessary to be able to represent a  solution to the problem as a  state of the  network  here  the  concentrator  assignment  problem  was  successfully  mapped  onto a  hopfield  network by associating  each neuron with  the  hypothesis  that a  given  site  should  be assigned  to  a  particular  concentrator  an energy  function  was  constructed to  determine  the  connections  that were  needed  and the  result ing  neural  network  was  simulated   while  the  neural  network  solution  to  the  concentrator  assignment  probcid173 lem  did  not  find  a  globally  minimum  cost  assignment  it  very  effectively  recid173 jected poor solutions  the network was even able to suggest assignments which  would  allow  concentrators  to  be  removed  from  the  communication network   references   1  a  s  tanenbaum  computer networks  prenticehall  englewood  cliffs   new  jersey  1981  p  83   2  e  feldman  f  a  lehner  and  t  l  ray  manag  sci  v12  670  1966   3  a  kuehn  and  m  hamburger  manag  sci  v9  643  1966   4  t  aykin  and a  1  g  babu  1  of the  oper  res  soc  v38  n3  241  1987   5  j  1  hopfield  proc  natl  acad  sci  u  s  a  v79  2554  1982   6  j  1  hopfield  and  d  w  tank  bio  cyber  v52  141  1985   7 d  w  tank and  1  1  hopfield  ieee trans  on cir  and sys cas33  n5   533  1986    \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top_keywords\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}